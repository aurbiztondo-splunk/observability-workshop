var relearn_search_index=[{content:` 5 minutes How to retrieve the IP address of the AWS/EC2 instance assigned to you. Connect to your instance using SSH, Putty1 or your web browser. Verify your connection to your AWS/EC2 cloud instance. Using Putty (Optional) Using Multipass (Optional) 1. AWS/EC2 IP Address In preparation for the workshop, Splunk has prepared an Ubuntu Linux instance in AWS/EC2.
To get access to the instance that you will be using in the workshop please visit the URL to access the Google Sheet provided by the workshop leader.
Search for your AWS/EC2 instance by looking for your first and last name, as provided during registration for this workshop.
Find your allocated IP address, SSH command (for Mac OS, Linux and the latest Windows versions) and password to enable you to connect to your workshop instance.
It also has the Browser Access URL that you can use in case you cannot connect via ssh or putty - see EC2 access via Web browser
Important Please use SSH or Putty to gain access to your EC2 instance if possible and make a note of the IP address as you will need this during the workshop.
2. SSH (Mac OS/Linux) Most attendees will be able to connect to the workshop by using SSH from their Mac or Linux device, or on Windows 10 and above.
To use SSH, open a terminal on your system and type ssh ubuntu@x.x.x.x (replacing x.x.x.x with the IP address found in Step #1).
When prompted Are you sure you want to continue connecting (yes/no/[fingerprint])? please type yes.
Enter the password provided in the Google Sheet from Step #1.
Upon successful login you will be presented with the Splunk logo and the Linux prompt.
3. SSH (Windows 10 and above) The procedure described above is the same on Windows 10, and the commands can be executed either in the Windows Command Prompt or PowerShell. However, Windows regards its SSH Client as an “optional feature”, which might need to be enabled.
You can verify if SSH is enabled by simply executing ssh
If you are shown a help text on how to use the ssh-command (like shown on the screenshot below), you are all set.
If the result of executing the command looks something like on the screenshot below, you want to enable the “OpenSSH Client” feature manually.
To do that, open the “Settings” menu, and click on “Apps”. While being in the “Apps \u0026 features” section, click on “Optional features”.
Here, you are presented a list of installed features. On the top, you see a button with a plus icon to “Add a feature”. Click it. In the search input field, type “OpenSSH”, and find a feature called “OpenSSH Client”, or respectively, “OpenSSH Client (Beta)”, click on it, and click the “Install”-button.
Now you are set! In case you are not able to access the provided instance in spite of enabling the OpenSSH feature, please do not shy away from reaching out to the course instructor, either via chat or directly.
At this point you are ready to continue and start the workshop
4. Putty (For Windows Versions prior to Windows 10) If you do not have ssh preinstalled or if you are on a Windows system, the best option is to install putty, you can find here.
Important If you cannot install Putty, please go to Web Browser (All).
Open Putty and enter the in Host Name (or IP address) field the IP address provided in the Google Sheet.
You can optionally save your settings by providing a name and pressing Save.
To then login to your instance click on the Open button as shown above.
If this is the first time connecting to your AWS/EC2 workshop instance, you will be presented with a security dialog, please click Yes.
Once connected, login in as ubuntu and the password is the one provided in the Google Sheet.
Once you are connected successfully you should see a screen similar to the one below:
At this point you are ready to continue and start the workshop
5. Web Browser (All) If you are blocked from using SSH (Port 22) or unable to install Putty you may be able to connect to the workshop instance by using a web browser.
Note This assumes that access to port 6501 is not restricted by your company’s firewall.
Open your web browser and type http://x.x.x.x:6501 (where X.X.X.X is the IP address from the Google Sheet).
Once connected, login in as ubuntu and the password is the one provided in the Google Sheet.
Once you are connected successfully you should see a screen similar to the one below:
Unlike when you are using regular SSH, copy and paste does require a few extra steps to complete when using a browser session. This is due to cross browser restrictions.
When the workshop ask you to copy instructions into your terminal, please do the following:
Copy the instruction as normal, but when ready to paste it in the web terminal, choose Paste from browser as show below:
This will open a dialog box asking for the text to be pasted into the web terminal:
Paste the text in the text box as show, then press OK to complete the copy and paste process.
Note Unlike regular SSH connection, the web browser has a 60 second time out, and you will be disconnected, and a Connect button will be shown in the center of the web terminal.
Simply click the Connect button and you will be reconnected and will be able to continue.
At this point you are ready to continue and start the workshop.
6. Multipass (All) If you are unable to access AWS, but you want to install software locally, follow the instructions for using Multipass.
Download Putty ↩︎
`,description:"",tags:null,title:"How to connect to your workshop environment",uri:"/en/imt/initial-setup/index.html"},{content:` 15 minutes Deploy the Online Boutique application into Kubernetes (K3s) Verify the application is running Generate some artificial traffic using Locust See APM metrics in the UI 1. Check your EC2 server This workshop module assumes you are running this after you have run the IM workshop, and still have access to your EC2 instance.
If this is the case, continue with Deploy Online Boutique, otherwise if you have received a fresh instance, please run the first two (2) sections of Deploy the OTel Collector to get the system ready for the APM workshop, then continue with the next section.
2. Deploy Online Boutique To deploy the Online Boutique application into K3s, run the apm-config.sh script, then apply the deployment:
Deploy Online Boutique Deployment Output cd ~/workshop/apm ./apm-config.sh kubectl apply -f deployment.yaml APM Only Deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created In case of a message about a VARIABLE being unset Delete the deployment running kubectl delete -f deployment.yaml.
Then, export the variable as described in the guide/message, followed by re-running the deployment script above.
To ensure the Online Boutique application is running:
Get Pods Get Pods Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-849cf595bf-l7mnq 1/1 Running 0 31m splunk-otel-collector-agent-pxrgp 2/2 Running 0 31m productcatalogservice-8464cd56d-n8f89 1/1 Running 0 1m redis-cart-bcf44df97-djv6z 1/1 Running 0 1m checkoutservice-8558fd7b95-b9pn8 1/1 Running 0 1m shippingservice-7cc4bdd6f4-xsvnx 1/1 Running 0 1m recommendationservice-647d57fd44-l7tkq 1/1 Running 0 1m frontend-66c5d589d-55vzb 1/1 Running 0 1m emailservice-6ff5bbd67d-pdcm2 1/1 Running 0 1m paymentservice-6866558995-8xmf2 1/1 Running 0 1m currencyservice-8668d75d6f-mr68h 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-cr4pr 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-qjr4b 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-fvb4x 1/1 Running 0 1m cartservice-7b58c88c45-xvxhq 1/1 Running 0 1m loadgenerator-6bdc7b4857-9kxjd 1/1 Running 2 (49s ago) 1m adservice-7b68d5b969-89ft2 1/1 Running 0 1m Info Usually it should only take around 1min 30secs for the pods to transition into a Running state.
4. Validate in the UI In the Splunk UI click on Infrastructure this will bring you to the Infrastructure Overview dashboard, then click on Kubernetes.
Use the Cluster dropdown so select your Cluster, you should see the new pods started and containers deployed. When you click on your Cluster in the Splunk UI you should have a view that looks like below:
If you select the WORKLOADS tab again you should now see that there are a number of Deployments and ReplicaSets:
5. View Online Boutique The Online Boutique is viewable on port 81 of the EC2 instance’s IP address. The IP address is the one you used to SSH into the instance at the beginning of the workshop.
Open your web browser and go to http://\u003cec2-ip-address\u003e:81/ where you will then be able to see the Online Boutique running.
`,description:"Deploy the Online Boutique application into Kubernetes (K3s) and generate some artificial traffic using Locust.",tags:null,title:"1. Deploy the Online Boutique",uri:"/en/apm/online-boutique/index.html"},{content:`1. Kubernetes Navigator 2.0 UI We will be starting this workshop using the new Kubernetes Navigator so please check that you are already using the new Navigator.
When you select Infrastructure from the main menu on the left, followed by selecting Kubernetes, you should see two services panes (K8s nodes and K8s workloads) for Kubernetes, similar like the ones below:
2. Connect to EC2 instance You will be able to connect to the workshop instance by using SSH from your Mac, Linux or Windows device. Open the link to the sheet provided by your instructor. This sheet contains the IP addresses and the password for the workshop instances.
To use SSH, open a terminal on your system and type ssh ubuntu@x.x.x.x (replacing x.x.x.x with the IP address assigned to you). The password for this workshop is also provided in the sheet.
Note Your workshop instance has been pre-configured with the correct Access Token and Realm for this workshop. There is no need for you to configure these.
3. Namespaces in Kubernetes Most of our customers will make use of some kind of private or public cloud service to run Kubernetes. They often choose to have only a few large Kubernetes clusters as it is easier to manage centrally.
Namespaces are a way to organize these large Kubernetes clusters into virtual sub-clusters. This can be helpful when different teams or projects share a Kubernetes cluster as this will give them the easy ability to just see and work with their own resources.
Any number of namespaces are supported within a cluster, each logically separated from others but with the ability to communicate with each other. Components are only visible when selecting a namespace or when adding the --all-namespaces flag to kubectl instead of allowing you to view just the components relevant to your project by selecting your namespace.
Most customers will want to install the Splunk OpenTelemetry Collector into a separate namespace. This workshop will follow that best practice.
4. Install Splunk OTel using Helm Install the OpenTelemetry Collector using the Splunk Helm chart. First, add the Splunk Helm chart repository and update.
helm repo add helm repo add output helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 "splunk-otel-collector-chart" has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the "splunk-otel-collector-chart" chart repository Update Complete. ⎈Happy Helming!⎈ Install the OpenTelemetry Collector Helm chart into a new splunk namespace with the following commands, do NOT edit this:
helm install helm install splunk-otel-collector \\ --set="splunkObservability.realm=$REALM" \\ --set="splunkObservability.accessToken=$ACCESS_TOKEN" \\ --set="clusterName=$(hostname)-k3s-cluster" \\ --set="splunkObservability.logsEnabled=true" \\ --set="splunkObservability.infrastructureMonitoringEventsEnabled=true" \\ splunk-otel-collector-chart/splunk-otel-collector \\ --namespace splunk \\ --create-namespace \\ -f ~/workshop/k3s/splunk-defaults.yaml 5. Verify Deployment You can monitor the progress of the deployment by running kubectl get pods and adding -n splunk to the command to see the pods in the splunk namespace which should typically report that the new pods are up and running after about 30 seconds.
Ensure the status is reported as Running before continuing.
kubectl get pods kubectl get pods Output kubectl get pods -n splunk NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-pvstb 2/2 Running 0 19s splunk-otel-collector-k8s-cluster-receiver-6c454894f8-mqs8n 1/1 Running 0 19s Use the label set by the helm install to tail logs (You will need to press ctrl + c to exit).
kubectl logs kubectl logs -l app=splunk-otel-collector -f --container otel-collector -n splunk Or use the installed k9s terminal UI.
Deleting a failed installation If you make an error installing the Splunk OpenTelemetry Collector you can start over by deleting the installation using:
helm delete splunk-otel-collector -n splunk `,description:"",tags:null,title:"Deploying the OpenTelemetry Collector in Kubernetes using a NameSpace",uri:"/en/other/hpa/1-deploy-otel/index.html"},{content:`Gain insights into and perform powerful, capable analytics on your infrastructure and resources across hybrid and multi-cloud environments with Splunk Infrastructure Monitoring. Infrastructure Monitoring offers support for a broad range of integrations for collecting all kinds of data, from system metrics for infrastructure components to custom data from your applications. Let us go ahead and explore the Metrics being captured through Splunk Otel collector.
`,description:"",tags:null,title:"Exploring IMT",uri:"/en/other/o11y4rookies/imt/imt/index.html"},{content:`Aim The aim of this module is for you to configure your personal profile which controls how you will be notified by Splunk On-Call whenever you get paged.
1. Contact Methods Switch to the Splunk On-Call UI and click on your login name in the top right hand corner and chose Profile from the drop down. Confirm your contact methods are listed correctly and add any additional phone numbers and e-mail address you wish to use.
2. Mobile Devices To install the Splunk On-Call app for your smartphone search your phones App Store for Splunk On-Call to find the appropriate version of the app. The publisher should be listed as VictorOps Inc.
Apple Store
Google Play
Configuration help guides are available:
Apple Android Install the App and login, then refresh the Profile page and your device should now be listed under the devices section. Click the Test push notification button and confirm you receive the test message.
3. Personal Calendar This link will enable you to sync your on-call schedule with your calendar, however as you do not have any allocated shifts yet this will currently be empty. You can add it to your calendar by copying the link into your preferred application and setting it up as a new subscription.
4. Paging Policies Paging Polices specify how you will be contacted when on-call. The Primary Paging Policy will have defaulted to sending you an SMS assuming you added your phone number when activating your account. We will now configure this policy into a three tier multi-stage policy similar to the image below.
4.1 Send a push notification Click the edit policy button in the top right corner for the Primary Paging Policy.
Send a push notification to all my devices Execute the next step if I have not responded within 5 minutes Click Add a Step
4.2 Send an e-mail Send an e-mail to [your email address] Execute the next step if I have not responded within 5 minutes Click Add a Step
4.3 Call your number Every 5 minutes until we have reached you Make a phone call to [your phone number] Click Save to save the policy.
When you are on-call or in the escalation path of an incident, you will receive notifications in this order following these time delays.
To cease the paging you must acknowledge the incident. Acknowledgements can occur in one of the following ways:
Expanding the Push Notification on your device and selecting Acknowledge Responding to the SMS with the 5 digit code included Pressing 4 during the Phone Call Slack Button For more information on Notification Types, see here.
5. Custom Paging Policies Custom paging polices enable you to override the primary policy based on the time and day of the week. A good example would be to get the system to immediately phone you whenever you get a page during the evening or weekends as this is more likely to get your attention than a push notification.
Create a new Custom Policy by clicking Add a Policy and configure with the following settings:
5.1 Custom evening policy Policy Name: Evening
Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: All 7 Days Timezone Between 7pm and 9am Click Save to save the policy then add one more.
5.2 Custom weekend policy Policy Name: Weekend
Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: Sat \u0026 Sun Timezone Between 9am and 7pm Click Save to save the policy.
These custom paging policies will be used during the specified times in place of the Primary Policy. However, admins do have the ability to ignore these custom policies, and we will highlight how this is achieved in a later module.
The final option here is the setting for Recovery Notifications. These are typically low priority, will default to Push, but can also be email, sms or phone call. Your profile is now fully configured using these example configurations.
Organizations will have different views on how profiles should be configured and will typically issue guidelines for paging policies and times between escalations etc.
Please wait for the instructor before proceeding to the Teams module.
`,description:"",tags:null,title:"User Profile",uri:"/en/oncall/getting_started/index.html"},{content:`Please note to begin the following lab, you must have completed the prework:
Obtain a Splunk Observability Cloud access key Understand cli commands Follow these steps if using O11y Workshop EC2 instances
1. Verify yelp data files are present ll /var/appdata/yelp* 2. Export the following variables export ACCESS_TOKEN=\u003cyour-access-token\u003e export REALM=\u003cyour-o11y-cloud-realm\u003e export clusterName=\u003cyour-k8s-cluster\u003e 3. Clone the following repo cd /home/ubuntu git clone https://github.com/leungsteve/realtime_enrichment.git cd realtime_enrichment/workshop python3 -m venv rtapp-workshop source rtapp-workshop/bin/activate `,description:"",tags:null,title:"Getting Started with O11y GDI - Real Time Enrichment Workshop",uri:"/en/other/gdi/1-getting-started/index.html"},{content:`1. Downloading the OpenTelemetry Collector Contrib distribution Obtain the .deb package for your platform from the OpenTelemetry Collector Contrib releases page
wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.75.0/otelcol-contrib_0.75.0_linux_amd64.deb 2. Installing the OpenTelemetry Collector Contrib distribution Install the .deb package using dpkg:
Install dpkg Output sudo dpkg -i otelcol-contrib_0.75.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 64218 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.75.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.75.0) ... Setting up otelcol-contrib (0.75.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service. 3. Confirm the Collector is running Command Status Output sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-05-16 08:23:23 UTC; 25s ago Main PID: 1415 (otelcol-contrib) Tasks: 5 (limit: 1141) Memory: 22.2M CPU: 125ms CGroup: /system.slice/otelcol-contrib.service └─1415 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: NumberDataPoints #0 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Data point attributes: May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e exporter: Str(logging) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_instance_id: Str(df8a57f4-abdc-46b9-a847-acd62db1001f) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_name: Str(otelcol-contrib) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_version: Str(0.75.0) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: StartTimestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Timestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Value: 0.000000 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: {"kind": "exporter", "data_type": "metrics", "name": "logging"} 4. Default configuration OpenTelemetry is configured through .yaml files. These files have default configurations that we can modify to meet our needs. Let’s look at the default configuration that is supplied:
Command Configuration Output cat /etc/otelcol-contrib/config.yaml extensions: health_check: pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] We will now walk through each section of the configuration file and modify it to send host metrics to Splunk Observability Cloud.
Splunk does provide its own, fully supported, distribution of the OpenTelemetry Collector. This distribution is available to install from the Splunk GitHub Repository. This distribution includes a number of additional features and enhancements that are not available in the OpenTelemetry Collector Contrib distribution.
The Splunk Distribution of the OpenTelemetry Collector is production tested; it is in use by a number of customers in their production environments. Customers that use our distribution can receive direct help from official Splunk support within SLA’s. Customers can use or migrate to the Splunk Distribution of the OpenTelemetry Collector without worrying about future breaking changes to its core configuration experience for metrics and traces collection (OpenTelemetry logs collection configuration is in beta). There may be breaking changes to the Collector’s own metrics. `,description:"",tags:null,title:"Installing OpenTelemetry Collector Contrib",uri:"/en/conf/opentelemetry-collector/1-installation/index.html"},{content:`1. Introduction The OpenTelemetry Collector is the core component of instrumenting infrastructure and applications. Its role is to collect and send:
Infrastructure metrics (disk, cpu, memory, etc) Application Performance Monitoring (APM) traces Profiling data Host and application logs Splunk Observability Cloud offers wizards to walk you through the setup of the Collector on both your infrastructure and applications. By default, the wizard will only provide the commands to only install the collector.
2. Configure environment variables If you have already completed the Splunk IM workshop you can take advantage of the existing environment variables. Otherwise, create the ACCESS_TOKEN and REALM environment variables to use in the proceeding OpenTelemetry Collector install command.
For instance, if your realm is us1, you would type export REALM=us1 and for eu0 type export REALM=eu0 etc.
Export ACCESS TOKEN export ACCESS_TOKEN="\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e" Export REALM export REALM="\u003creplace_with_REALM\u003e" Delete any existing OpenTelemetry Collectors If you have completed the Splunk IM workshop, please ensure you have deleted the collector running in Kubernetes before continuing. This can be done by running the following command:
helm delete splunk-otel-collector 3. Install the OpenTelemetry Collector We can then go ahead and install the Collector. There are two additional parameters passed to the install script, they are --with-instrumentation and --deployment-environment. The --with-instrumentation option the installer will install the agent from the Splunk distribution of OpenTelemetry Java, which is then loaded automatically when the PetClinic Java application starts up. No configuration required!
curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\ sudo sh /tmp/splunk-otel-collector.sh --with-instrumentation --deployment-environment $(hostname)-petclinic --realm $REALM -- $ACCESS_TOKEN AWS/EC2 instances If you are attempting this workshop on an AWS/EC2 instance you will have to patch the collector to expose the hostname of the instance:
sudo sed -i 's/gcp, ecs, ec2, azure, system/system, gcp, ecs, ec2, azure/g' /etc/otel/collector/agent_config.yaml Once the agent_config.yaml has been patched, you will need to restart the collector:
sudo systemctl restart splunk-otel-collector Once the install is completed, you can navigate to the Hosts with agent installed dashboard to see the data from your host, Dashboards → Hosts with agent installed.
Use the dashboard filter and select host.name and type or select the hostname of your virtual machine. Once you see data flowing for your host, we are then ready to get started with the APM component.
`,description:"",tags:null,title:"Installing the OpenTelemetry Collector",uri:"/en/other/pet-clinic/imt/index.html"},{content:`Overview of the RUM Workshop The aim of this Splunk Real User Monitoring (RUM) workshop is to let you:
Shop for some fantastic items on the Online Boutique to create traffic, and create a number of RUM User Sessions1 that you can view in the Splunk Observability Suite.
See an overview of the performance of all your application(s) in the Application Summary Dashboard (Both Mobile and Web based)
Examine the performance of a specific website or Mobile App with RUM metrics.
Investigate issues with your website and backend services.
(Optionally) See how to add RUM to your website.
In order to reach this goal, we will use an online boutique to order various products. Whilst shopping on the online boutique you will create what is called a User Session.
You may encounter some issues with this web site, and you will use Splunk RUM to identify the issues, so they can be resolved by the developers.
If this a standalone RUM workshop, the workshop host will provide you with a URL for an online boutique store that has RUM enabled.
If you are running this session as part of the IM/APM workshop you will be able to use your current online boutique store after we enable RUM.
Each of these Online Boutiques are also being visited by a few synthetic users, this will allow us to generate more live data to be analyzed later.
A RUM Users session is a “recording” of a collection of user interactions on an application, basically collecting a website or app’s performance measured straight from the browser or Mobile App of the end user. To do this a small amount of JavaScript is embedded in each page. This script then collects data from each user as he or she explores the page, and transfers that data back for analysis. ↩︎
`,description:"",tags:null,title:"1. Overview",uri:"/en/other/o11y4rookies/rum/1-overview/index.html"},{content:`Overview of the RUM Workshop The aim of this Splunk Real User Monitoring (RUM) workshop is to let you:
Shop for some fantastic items on the Online Boutique to create traffic, and create a number of RUM User Sessions1 that you can view in the Splunk Observability Suite.
See an overview of the performance of all your application(s) in the Application Summary Dashboard (Both Mobile and Web based)
Examine the performance of a specific website or Mobile App with RUM metrics.
Investigate issues with your website and backend services.
(Optionally) See how to add RUM to your website.
In order to reach this goal, we will use an online boutique to order various products. Whilst shopping on the online boutique you will create what is called a User Session.
You may encounter some issues with this web site, and you will use Splunk RUM to identify the issues, so they can be resolved by the developers.
If this a standalone RUM workshop, the workshop host will provide you with a URL for an online boutique store that has RUM enabled.
If you are running this session as part of the IM/APM workshop you will be able to use your current online boutique store after we enable RUM.
Each of these Online Boutiques are also being visited by a few synthetic users, this will allow us to generate more live data to be analyzed later.
A RUM Users session is a “recording” of a collection of user interactions on an application, basically collecting a website or app’s performance measured straight from the browser or Mobile App of the end user. To do this a small amount of JavaScript is embedded in each page. This script then collects data from each user as he or she explores the page, and transfers that data back for analysis. ↩︎
`,description:"",tags:null,title:"1. Overview",uri:"/en/rum/1-overview/index.html"},{content:`This lab will make a tracing superhero out of you!
In this lab you will learn how a distributed trace is constructed for a small serverless application that runs on AWS Lambda, producing and consuming your message via AWS Kinesis.
Pre-requisites You should already have the lab content available on your EC2 lab host.
Ensure that this lab’s required folder o11y-lambda-lab is on your home directory:
Command Output cd ~ \u0026\u0026 ls o11y-lambda-lab Note If you don’t see it, fetch the lab contents by running the following command:
git clone https://github.com/kdroukman/o11y-lambda-lab.git Set Environment Variables In your Splunk Observability Cloud Organisation (Org) obtain your Access Token and Realm Values.
Please reset your environment variables from the earlier lab. Take care that for this lab we may be using different names - make sure to match the Environment Variable names bellow.
Export Environment Variables export ACCESS_TOKEN=CHANGE_ME \\ export REALM=CHANGE_ME \\ export PREFIX=$(hostname) Update Auto-instrumentation serverless template Update your auto-instrumentation Serverless template to include new values from the Enviornment variables.
Substitute Environment Variables cat ~/o11y-lambda-lab/auto/serverless_unset.yml | envsubst \u003e ~/o11y-lambda-lab/auto/serverless.yml Examine the output of the updated serverless.yml contents (you may need to scroll up to the relevant section).
Check file contents Expected Content cat ~/o11y-lambda-lab/auto/serverless.yml # USER SET VALUES ===================== custom: accessToken: \u003cupdated to your Access Token\u003e realm: \u003cupdated to your Realm\u003e prefix: \u003cupdated to your Hostname\u003e #====================================== Update Manual instrumentation template Update your manual instrumentation Serverless template to include new values from the Enviornment variables.
Substitute Environment Variables cat ~/o11y-lambda-lab/manual/serverless_unset.yml | envsubst \u003e ~/o11y-lambda-lab/manual/serverless.yml Examine the output of the updated serverless.yml contents (you may need to scroll up to the relevant section).
Check file contents Expected Content cat ~/o11y-lambda-lab/manual/serverless.yml # USER SET VALUES ===================== custom: accessToken: \u003cupdated to your Access Token\u003e realm: \u003cupdated to your Realm\u003e prefix: \u003cupdated to your Hostname\u003e #====================================== Set your AWS Credentials You will be provided with AWS Access Key ID and AWS Secret Access Key values - substitue these values in place of AWS_ACCESS_KEY_ID and AWS_ACCESS_KEY_SECRET in the bellow command:
Set AWS Credentials sls config credentials --provider aws --key AWS_ACCCESS_KEY_ID --secret AWS_ACCESS_KEY_SECRET This command will create a file ~/.aws/credentials with your AWS Credentials populated.
Note that we are using sls here, which is a Serverless framework for developing and deploying AWS Lambda functions. We will be using this command throughout the lab.
Now you are set up and ready go!
`,description:"",tags:null,title:"Setup",uri:"/en/other/lambda-kinesis/1-setup/index.html"},{content:`Environment Setup - Mac Note If you wish to run this on Mac directly, you can see the instructions here in the appendix and skip the next section on Linux.
All installs must continue at setting up the app.
Environment Setup - Linux You can skip past the EC2 configuration to Linux Software Requirements if you already have an Ec2 that meets the specifications below !!!!
ubuntu 22.04 Security Group Security Settings HTTP inbound open on 8010 All Traffic open outbound Linux Software Requirements: docker, docker-compose, git, maven sudo apt update sudo apt upgrade sudo apt install docker docker-compose maven `,description:"",tags:null,title:"Setting up your AWS Instance",uri:"/en/other/dev-mttr-custom-tags/1-setup-os/index.html"},{content:`The Kubernetes Navigator offers you two separate use cases to view your Kubernetes data.
The K8s workloads is focusing on providing information in regards to workloads a.k.a. your deployments. The K8s nodes is focusing on providing insight into the performance of clusters, nodes, pods and containers.
`,description:"",tags:null,title:"Exploring Kubernetes Cluster",uri:"/en/other/o11y4rookies/imt/imt/nginx/index.html"},{content:`Service Map Click on paymentservice in the service map and select version from the breakdown drop down filter underneath paymentservice. This will filter our service map by the custom span tag version.
You will now see the service map has been updated like the below screenshot to show the different versions of the paymentservice.
Splunk Observability shows that not only is paymentservice experiencing errors (you can see request rate vs error rate) but that this service is the root cause.
This happens automatically with our AI-directed triage capabilities once distributed tracing is enabled in your services. You don’t have to set a threshold or anything for it to populate just like this.
This is one example of how customers can detect issues faster and know where to look for errors and hence helps reduce the MTTD and MTTR.
`,description:"",tags:null,title:"1.1 Service Map",uri:"/en/other/o11y4rookies/apm/using-splunk-apm/service_map/index.html"},{content:`Aim The aim of this module is for you to complete the first step of Team configuration by adding users to your Team.
1. Find your Team Navigate to the Teams tab on the main toolbar, you should find you that a Team has been created for you as part of the workshop pre-setup and you would have been informed of your Team Name via e-mail.
If you have found your pre-configured Team, skip Step 2. and proceed to Step 3. Configure Your Team. However, if you cannot find your allocated Team, you will need to create a new one, so proceed with Step 2. Create Team
2. Create Team Only complete this step if you cannot find your pre-allocated Team as detailed in your workshop e-mail. Select Add Team, then enter your allocated team name, this will typically be in the format of “AttendeeID Workshop” and then save by clicking the Add Team button.
3. Configure Your Team You now need to add other users to your team. If you are running this workshop using the Splunk provided environment, the following accounts are available for testing. If you are running this lab in your own environment, you will have been provided a list of usernames you can use in place of the table below.
These users are dummy accounts who will not receive notifications when they are on call.
Name Username Shift Duane Chow duanechow Europe Steven Gomez gomez Europe Walter White heisenberg Europe Jim Halpert jimhalpert Asia Lydia Rodarte-Quayle lydia Asia Marie Schrader marie Asia Maximo Arciniega maximo West Coast Michael Scott michaelscott West Coast Tuco Salamanca tuco West Coast Jack Welker jackwelker 24/7 Hank Schrader hank 24/7 Pam Beesly pambeesly 24/7 Add the users to your team, using either the above list or the alternate one provided to you. The value in the Shift column can be ignored for now, but will be required for a later step.
Click Invite User button on the right hand side, then either start typing the usernames (this will filter the list), or copy and paste them into the dialogue box. Once all users are added to the list click the Add User button.
To make a team member a Team Admin, simply click the :fontawesome-regular-edit: icon in the right hand column, pick any user and make them an Admin.
Tip For large team management you can use the APIs to streamline this process.
Continue and also complete the Configure Rotations module.
`,description:"",tags:null,title:"Teams",uri:"/en/oncall/getting_started/team/index.html"},{content:`Aim The aim of this module is for you to get more familiar with the Timeline Tab and the filtering features.
1. Timeline The aim of Splunk On-Call is to make being on call more bearable, and it does this by getting the critical data, to the right people, at the right time.
The key to making it work for you is to centralize all your alerting sources, sending them all to the Splunk On-Call platform, then you have a single pane of glass in which to manage all of your alerting.
Login to the Splunk On-Call UI and select the Timeline tab on the main menu bar, you should have a screen similar to the following image:
2. People On the left we have the People section with the Teams and Users sub tabs. On the Teams tab, click on All Teams then expand [Your Teamname].
Users with the Splunk On-Call Logo against their name are currently on call. Here you can see who is on call within a particular Team, or across all Teams via Users → On-Call.
If you click into one of the currently on call users, you can see their status. It shows which Rotation they are on call for, when their current Shift ends and their next Shift starts (times are displayed in your timezone), what contact methods they have and which Teams they belong to (dummy users such as Hank do not have Contact Methods configured).
3. Timeline In the centre Timeline section you get a realtime view of what is happening within your environment with the newest messages at the top. Here you can quickly post update messages to make your colleagues aware of important developments etc.
You can filter the view using the buttons on the top toolbar showing only update messages, GitHub integrations, or apply more advanced filters.
Lets change the Filters settings to streamline your view. Click the Filters button then within the Routing Keys tab change the Show setting from all routing keys to selected routing keys. Change the My Keys value to all and the Other Keys value to selected and deselect all keys under the Other Keys section.
Click anywhere outside of the dialogue box to close it.
You will probably now have a much simpler view as you will not currently have Incidents created using your Routing Keys, so you are left with the other types of messages that the Timeline can display.
Click on Filters again, but this time switch to the Message Types tab. Here you control the types of messages that are displayed.
For example, deselect On-call Changes and Escalations, this will reduce the amount of messages displayed.
4. Incidents On the right we have the Incidents section. Here we get a list of all the incidents within the platform, or we can view a more specific list such as incidents you are specifically assigned to, or for any of the Teams you are a member of.
Select the Team Incidents tab you should find that the Triggered, Acknowledged \u0026 Resolved tabs are currently all empty as you have had no incidents logged.
Let’s change that by generating your first incident!
Continue with the Create Incidents module.
`,description:"",tags:null,title:"Incident Lifecycle",uri:"/en/oncall/incident_lifecycle/index.html"},{content:`Aim The aim of this module is for you to place yourself ‘On-Call’ then generate an Incident using the supplied EC2 Instance so you can then work through the lifecycle of an Incident.
1. On-Call Before generating any incidents you should assign yourself to the current Shift within your Follow the Sun Support - Business Hours Rotation and also place yourself On-Call.
Click on the Schedule link within your Team in the People section on the left, or navigate to Teams → [Your Team] → Rotations Expand the Follow the Sun Support - Business Hours Rotation Click on the Manage members icon (the figures) for the current active shift depending on your timezone Use the Select a user to add… dropdown to add yourself to the shift Then click on Set Current next to your name to make yourself the current on-call user within the shift You should now get a Push Notification to your phone informing you that You Are Now On-Call 2. Trigger Alert Switch back to your shell session connected to your EC2 Instance; all of the following commands will be executed from your Instance.
Force the CPU to spike to 100% by running the following command:
openssl speed -multi $(grep -ci processor /proc/cpuinfo) Forked child 0 +DT:md4:3:16 +R:19357020:md4:3.000000 +DT:md4:3:64 +R:14706608:md4:3.010000 +DT:md4:3:256 +R:8262960:md4:3.000000 +DT:md4:3:1024 This will result in an Alert being generated by Splunk Infrastructure Monitoring which in turn will generate an Incident within Splunk On-Call within a maximum of 10 seconds. This is the default polling time for the OpenTelemetry Collector installed on your instance (note it can be reduced to 1 second).
Continue with the Manage Incidents module.
`,description:"",tags:null,title:"Create Incidents",uri:"/en/oncall/incident_lifecycle/create_incidents/index.html"},{content:`1. Editing a chart Select the SAMPLE CHARTS dashboard and then click on the three dots ... on the Latency histogram chart, then on Open (or you can click on the name of the chart which here is Latency histogram).
You will see the plot options, current plot and signal (metric) for the Latency histogram chart in the chart editor UI.
In the Plot Editor tab under Signal you see the metric demo.trans.latency we are currently plotting.
You will see a number of Line plots. The number 18 ts indicates that we are plotting 18 metric time series in the chart.
Click on the different chart type icons to explore each of the visualizations. Notice their name while you swipe over them. For example, click on the Heat Map icon:
See how the chart changes to a heat map.
Note You can use different charts to visualize your metrics - you choose which chart type fits best for the visualization you want to have.
For more info on the different chart types see Choosing a chart type.
Click on the Line chart type and you will see the line plot.
2. Changing the time window You can also increase the time window of the chart by changing the time to Past 15 minutes by selecting from the Time dropdown.
3. Viewing the Data Table Click on the Data Table tab.
You now see 18 rows, each representing a metric time series with a number of columns. These columns represent the dimensions of the metric. The dimensions for demo.trans.latency are:
demo_datacenter demo_customer demo_host In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics.
If you move your cursor over the lines in the chart horizontally you will see the data table update accordingly. If you click on one of the lines in the chart you will see a pinned value appear in the data table.
Now click on Plot editor again to close the Data Table and let’s save this chart into a dashboard for later use!
`,description:"",tags:null,title:"Editing charts",uri:"/en/other/o11y4rookies/imt/dashboards/editing/index.html"},{content:` Learn how to configure Muting Rules Learn how to resume notifications 1. Configuring Muting Rules There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in Splunk Observability Cloud. Let’s create one!
Click on Alerts \u0026 Detectors in the sidebar and then click Detectors to see the list of active detectors.
If you created a detector in Creating a Detector you can click on the three dots ... on the far right for that detector; if not, do that for another detector.
From the drop-down click on Create Muting Rule…
In the Muting Rule window check Mute Indefinitely and enter a reason.
Important This will mute the notifications permanently until you come back here and un-check this box or resume notifications for this detector.
Click Next and in the new modal window confirm the muting rule setup.
Click on Mute Indefinitely to confirm.
You won’t be receiving any email notifications from your detector until you resume notifications again. Let’s now see how to do that!
2. Resuming notifications To Resume notifications, click on Muting Rules, you will see the name of the detector you muted notifications for under Detector heading.
Click on the thee dots ... on the far right, and click on Resume Notifications.
Click on Resume to confirm and resume notifications for this detector.
Congratulations! You have now resumed your alert notifications!
`,description:"",tags:null,title:"Working with Muting Rules",uri:"/en/other/o11y4rookies/imt/detectors/muting/index.html"},{content:`1. Editing a chart Select the SAMPLE CHARTS dashboard and then click on the three dots ... on the Latency histogram chart, then on Open (or you can click on the name of the chart which here is Latency histogram).
You will see the plot options, current plot and signal (metric) for the Latency histogram chart in the chart editor UI.
In the Plot Editor tab under Signal you see the metric demo.trans.latency we are currently plotting.
You will see a number of Line plots. The number 18 ts indicates that we are plotting 18 metric time series in the chart.
Click on the different chart type icons to explore each of the visualizations. Notice their name while you swipe over them. For example, click on the Heat Map icon:
See how the chart changes to a heat map.
Note You can use different charts to visualize your metrics - you choose which chart type fits best for the visualization you want to have.
For more info on the different chart types see Choosing a chart type.
Click on the Line chart type and you will see the line plot.
2. Changing the time window You can also increase the time window of the chart by changing the time to Past 15 minutes by selecting from the Time dropdown.
3. Viewing the Data Table Click on the Data Table tab.
You now see 18 rows, each representing a metric time series with a number of columns. These columns represent the dimensions of the metric. The dimensions for demo.trans.latency are:
demo_datacenter demo_customer demo_host In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics.
If you move your cursor over the lines in the chart horizontally you will see the data table update accordingly. If you click on one of the lines in the chart you will see a pinned value appear in the data table.
Now click on Plot editor again to close the Data Table and let’s save this chart into a dashboard for later use!
`,description:"",tags:null,title:"Editing charts",uri:"/en/imt/dashboards/editing/index.html"},{content:` Learn how to configure Muting Rules Learn how to resume notifications 1. Configuring Muting Rules There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in Splunk Observability Cloud. Let’s create one!
Click on Alerts \u0026 Detectors in the sidebar and then click Detectors to see the list of active detectors.
If you created a detector in Creating a Detector you can click on the three dots ... on the far right for that detector; if not, do that for another detector.
From the drop-down click on Create Muting Rule…
In the Muting Rule window check Mute Indefinitely and enter a reason.
Important This will mute the notifications permanently until you come back here and un-check this box or resume notifications for this detector.
Click Next and in the new modal window confirm the muting rule setup.
Click on Mute Indefinitely to confirm.
You won’t be receiving any email notifications from your detector until you resume notifications again. Let’s now see how to do that!
2. Resuming notifications To Resume notifications, click on Muting Rules, you will see the name of the detector you muted notifications for under Detector heading.
Click on the thee dots ... on the far right, and click on Resume Notifications.
Click on Resume to confirm and resume notifications for this detector.
Congratulations! You have now resumed your alert notifications!
`,description:"",tags:null,title:"Working with Muting Rules",uri:"/en/imt/detectors/muting/index.html"},{content:` Introduction to Teams Create a Team and add members to Team 1. Introduction to Teams To make sure that users see the dashboards and alerts that are relevant to them when using Observability Cloud, most organizations will use Observability Cloud’s Teams feature to assign a member to one or more Teams.
Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in Observability Cloud.
When a user logs into Observability Cloud, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role.
In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team.
This Dashboard has specific Dashboard Groups for Usage, SaaS and APM Business Workflows assigned but any Dashboard Group can be linked to a Teams Dashboard.
They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL Dashboards using the adjacent link.
Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert.
The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown).
2. Creating a new Team To work with to Splunk’s Team UI click on the hamburger icon top left and select the Organizations Settings → Teams.
When the Team UI is selected you will be presented with the list of current Teams.
To add a new Team click on the Create New Team button. This will present you with the Create New Team dialog.
Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below:
You can remove selected users by pressing Remove or the small x.
Make sure you have your group created with your initials and with yourself added as a member, then click Done This will bring you back to the Teams list that will now show your Team and the one’s created by others.
Note The Teams(s) you are a member of have a grey Member icon in front of it.
If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself.
This is the same dialog you get when pressing the 3 dots … at the end of the line with your Team and selecting Edit Team
The … menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member).
3. Adding Notification Rules You can set up specific Notification rules per team, click on the Notification Policy tab, this will open the notification edit menu.
By default the system offers you the ability to set up a general notification rule for your team.
Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type.
3.1 Adding recipients You can add other recipients, by clicking Add Recipient . These recipients do not need to be Observability Cloud users.
However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently.
Different alert rules for the different alert levels can be configured, as shown in the above image.
Critical and Major are using Splunk's On-Call Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email.
3.2 Notification Integrations In addition to sending alert notifications via email, you can configure Observability Cloud to send alert notifications to the services shown below.
Take a moment to create some notification rules for you Team.
`,description:"",tags:null,title:"Teams",uri:"/en/other/o11y4rookies/imt/servicebureau/teams/index.html"},{content:` Introduction to Teams Create a Team and add members to Team 1. Introduction to Teams To make sure that users see the dashboards and alerts that are relevant to them when using Observability Cloud, most organizations will use Observability Cloud’s Teams feature to assign a member to one or more Teams.
Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in Observability Cloud.
When a user logs into Observability Cloud, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role.
In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team.
This Dashboard has specific Dashboard Groups for Usage, SaaS and APM Business Workflows assigned but any Dashboard Group can be linked to a Teams Dashboard.
They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL Dashboards using the adjacent link.
Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert.
The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown).
2. Creating a new Team To work with to Splunk’s Team UI click on the hamburger icon top left and select the Organizations Settings → Teams.
When the Team UI is selected you will be presented with the list of current Teams.
To add a new Team click on the Create New Team button. This will present you with the Create New Team dialog.
Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below:
You can remove selected users by pressing Remove or the small x.
Make sure you have your group created with your initials and with yourself added as a member, then click Done This will bring you back to the Teams list that will now show your Team and the one’s created by others.
Note The Teams(s) you are a member of have a grey Member icon in front of it.
If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself.
This is the same dialog you get when pressing the 3 dots … at the end of the line with your Team and selecting Edit Team
The … menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member).
3. Adding Notification Rules You can set up specific Notification rules per team, click on the Notification Policy tab, this will open the notification edit menu.
By default the system offers you the ability to set up a general notification rule for your team.
Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type.
3.1 Adding recipients You can add other recipients, by clicking Add Recipient . These recipients do not need to be Observability Cloud users.
However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently.
Different alert rules for the different alert levels can be configured, as shown in the above image.
Critical and Major are using Splunk's On-Call Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email.
3.2 Notification Integrations In addition to sending alert notifications via email, you can configure Observability Cloud to send alert notifications to the services shown below.
Take a moment to create some notification rules for you Team.
`,description:"",tags:null,title:"Teams",uri:"/en/imt/servicebureau/teams/index.html"},{content:` 45 minutes Splunk Observability Cloud provides full-fidelity monitoring and troubleshooting across infrastructure, applications, and user interfaces, in real-time and at any scale, to help you:
Keeping your services reliable, Innovate faster and Deliver great customer experiences
In this workshop we would provided you a guided hands on deck experience on how you can leverage Splunk Observability solution to reduce the MTTD and MTTR and improve overall customer experience.
`,description:"This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector",tags:null,title:"Observability 4 Rookies",uri:"/en/other/o11y4rookies/index.html"},{content:`The goal is to walk through the basic steps to configure the following components of the Splunk Observability platform:
Splunk Infrastructure Monitoring (IM) Splunk Zero Configuration Auto Instrumentation for Java (APM) Database Query Performance AlwaysOn Profiling Splunk Real User Monitoring (RUM) RUM spans to APM spans Splunk LogsObserver (LO) We will also show the steps about how to clone (download) a sample Java application (Spring PetClinic), as well as how to compile, package and run the application.
Once the application is up and running, we will instantly start seeing metrics and traces via the Zero Configuration Auto Instrumentation for Java that will be used by the Splunk APM product.
After that, we will instrument the PetClinic’s end user interface (HTML pages rendered by the application) with the Splunk OpenTelemetry Javascript Libraries (RUM) that will generate RUM traces around all the individual clicks and page loads executed by an end user.
Lastly, we will configure the Spring PetClinic application to write application logs to the filesystem and also configure the Splunk OpenTelemetry Collector to read (tail) the logs and report to Splunk Observability Cloud.
Prerequisites A Splunk run workshop where an host/instance is provided OR a self led workshop on own host / multipass instance
For your own system you will need the following installed and enabled:
JDK 17 installed Maven Port 8080 open inbound/outbound `,description:"A workshop using Zero Configuration Auto-Instrumentation for Java",tags:null,title:"PetClinic Java Workshop",uri:"/en/other/pet-clinic/index.html"},{content:`During this technical Splunk Observability Cloud Infrastructure Monitoring and APM Workshop you will build out an environment based on a lightweight Kubernetes1 cluster.
In order to simplify the workshop modules, a pre-configured AWS/EC2 instance is provided.
The instance is pre-configured with all the software required to deploy the Splunk OpenTelemetery Connector2 in Kubernetes, deploy a NGINX3 ReplicaSet4 and finally deploy a microservices based application which has been instrumented using OpenTelemetry to send metrics, traces, spans and logs5.
The workshops also introduce you to dashboards, editing and creating charts, creating detectors to fire alerts, Monitoring as Code and the Service Bureau6
By the end of these technical workshops you will have a good understanding of some of the key features and capabilities of the Splunk Observability Cloud.
Here are the instructions on how to access you pre-configured AWS/EC2 instance
Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. ↩︎
The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) sending to multiple open-source or commercial back-ends. ↩︎
NGINX is a web server that can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. ↩︎
Kubernetes ReplicaSet ↩︎
Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies. It is used for monitoring and troubleshooting microservices-based distributed systems ↩︎
Monitoring as Code and Service Bureau ↩︎
`,description:"Whether on-prem, hybrid or multicloud, Splunk delivers real-time monitoring and troubleshooting to help you maximize infrastructure performance with complete visibility.",tags:null,title:"Splunk IM",uri:"/en/imt/index.html"},{content:`In order to simplify the overall experience we will provide you hands on deck to the actual environment where we have the Online Boutique store instrumented via Splunk. This application is written in Java and has microservice architecture
The workshops also introduce you to dashboards, editing and creating charts, creating detectors to fire alerts, Monitoring as Code and the Service Bureau[^6]
By the end of these technical workshops you will have a good understanding of some of the key features and capabilities of the Splunk Observability Cloud.
`,description:"Whether on-prem, hybrid or multicloud, Splunk delivers real-time monitoring and troubleshooting to help you maximize infrastructure performance with complete visibility.",tags:null,title:"Splunk IM",uri:"/en/other/o11y4rookies/imt/index.html"},{content:`Welcome to the Splunk Observability Workshops Get insights into your applications and infrastructure in real-time with the help of the monitoring, analytics and response tools of the Splunk Observability Cloud
These workshops are going to take you through the best-in-class observability platform for ingesting, monitoring, visualizing and analyzing metrics, traces and logs.
OpenTelemetry OpenTelemetry is used in this workshop to instrument, generate, collect and export telemetry data (metrics, traces and logs) to help you analyze your application and infrastructure.
GitHub You can contribute to this documentation via issues and pull requests. Please don’t hesitate to help to make the workshops better.
Twitter You can find information about updates and interesting reads in the Twitter channel of Splunk.
Splunk IMWhether on-prem, hybrid or multicloud, Splunk delivers real-time monitoring and troubleshooting to help you maximize infrastructure performance with complete visibility.
Splunk APMSplunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.
Splunk RUMEnd-to-end visibility helps you pinpoint customer-impacting issues from web browsers and native mobile apps to your backend services.
Splunk SyntheticsProactively find and fix performance issues across user flows, business transactions and APIs to deliver better digital experiences.
Splunk OnCallMake expensive service outages a thing of the past. Remediate issues faster, reduce on-call burnout and keep your services up and running.
Other WorkshopsObservability 4 RookiesThis workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector PetClinic Java WorkshopA workshop using Zero Configuration Auto-Instrumentation for Java Getting Data In (GDI) with OTel and UF45 minutes During this technical workshop you will learn how to: Efficiently deploy complex environments Capture metrics from these environments to Splunk Observability Cloud Auto-instrument a python application Enable OS logging to Splunk Enterprise via Universal Forwarder In order to simplify the workshop modules, a pre-configured AWS EC2 instance is provided.
`,description:"Learn how to build observability solutions with Splunk",tags:null,title:"Splunk Observability Workshops",uri:"/en/index.html"},{content:`This Lab walks your through using the Chrome Selenium IDE extension to create a synthetic transaction against a Splunk demo instance and creating a Splunk Synthetic Monitoring Real Browser Check (RBC). In addition you also get to learn other Splunk Synthetic Monitoring checks like REST API checks and Uptime Checks.
1. Prerequisites Ensure you can login with your username and password at https://monitoring.rigor.com and https://optimization.rigor.com. Also, make sure you are assigned to your own account for example: O11y Workshop.
Edit your Splunk Synthetic Monitoring account personal information and adjust your timezone and email notifications. Splunk Synthetic Monitoring will default to start sending you notifications, you can turn them off at the monitor configuration level.
Add the Chrome Selenium IDE extension to your Chrome Browser. Once installed click on the extension and you will see the following screen:
2. Using Selenium IDE You can now go ahead and record a web transaction using Selenium IDE to check on http://splunk.o11ystore.com.
Click on Record a new test in a new project, name the project [YOUR_INITIALS] - O11y Store e.g. RWC - O11y Store.
!!! question “What is Selenium IDE?” - Selenium IDE is an open source record and playback test automation for the web. - Selenium is a portable framework for testing web applications. - Selenium provides a playback tool for authoring functional tests without the need to learn a test scripting language (Selenium IDE). - It also provides a test domain-specific language (Selenese) to write tests in a number of popular programming languages, including C#, Groovy, Java, Perl, PHP, Python, Ruby and Scala. - The tests can then run against most modern web browsers. - Selenium runs on Windows, Linux, and macOS. - It is open-source software released under the Apache License 2.0.
Enter http://splunk.o11ystore.com as your base URL.
Click Start Recording , a new window should open up with splunk.o11ystore.com. Click Vintage Camera Lens, click Add To Cart and then click Place Order.
Close the window and then stop the recording by navigating back to Selenium IDE. Finally name the test: [YOUR_INITIALS] - Checkout Flow (Desktop) e.g. RWC - Checkout Flow (Desktop).
Your Selenium IDE Project will look something like this:
Test your recording by pressing on the play button, make sure your recording successfully completes the transaction:
Save your Selenium IDE Project to your Downloads folder as Workshop.side
3. Create Real Browser Check Login to Splunk Synthetic Monitoring using https://monitoring.rigor.com. Click on REAL BROWSER and click +New{: .label-button .sfx-ui-button-blue}.
Click on “From File” and select your recording then click on Import
Set the Frequency to 5 Minutes
Click on Steps and make the following adjustments to your recording provide a friendly name to Steps 1 (Click Camera), 2 (Add to Cart) \u0026 3 (Place Order).
Next, click + Add Step, with this new step we will add some validation to the monitor. This is to ensure the checkout completed successfully.
Enter Confirm Order for the Name and change the Action to Wait for text present and finally enter Your order is complete! for the Value. You will now have a Start Url and 4 steps in your monitor configuration.
Tip As you are creating the steps think about how to go about using the Business Transaction feature in Splunk Synthetic Monitoring which is very powerful.
“Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.”
Click on Advanced and make sure the Viewport Size is set to Default desktop: 1366 x 768
Click on “Test” to test your monitor. Once the test has successfully completed make sure to click on “AFTER” in Step 4 to validate the monitor was able to get to the order complete screenshot.
Click on Create{: .label-button .sfx-ui-button-blue} to save your Real Browser Monitor. After 5-10 minutes validate your monitor is working and producing successful checks e.g.
Tip You can force to run your monitor now using Run Now
Change your view to Segment by location and observe the difference. You can turn off/on locations by clicking on them.
!!! question “Question?” Which Location has the poorest Response Time?
Click on one of the successful circles to drill-down into that Run:
Take a moment to explore the metrics with the CONFIGURE METRICS/HIDE METRICS dropdown.
Click Page 2 in the dropdown, and scroll down to view the Filmstrip and the Waterfall Chart.
Click on Click Here to Analyze with Optimization which will prompt you to login to your Splunk Synthetic Monitoring Optimization Account. If you don’t have this option, navigate to this page.
Click the “Best Practices Score” tab. Scroll down, and review all the findings
Spend some time to review the findings. Click into any line item
4. Create Mobile Check Copy the RBC you created above:
Rename it, for example: RWC - Checkout Flow (Tablet)
Under the Advanced tab, update the following three settings and create your new mobile RBC.
Test \u0026 Validate the new monitor
Tip As you are creating the steps try using the Business Transaction feature in Splunk Synthetic Monitoring.
“Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.”
5. Resources Getting Started With Selenium IDE
Splunk Synthetic Monitoring Scripting Guide
How Can I Fix A Broken Script?
Introduction to the DOM (Document Object Model (DOM)
Selenium IDE
`,description:"",tags:null,title:"Real Browser Checks",uri:"/en/other/o11y4rookies/synthetics/real-browser-checks/index.html"},{content:`This Lab walks your through using the Chrome Selenium IDE extension to create a synthetic transaction against a Splunk demo instance and creating a Splunk Synthetic Monitoring Real Browser Check (RBC). In addition you also get to learn other Splunk Synthetic Monitoring checks like REST API checks and Uptime Checks.
1. Prerequisites Ensure you can login with your username and password at https://monitoring.rigor.com and https://optimization.rigor.com. Also, make sure you are assigned to your own account for example: O11y Workshop.
Edit your Splunk Synthetic Monitoring account personal information and adjust your timezone and email notifications. Splunk Synthetic Monitoring will default to start sending you notifications, you can turn them off at the monitor configuration level.
Add the Chrome Selenium IDE extension to your Chrome Browser. Once installed click on the extension and you will see the following screen:
2. Using Selenium IDE You can now go ahead and record a web transaction using Selenium IDE to check on http://splunk.o11ystore.com.
Click on Record a new test in a new project, name the project [YOUR_INITIALS] - O11y Store e.g. RWC - O11y Store.
!!! question “What is Selenium IDE?” - Selenium IDE is an open source record and playback test automation for the web. - Selenium is a portable framework for testing web applications. - Selenium provides a playback tool for authoring functional tests without the need to learn a test scripting language (Selenium IDE). - It also provides a test domain-specific language (Selenese) to write tests in a number of popular programming languages, including C#, Groovy, Java, Perl, PHP, Python, Ruby and Scala. - The tests can then run against most modern web browsers. - Selenium runs on Windows, Linux, and macOS. - It is open-source software released under the Apache License 2.0.
Enter http://splunk.o11ystore.com as your base URL.
Click Start Recording , a new window should open up with splunk.o11ystore.com. Click Vintage Camera Lens, click Add To Cart and then click Place Order.
Close the window and then stop the recording by navigating back to Selenium IDE. Finally name the test: [YOUR_INITIALS] - Checkout Flow (Desktop) e.g. RWC - Checkout Flow (Desktop).
Your Selenium IDE Project will look something like this:
Test your recording by pressing on the play button, make sure your recording successfully completes the transaction:
Save your Selenium IDE Project to your Downloads folder as Workshop.side
3. Create Real Browser Check Login to Splunk Synthetic Monitoring using https://monitoring.rigor.com. Click on REAL BROWSER and click +New{: .label-button .sfx-ui-button-blue}.
Click on “From File” and select your recording then click on Import
Set the Frequency to 5 Minutes
Click on Steps and make the following adjustments to your recording provide a friendly name to Steps 1 (Click Camera), 2 (Add to Cart) \u0026 3 (Place Order).
Next, click + Add Step, with this new step we will add some validation to the monitor. This is to ensure the checkout completed successfully.
Enter Confirm Order for the Name and change the Action to Wait for text present and finally enter Your order is complete! for the Value. You will now have a Start Url and 4 steps in your monitor configuration.
Tip As you are creating the steps think about how to go about using the Business Transaction feature in Splunk Synthetic Monitoring which is very powerful.
“Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.”
Click on Advanced and make sure the Viewport Size is set to Default desktop: 1366 x 768
Click on “Test” to test your monitor. Once the test has successfully completed make sure to click on “AFTER” in Step 4 to validate the monitor was able to get to the order complete screenshot.
Click on Create{: .label-button .sfx-ui-button-blue} to save your Real Browser Monitor. After 5-10 minutes validate your monitor is working and producing successful checks e.g.
Tip You can force to run your monitor now using Run Now
Change your view to Segment by location and observe the difference. You can turn off/on locations by clicking on them.
!!! question “Question?” Which Location has the poorest Response Time?
Click on one of the successful circles to drill-down into that Run:
Take a moment to explore the metrics with the CONFIGURE METRICS/HIDE METRICS dropdown.
Click Page 2 in the dropdown, and scroll down to view the Filmstrip and the Waterfall Chart.
Click on Click Here to Analyze with Optimization which will prompt you to login to your Splunk Synthetic Monitoring Optimization Account. If you don’t have this option, navigate to this page.
Click the “Best Practices Score” tab. Scroll down, and review all the findings
Spend some time to review the findings. Click into any line item
4. Create Mobile Check Copy the RBC you created above:
Rename it, for example: RWC - Checkout Flow (Tablet)
Under the Advanced tab, update the following three settings and create your new mobile RBC.
Test \u0026 Validate the new monitor
Tip As you are creating the steps try using the Business Transaction feature in Splunk Synthetic Monitoring.
“Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.”
5. Resources Getting Started With Selenium IDE
Splunk Synthetic Monitoring Scripting Guide
How Can I Fix A Broken Script?
Introduction to the DOM (Document Object Model (DOM)
Selenium IDE
`,description:"",tags:null,title:"Real Browser Checks",uri:"/en/synthetics/real-browser-checks/index.html"},{content:` 5 minutes 1. Generate traffic The Online Boutique deployment contains a container running Locust that we can use to generate load traffic against the website to generate metrics, traces and spans.
Locust is available on port 82 of the EC2 instance’s IP address. Open a new tab in your web browser and go to http://\u003cec2-ip-address\u003e:82/, you will then be able to see the Locust running.
Set the Spawn rate to be 2 and click Start Swarming, this will start a gentle continous load on the application.
Now go to Dashboards → All Dashboards → APM Services → Service.
For this we need to know the name of your application environment. In this workshop all the environments use: \u003chostname\u003e-apm-env.
To find the hostname, on the AWS/EC2 instance run the following command:
Echo Hostname Output Example echo $(hostname)-apm-env bdzx-apm-env Select your environment you found in the previous step then select the frontend service and set time to Past 15 minutes.
With this automatically generated dashboard you can keep an eye out for the health of your service(s) using RED (Rate, Error \u0026 Duration) metrics. It provides various performance related charts as well as correlated information on the underlying host and Kubernetes pods (if applicable).
Take some time to explore the various charts in this dashboard
2. Verify Splunk APM metrics In the left hand menu card click on APM this will bring you to the APM Overview dashboard:
Select the Explore on the right hand side and select your environment you found before and set the time to 15 minutes. This will show you the automatically generated Dependency/Service Map for the Online Boutique application.
It should look similar to the screenshot below:
The legend at the bottom of the page explains the different visualizations in the Dependency/Service Map.
Service requests, error rate and root error rate. Request rate, latency and error rate Also in this view you can see the overall Error and Latency rates over time charts.
3. OpenTelemetry Dashboard Once the Open Telemetery Collector is deployed the platform will automatically provide a built in dashboard display OpenTelemetry Collector metrics.
From the top left hamburger menu Dashboards → OpenTelemetry Collector, scroll all the way to the bottom of the page and validate metrics and spans are being sent:
4. OpenTelemetry zpages To debug the traces being sent you can use the zpages extension. zpages are part of the OpenTelemetry collector and provide live data for troubleshooting and statistics. They are available on port 55679 of the EC2 instance’s IP address. Open a new tab in your web browser and enter in http://{==EC2-IP==}:55679/debug/tracez, you will then be able to see the zpages output.
Alternatively, from your shell prompt you can run a text based browser:
Lynx Command lynx http://localhost:55679/debug/tracez `,description:"",tags:null,title:"1.1 Generate load using Locust",uri:"/en/apm/online-boutique/locust/index.html"},{content:`Aim A rotation is a recurring schedule, that consists of one or more shifts, with members who rotate through a shift.
The aim of this module is for you to configure two example Rotations, and assign Team Members to the Rotations.
Navigate to the Rotations tab on the Teams sub menu, you should have no existing Rotations so we need to create some.
The 1st Rotation you will create is for a follow the sun support pattern where the members of each shift provide cover during their normal working hours within their time zone.
The 2nd will be a Rotation used to provide escalation support by more experienced senior members of the team, based on a 24/7, 1 week shift pattern.
1. Follow the Sun Support - Business Hours Click Add Rotation
Enter a name of “Follow the Sun Support - Business Hours” and Select Partial day from the three available shift templates.
Enter a Shift name of “Asia” Time Zone set to “Asia/Tokyo” Each user is on duty from “Monday through Friday from 9.00am to 5.00pm” Handoff happens every “5 days” The next handoff happens - Select the next Monday using the calendar Click Save Rotation You will now be prompted to add Members to this shift; add the Asia members who are Jim Halpert, Lydie Rodarte-Quayle and Marie Schrader, but only if you’re using the Splunk provided environment for this workshop.
If you’re using your own Organisation refer to the specific list provided separately.
Now add an 2nd shift for Europe by again clicking +Add a shift → Partial Day
Enter a Shift name of “Europe” Time Zone set to “Europe/London” Each user is on duty from “Monday through Friday from 9.00am to 5.00pm” Handoff happens every “5 days” The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the Europe members who are Duane Chow, Steven Gomez and Walter White, but only if you’re using the Observability Workshop Org for this workshop.
If you’re using your own Organisation refer to the specific list provided separately.
Now add a 3rd shift for West Coast USA by again clicking +Add a shift - Partial Day
Enter a Shift name of “West Coast” Time Zone set to “US/Pacific” Each user is on duty from “Monday through Friday from 9.00am to 5.00pm” Handoff happens every “5 days” The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the West Coast members who are Maximo Arciniega, Michael Scott and Tuco Salamanca, but only if you’re using the Observability Workshop Org for this workshop.
If you’re using your own Organisation refer to the specific list provided separately.
The first user added will be the ‘current’ user for that shift.
You can re-order the shifts by simply dragging the users up and down, and you can change the current user by clicking Set Current on an alternate user
You will now have three different Shift patterns, that provide cover 24hr hours, Mon - Fri, but with no cover at weekends.
We will now add another Rotation for our Senior SRE Escalation cover.
2. Senior SRE Escalation Click Add Rotation Enter a name of “Senior SRE Escalation” Select 24/7 from the three available shift templates Enter a Shift name of “Senior SRE Escalation” Time Zone set to “Asia/Tokyo” Handoff happens every “7 days at 9.00am” The next handoff happens [select the next Monday from the date picker] Click Save Rotation You will again be prompted to add Members to this shift; add the 24/7 members who are Jack Welker, Hank Schrader and Pam Beesly, but only if you’re using the Observability Workshop Org for this workshop.
If you’re using your own Organisation refer to the specific list provided separately.
Please wait for the instructor before proceeding to the Configuring Escalation Policies module.
`,description:"",tags:null,title:"Configure Rotations",uri:"/en/oncall/getting_started/rotations/index.html"},{content:`Tag Spotlight On the right hand side of the screen scroll down on Tag Spotlight, ensure Top Across All Indexed Tags is selected in the dropdown click the full screen button as indicated in the screenshot below.
The Tag Spotlight Page will be displayed. From this page you can view the top tags in your application and their corresponding error rates and request rates.
Note that for the version span tag it appears that version 350.10 has a 100% error rate and for our tenant.level span tag it shows that all three tenants (Gold, Silver \u0026 Bronze) have errors present.
The Tag Spotlight page is interactive and allows you to add a tag as a filter by simply clicking on your desired tag. Click on gold under tenant.level to add it as a filter. Once this is done the page will now only display data with gold as it’s tenant.level.
Tag Spotlight is very useful for analysing your data and spotting trends. We can see that for the Gold Tenant that out of the total number of requests, 55 of them are in error (this number will vary in your workshop).
If we correlate this to the version tag, we can see that version 350.10 served 55 requests and version 350.9 served 17 requests. This means that all of the requests that went through version 350.10 ended up in an error state.
In order to test this theory further that all of the requests from paymentservice version 350.10 result in an error, we can change our filter to another tenant by using the tag selector. Change your filter from gold tenant to silver tenant.
Now we can perform a similar analysis by looking at the number of requests in error for the silver tenant and correlating that with the version number. Note the amount of errors for the silver tenant match the amount of requests for version 350.10.
Tag Spotlight not only allows you to look at request and error rates but also at the latency per service. In order to do this just select the latency button and remove your Silver Tenant Tag so that you can see the latency for all of the Payment Service.
Go back to your service map by pressing the X button on the far right underneath Clear All.
Click anywhere on the pink line in the Services by Error Rate graph in the top right hand corner. Once selected you should see a list of example traces. Click on one of the example traces with an initiating operation of frontend: POST /cart/checkout.
`,description:"",tags:null,title:"1.2 Tag Spotlight",uri:"/en/other/o11y4rookies/apm/using-splunk-apm/tag_spotlight/index.html"},{content:`The API Check provides a flexible way to check the functionality and performance of API endpoints. The shift toward API-first development has magnified the necessity to monitor the back-end services that provide your core front-end functionality. Whether you’re interested in testing the multi-step API interactions or you want to gain visibility into the performance of your endpoints, the API Check can help you accomplish your goals.
1. Create a Global Variable View the global variable that we’ll use to perform our API check. Click on Global Variables under Admin Tools. View the global variable that we’ll use to make the spotify API transaction
2. Create an API Check Create a new API Check and name it \u003cyour initials\u003e followed by Splunk REST API Check for example: AP - Spotify API
Take a second to explore the notification tab after you’ve named your check
Add the following API Check Steps:
Available Variables to choose from:
Request Step
A Request Step makes an HTTP request to some endpoint and collects data from that interaction. Unlike other check types, API Checks do not require an initial URL to start the check. All HTTP requests are configured within Request Steps. Extract Step
An Extract Step extracts data out of JSON, XML, or HTML formatted data.
To extract data out of JSON, supply three things:
The source containing the JSON,
The JSONPath expression to extract out the data, and
The name of the custom variable that you want to save to.
The source can be any JSON, but most likely will come from the response body. The source could also come from a response header or can be a custom value. The source must be well-formed JSON.
Save Step
A Save Step stores some data to be reused later in the check. To save data, supply the source and the name of the custom variable to save to. The source can be selected from the presets, including response headers, or by providing a custom value.
Some additional use cases are appending bits of information to easily reuse in other steps and saving the results from one request to be reused after another request is made.
It is important to remember that request variables are only available after a request is made. If you try to save a value from a request but haven’t made a request yet, then an empty string will be saved.
Assert Step
An Assert Step makes an assertion on two values. To make an assertion, supply two parameters along with the comparison that you would like to perform between the two. Comparisons
We currently support 3 types of comparisons: string, numeric, and regular expression.
For string and numeric comparisons, values are coerced to the comparison type before the comparison is made.
For a regular expression comparison, the first parameter is a string and the second parameter is a regular expression.
Tag your API Check with Splunk and API and SAVE it
3. Test your REST API Check Press got back into the edit configuration and press ’test’ at the bottom of the page to ensure there are no errors
Slide the window up to view details about the successful run
Now, let’s add some more functionality to the monitor. Slide the detailed window back down and add steps 5-8
BONUS: use step 6 to assert that the following response came back in a timely manner (1000 ms)
Once the steps are added, test \u0026 save the monitor.
4. Resources How to Create an API Check
API Check Overview
How Do I Use Business Transactions?
`,description:"",tags:null,title:"API Checks",uri:"/en/other/o11y4rookies/synthetics/api-checks/index.html"},{content:`The API Check provides a flexible way to check the functionality and performance of API endpoints. The shift toward API-first development has magnified the necessity to monitor the back-end services that provide your core front-end functionality. Whether you’re interested in testing the multi-step API interactions or you want to gain visibility into the performance of your endpoints, the API Check can help you accomplish your goals.
1. Create a Global Variable View the global variable that we’ll use to perform our API check. Click on Global Variables under Admin Tools. View the global variable that we’ll use to make the spotify API transaction
2. Create an API Check Create a new API Check and name it \u003cyour initials\u003e followed by Splunk REST API Check for example: AP - Spotify API
Take a second to explore the notification tab after you’ve named your check
Add the following API Check Steps:
Available Variables to choose from:
Request Step
A Request Step makes an HTTP request to some endpoint and collects data from that interaction. Unlike other check types, API Checks do not require an initial URL to start the check. All HTTP requests are configured within Request Steps. Extract Step
An Extract Step extracts data out of JSON, XML, or HTML formatted data.
To extract data out of JSON, supply three things:
The source containing the JSON,
The JSONPath expression to extract out the data, and
The name of the custom variable that you want to save to.
The source can be any JSON, but most likely will come from the response body. The source could also come from a response header or can be a custom value. The source must be well-formed JSON.
Save Step
A Save Step stores some data to be reused later in the check. To save data, supply the source and the name of the custom variable to save to. The source can be selected from the presets, including response headers, or by providing a custom value.
Some additional use cases are appending bits of information to easily reuse in other steps and saving the results from one request to be reused after another request is made.
It is important to remember that request variables are only available after a request is made. If you try to save a value from a request but haven’t made a request yet, then an empty string will be saved.
Assert Step
An Assert Step makes an assertion on two values. To make an assertion, supply two parameters along with the comparison that you would like to perform between the two. Comparisons
We currently support 3 types of comparisons: string, numeric, and regular expression.
For string and numeric comparisons, values are coerced to the comparison type before the comparison is made.
For a regular expression comparison, the first parameter is a string and the second parameter is a regular expression.
Tag your API Check with Splunk and API and SAVE it
3. Test your REST API Check Press got back into the edit configuration and press ’test’ at the bottom of the page to ensure there are no errors
Slide the window up to view details about the successful run
Now, let’s add some more functionality to the monitor. Slide the detailed window back down and add steps 5-8
BONUS: use step 6 to assert that the following response came back in a timely manner (1000 ms)
Once the steps are added, test \u0026 save the monitor.
4. Resources How to Create an API Check
API Check Overview
How Do I Use Business Transactions?
`,description:"",tags:null,title:"API Checks",uri:"/en/synthetics/api-checks/index.html"},{content:`Auto-Instrumentation Navigate to the auto directory that contains auto-instrumentation code.
Command cd ~/o11y-lambda-lab/auto Inspect the contents of the files in this directory. Take a look at the serverless.yml template.
Command cat serverless.yml Workshop Question Can you identify which AWS entities are being created by this template? Can you identify where OpenTelemetry instrumentation is being set up? Can you determine which instrumentation information is being provided by the Environment Variables? You should see the Splunk OpenTelemetry Lambda layer being added to each fuction.
layers: - arn:aws:lambda:us-east-1:254067382080:layer:splunk-apm:70 You can see the relevant layer ARNs (Amazon Resource Name) and latest versions for each AWS region here: https://github.com/signalfx/lambda-layer-versions/blob/main/splunk-apm/splunk-apm.md
You should also see a section where the Environment variables that are being set.
environment: AWS_LAMBDA_EXEC_WRAPPER: /opt/nodejs-otel-handler OTEL_RESOURCE_ATTRIBUTES: deployment.environment=\${self:custom.prefix}-apm-lambda OTEL_SERVICE_NAME: consumer-lambda SPLUNK_ACCESS_TOKEN: \${self:custom.accessToken} SPLUNK_REALM: \${self:custom.realm} Using the environment variables we are configuring and enriching our auto-instrumentation.
Here we provide minimum information, such as NodeJS wrapper location in the Splunk APM Layer, environment name, service name, and our Splunk Org credentials. We are sending trace data directly to Splunk Observability Cloud. You could alternatively export traces to an OpenTelemetry Collector set up in Gateway mode.
Take a look at the function code.
Command cat handler.js Workshop Question Can you identify the code for producer function? Can you identify the code for consumer function? Notice there is no mention of Splunk or OpenTelemetry in the code. We are adding the instrumentation using the Lambda layer and Environment Variables only.
Deploy your Lambdas Run the following command to deploy your Lambda Functions:
Deploy Command Expected Output sls deploy Deploying hostname-lambda-lab to stage dev (us-east-1) ... ... endpoint: POST - https://randomstring.execute-api.us-east-1.amazonaws.com/dev/producer functions: producer: hostname-lambda-lab-dev-producer (1.6 kB) consumer: hostname-lambda-lab-dev-consumer (1.6 kB) This command will follow the instructions in your serverless.yml template to create your Lambda functions and your Kinesis stream. Note it may take a 1-2 minutes to execute.
Note serverless.yml is in fact a CloudFormation template. CloudFormation is an infrastructure as code service from AWS. You can read more about it here - https://aws.amazon.com/cloudformation/ Check the details of your serverless functions:
Command sls info Take note of your endpoint value: Send some Traffic Use the curl command to send a payload to your producer function. Note the command option -d is followed by your message payload.
Try changing the value of name to your name and telling the Lambda function about your superpower. Replace YOUR_ENDPOINT with the endpoint from your previous step.
Command curl -d '{ "name": "CHANGE_ME", "superpower": "CHANGE_ME" }' YOUR_ENDPOINT For example:
curl -d '{ "name": "Kate", "superpower": "Distributed Tracing" }' https://xvq043lj45.execute-api.us-east-1.amazonaws.com/dev/producer You should see the following output if your message is successful:
{"message":"Message placed in the Event Stream: hostname-eventSteam"} If unsuccessful, you will see:
{"message": "Internal server error"} If this occurs, ask one of the lab facilitators for assistance.
If you see a success message, generate more load: re-send that messate 5+ times. You should keep seeing a success message after each send.
Check the lambda logs output:
Producer function logs:
Producer Function Logs sls logs -f producer Consumer function logs:
Consumer Function Logs sls logs -f consumer Examine the logs carefully.
Workshop Question Do you see OpenTelemetry being loaded? Look out for lines with splunk-extension-wrapper.
`,description:"",tags:null,title:"Auto-Instrumentation",uri:"/en/other/lambda-kinesis/2-auto-instrumentation/index.html"},{content:` 20 minutes Introduction to the Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Saving charts in a dashboard Introduction to SignalFlow 1. Dashboards Dashboards are groupings of charts and visualizations of metrics. Well-designed dashboards can provide useful and actionable insight into your system at a glance. Dashboards can be complex or contain just a few charts that drill down only into the data you want to see.
During this module we are going to create the following charts and dashboard and connect it to your Team page.
2. Your Teams’ Page Click on the from the navbar. As you have already been assigned to a team, you will land on the team dashboard.
We use the Example Team as an example here. The one in your workshop will be different!
This page shows the total number of team members, how many active alerts for your team and all dashboards that are assigned to your team. Right now they are no dashboards assigned but as stated before, we will add the new dashboard that you will create to your Teams page later.
3. Sample Charts To continue, click on All Dashboards on the top right corner of the screen. This brings you to the view that shows all the available dashboards, including the pre-built ones.
If you are already receiving metrics from a Cloud API integration or another service through the Splunk Agent you will see relevant dashboards for these services.
4. Inspecting the Sample Data Among the dashboards you will see a Dashboard group called Sample Data. Expand the Sample Data dashboard group by clicking on it, and then click on the Sample Charts dashboard.
In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.
Have a look through all the dashboards in this dashboard group (PART 1, PART 2, PART 3 and INTRO TO SPLUNK OBSERVABILITY CLOUD)
`,description:"",tags:null,title:"Working with Dashboards",uri:"/en/other/o11y4rookies/imt/dashboards/index.html"},{content:`Objective: Learn how to efficiently deploy complex infrastructure components such as Kafka and MongoDB to demonstrate metrics collection with Splunk O11y IM integrations
Duration: 15 Minutes
Scenario A prospect uses Kafka and MongoDB in their environment. Since there are integrations for these services, you’d like to demonstrate this to the prospect. What is a quick and efficient way to set up a live environment with these services and have metrics collected?
1. Where can I find helm charts? Google “myservice helm chart” https://artifacthub.io/ (Note: Look for charts from trusted organizations, with high star count and frequent updates) 2. Review Apache Kafka packaged by Bitnami We will deploy the helm chart with these options enabled:
replicaCount=3 metrics.jmx.enabled=true metrics.kafka.enabled=true deleteTopicEnable=true 3. Review MongoDB(R) packaged by Bitnami We will deploy the helm chart with these options enabled:
version 12.1.31 metrics.enabled=true global.namespaceOverride=default auth.rootUser=root auth.rootPassword=splunk auth.enabled=false 4. Install Kafka and MongoDB with helm charts helm repo add bitnami https://charts.bitnami.com/bitnami helm install kafka --set replicaCount=3 --set metrics.jmx.enabled=true --set metrics.kafka.enabled=true --set deleteTopicEnable=true bitnami/kafka helm install mongodb --set metrics.enabled=true bitnami/mongodb --set global.namespaceOverride=default --set auth.rootUser=root --set auth.rootPassword=splunk --set auth.enabled=false --version 12.1.31 Verify the helm chart installation
helm list helm list output helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION kafka default 1 2022-11-14 11:21:36.328956822 -0800 PST deployed kafka-19.1.3 3.3.1 mongodb default 1 2022-11-14 11:19:36.507690487 -0800 PST deployed mongodb-12.1.31 5.0.10 Verify the helm chart installation
kubectl get pods kubectl get pods Output kubectl get pods NAME READY STATUS RESTARTS AGE kafka-exporter-595778d7b4-99ztt 0/1 ContainerCreating 0 17s mongodb-b7c968dbd-jxvsj 0/2 Pending 0 6s kafka-1 0/2 ContainerCreating 0 16s kafka-2 0/2 ContainerCreating 0 16s kafka-zookeeper-0 0/1 Pending 0 17s kafka-0 0/2 Pending 0 17s Use information for each Helm chart and Splunk O11y Data Setup to generate values.yaml for capturing metrics from Kafka and MongoDB.
Note values.yaml for the different services will be passed to the Splunk Helm Chart at installation time. These will configure the OTEL collector to capture metrics from these services.
References: Apache Kafka packaged by Bitnami Configure application receivers for databases » Apache Kafka Kafkametricsreceiver 4.1 Example kafka.values.yaml otelAgent: config: receivers: receiver_creator: receivers: smartagent/kafka: rule: type == "pod" \u0026\u0026 name matches "kafka" config: #endpoint: '\`endpoint\`:5555' port: 5555 type: collectd/kafka clusterName: sl-kafka otelK8sClusterReceiver: k8sEventsEnabled: true config: receivers: kafkametrics: brokers: kafka:9092 protocol_version: 2.0.0 scrapers: - brokers - topics - consumers service: pipelines: metrics: receivers: #- prometheus - k8s_cluster - kafkametrics 4.2 Example mongodb.values.yaml otelAgent: config: receivers: receiver_creator: receivers: smartagent/mongodb: rule: type == "pod" \u0026\u0026 name matches "mongo" config: type: collectd/mongodb host: mongodb.default.svc.cluster.local port: 27017 databases: ["admin", "O11y", "local", "config"] sendCollectionMetrics: true sendCollectionTopMetrics: true 4.3 Example zookeeper.values.yaml otelAgent: config: receivers: receiver_creator: receivers: smartagent/zookeeper: rule: type == "pod" \u0026\u0026 name matches "kafka-zookeeper" config: type: collectd/zookeeper host: kafka-zookeeper port: 2181 5. Install the Splunk OTEL helm chart cd /home/ubuntu/realtime_enrichment/otel_yamls/ helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart helm repo update helm install --set provider=' ' --set distro=' ' --set splunkObservability.accessToken=$ACCESS_TOKEN --set clusterName=$clusterName --set splunkObservability.realm=$REALM --set otelCollector.enabled='false' --set splunkObservability.logsEnabled='true' --set gateway.enabled='false' --values kafka.values.yaml --values mongodb.values.yaml --values zookeeper.values.yaml --values alwayson.values.yaml --values k3slogs.yaml --generate-name splunk-otel-collector-chart/splunk-otel-collector 6. Verify installation Verify that the Kafka, MongoDB and Splunk OTEL Collector helm charts are installed, note that names may differ.
helm list helm list Output helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION kafka default 1 2021-12-07 12:48:47.066421971 -0800 PST deployed kafka-14.4.1 2.8.1 mongodb default 1 2021-12-07 12:49:06.132771625 -0800 PST deployed mongodb-10.29.2 4.4.10 splunk-otel-collector-1638910184 default 1 2021-12-07 12:49:45.694013749 -0800 PST deployed splunk-otel-collector-0.37.1 0.37.1 kubectl get pods kubectl get pods Output kubectl get pods NAME READY STATUS RESTARTS AGE kafka-zookeeper-0 1/1 Running 0 18m kafka-2 2/2 Running 1 18m mongodb-79cf87987f-gsms8 2/2 Running 0 18m kafka-1 2/2 Running 1 18m kafka-exporter-7c65fcd646-dvmtv 1/1 Running 3 18m kafka-0 2/2 Running 1 18m splunk-otel-collector-1638910184-agent-27s5c 2/2 Running 0 17m splunk-otel-collector-1638910184-k8s-cluster-receiver-8587qmh9l 1/1 Running 0 17m 7. Verify dashboards Verify that out of the box dashboards for Kafka, MongoDB and Zookeeper are populated in the Infrastructure Monitor landing page. Drill down into each component to view granular details for each service.
Tip: You can use the filter k8s.cluster.name with your cluster name to find your instance.
Infrastructure Monitoring Landing page: K8 Navigator: MongoDB Dashboard: Kafka Dashboard: `,description:"",tags:null,title:"Deploy Complex Environments and Capture Metrics",uri:"/en/other/gdi/2-deploy/index.html"},{content:`Extensions are available primarily for tasks that do not involve processing telemetry data. Examples of extensions include health monitoring, service discovery, and data forwarding. Extensions are optional.
Let’s edit the config.yaml file and configure the extensions. Note that the pprof and zpages extensions are already configured in the default config.yaml file. We will only be updating the health_check extension.
sudo vi /etc/otelcol-contrib/config.yaml Extensions Configuration Extensions Configuration Complete extensions: health_check: endpoint: 0.0.0.0:13133 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] Restart the collector:
sudo systemctl restart otelcol-contrib Health Check This extension enables an HTTP url that can be probed to check the status of the OpenTelemetry Collector. This extension can be used as a liveness and/or readiness probe on Kubernetes. To learn more about the curl command, check out the curl man page.
Command Status Output curl http://localhost:13133 {"status":"Server available","upSince":"2023-04-27T10:11:22.153295874+01:00","uptime":"16m24.684476004s"} Performance Profiler Performance Profiler extension enables the golang net/http/pprof endpoint. This is typically used by developers to collect performance profiles and investigate issues with the service.
zPages zPages are an in-process alternative to external exporters. When included, they collect and aggregate tracing and metrics information in the background; this data is served on web pages when requested.
Tip Install a text-based web browser (or use your local browser using the instance IP address)
sudo apt update \u0026\u0026 sudo apt install lynx -y ServiceZ gives an overview of the collector services and quick access to the pipelinez, extensionz, and featurez zPages. The page also provides build and runtime information.
Example URL: http://localhost:55679/debug/servicez
PipelineZ brings insight on the running pipelines running in the collector. You can find information on type, if data is mutated and the receivers, processors and exporters that are used for each pipeline.
Example URL: http://localhost:55679/debug/pipelinez
ExtensionZ shows the extensions that are active in the collector.
Example URL: http://localhost:55679/debug/extensionz
`,description:"",tags:null,title:"OpenTelemetry Collector Extensions",uri:"/en/conf/opentelemetry-collector/2-extensions/index.html"},{content:` 15 minutes Use the Splunk Helm chart to install the OpenTelemetry Collector in K3s Explore your cluster in the Kubernetes Navigator 1. Obtain Access Token You will need to obtain your Access Token1 from the Splunk UI. You can find the workshop Access Token by clicking » bottom left and then selecting Settings → Access Tokens.
Expand the workshop token that your host has instructed you to use e.g. O11y-Workshop-ACCESS, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. Please do not use the Default token!
Please do not attempt to create your own token We have created a Token specifically for this workshop with the appropriate settings for the exercises you will be performing so have allocated it both Ingest and API Permissions. Best practice in production is to only allocate a single permission to a Token such as Ingest OR API OR RUM and use multiple Tokens where required.
You will also need to obtain the name of the Realm2 for your Splunk account. At the top of the side menu, click on your name. This will direct you to the Account Settings Page. Click the Organizations-tab. The Realm can be found at the top of the displayed information in the tab. In this example it is eu0.
2. Installation using Helm Create the ACCESS_TOKEN and REALM environment variables to use in the proceeding Helm install command. For instance, if your realm is us1, you would type export REALM=us1 and for eu0 type export REALM=eu0.
Export ACCESS TOKEN export ACCESS_TOKEN="\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e" Export REALM export REALM="\u003creplace_with_REALM\u003e" Install the OpenTelemetry Collector using the Splunk Helm chart. First, add the Splunk Helm chart repository to Helm and update.
Helm Repo Add Helm Repo Add Output helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 “splunk-otel-collector-chart” has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories… …Successfully got an update from the “splunk-otel-collector-chart” chart repository Update Complete. ⎈Happy Helming!⎈
Install the OpenTelemetry Collector Helm chart with the following commands, do NOT edit this:
Helm Install Helm Install Output Install Network Explorer helm install splunk-otel-collector \\ --set="splunkObservability.realm=$REALM" \\ --set="splunkObservability.accessToken=$ACCESS_TOKEN" \\ --set="clusterName=$(hostname)-k3s-cluster" \\ --set="splunkObservability.logsEnabled=true" \\ --set="splunkObservability.profilingEnabled=true" \\ --set="splunkObservability.infrastructureMonitoringEventsEnabled=true" \\ --set="environment=$(hostname)-apm-env" \\ splunk-otel-collector-chart/splunk-otel-collector \\ -f ~/workshop/k3s/otel-collector.yaml Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 NAME: splunk-otel-collector LAST DEPLOYED: Fri May 7 11:19:01 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None helm install splunk-otel-collector \\ --set="splunkObservability.realm=$REALM" \\ --set="splunkObservability.accessToken=$ACCESS_TOKEN" \\ --set="clusterName=$(hostname)-k3s-cluster" \\ --set="splunkObservability.logsEnabled=true" \\ --set="splunkObservability.infrastructureMonitoringEventsEnabled=true" \\ --set="networkExplorer.enabled=true" \\ --set="networkExplorer.podSecurityPolicy.enabled=false" \\ --set="agent.enabled=true" \\ --set="gateway.replicaCount=1" \\ --set="gateway.resources.limits.cpu=500m" \\ --set="gateway.resources.limits.memory=1Gi" \\ --set="clusterReceiver.enabled=true" \\ --set="environment=$(hostname)-apm-env" \\ splunk-otel-collector-chart/splunk-otel-collector \\ -f ~/workshop/k3s/otel-collector.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds.
Ensure the status is reported as Running before continuing.
Kubectl Get Pods Kubectl Get Pods Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-2sk6k 0/1 Running 0 10s splunk-otel-collector-k8s-cluster-receiver-6956d4446f-gwnd7 0/1 Running 0 10s Ensure there are no errors by tailing the logs from the OpenTelemetry Collector pod. Output should look similar to the log output shown in the Output tab below.
Use the label set by the helm install to tail logs (You will need to press ctrl+c to exit). Or use the installed k9s terminal UI for bonus points!
Kubectl Logs Kubectl Logs Output kubectl logs -l app=splunk-otel-collector -f --container otel-collector 2021-03-21T16:11:10.900Z INFO service/service.go:364 Starting receivers… 2021-03-21T16:11:10.900Z INFO builder/receivers_builder.go:70 Receiver is starting… {“component_kind”: “receiver”, “component_type”: “prometheus”, “component_name”: “prometheus”} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {“component_kind”: “receiver”, “component_type”: “prometheus”, “component_name”: “prometheus”} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:70 Receiver is starting… {“component_kind”: “receiver”, “component_type”: “k8s_cluster”, “component_name”: “k8s_cluster”} 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/watcher.go:195 Configured Kubernetes MetadataExporter {“component_kind”: “receiver”, “component_type”: “k8s_cluster”, “component_name”: “k8s_cluster”, “exporter_name”: “signalfx”} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {“component_kind”: “receiver”, “component_type”: “k8s_cluster”, “component_name”: “k8s_cluster”} 2021-03-21T16:11:11.009Z INFO healthcheck/handler.go:128 Health Check state change {“component_kind”: “extension”, “component_type”: “health_check”, “component_name”: “health_check”, “status”: “ready”} 2021-03-21T16:11:11.009Z INFO service/service.go:267 Everything is ready. Begin running and processing data. 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/receiver.go:59 Starting shared informers and wait for initial cache sync. {“component_kind”: “receiver”, “component_type”: “k8s_cluster”, “component_name”: “k8s_cluster”} 2021-03-21T16:11:11.281Z INFO k8sclusterreceiver@v0.21.0/receiver.go:75 Completed syncing shared informer caches. {“component_kind”: “receiver”, “component_type”: “k8s_cluster”, “component_name”: “k8s_cluster”}
Deleting a failed installation If you make an error installing the OpenTelemetry Collector you can start over by deleting the installation using:
helm delete splunk-otel-collector 3. Validate metrics in the UI In the Splunk UI, click the » bottom left and click on Infrastructure.
Under Containers click on Kubernetes to open the Kubernetes Navigator Cluster Map to ensure metrics are being sent in.
Validate that your cluster is discovered and reporting by finding your cluster (in the workshop you will see many other clusters). To find your cluster name run the following command and copy the output to your clipboard:
Echo Cluster Name echo $(hostname)-k3s-cluster Then in the UI, click on the “Cluster: - " menu just below the Splunk Logo, and paste the Cluster name you just copied into the search box, click the box to select your cluster, and finally click off the menu into white space to apply the filter.
To examine the health of your node, hover over the pale blue background of your cluster, then click on the blue magnifying glass that appears in the top left hand corner.
This will drill down to the node level. Next, open the side bar by clicking on the side bar button to open the Metrics side bar.
Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: CPU, Memory, Network, Events etc.
Access Tokens (sometimes called Org Tokens) are long-lived organization-level tokens. By default, these tokens persist for 5 years, and thus are suitable for embedding into emitters that send data points over long periods of time, or for any long-running scripts that call the Splunk API. ↩︎
A realm is a self-contained deployment of Splunk in which your Organization is hosted. Different realms have different API endpoints (e.g. the endpoint for sending data is ingest.us1.signalfx.com for the us1 realm, and ingest.eu0.signalfx.com for the eu0 realm). This realm name is shown on your profile page in the Splunk UI. If you do not include the realm name when specifying an endpoint, Splunk will interpret it as pointing to the us0 realm. ↩︎
`,description:"",tags:null,title:"Deploying the OpenTelemetry Collector in Kubernetes",uri:"/en/imt/gdi/index.html"},{content:`1. Cluster vs Workload View The Kubernetes Navigator offers you two separate use cases to view your Kubernetes data.
The K8s workloads is focusing on providing information in regards to workloads a.k.a. your deployments. The K8s nodes is focusing on providing insight into the performance of clusters, nodes, pods and containers. You will initially select either view depending on your need (you can switch between the view on the fly if required). The most common one we will use in this workshop is the workload view and we will focus on that specifically.
1.1 Finding your K8s Cluster name Your first task is to identify and find your own cluster. The cluster will be named after your EC2 instance name.
To confirm your EC2 instance name, look at the prompt of your EC2 instance. For example, if you are assigned the 7th EC2 instance, the prompt will show:
ubuntu@emea-ws-7 ~ $ This means your cluster will be named: emea-ws-7-k3s-cluster. Please make a note of your cluster name as you will need this later in the workshop for filtering.
2. Workloads \u0026 Workload Details Pane Go to the Infrastructure page in the Observability UI and select Kubernetes, this will offer you a set of Kubernetes services, one of them being the K8s workloads pane.
The pane will show a tiny graph giving you a bird’s eye view of the load being handled across those Workloads. Also, if there are any alerts for one of the workloads, you will see a small alert indicator as shown in the image below.
Click on the K8s workloads pane and you will be taken to the workload view.
Initially, you will see all the workloads for all clusters that are reported into your Observability Cloud Org. If an alert has fired for any of the workloads, it will be highlighted on the top right (as marked with a red stripe) in the image below. You can go directly to the alert by clicking it to expand it.
Now, let’s find your own cluster by filtering on the field k8s.cluster.name in the filter toolbar (as marked with a blue stripe).
Note You can enter a partial name into the search box, such as ’emea-ws-7*’, to quickly find your Cluster.
Also, it’s a very good idea to switch the default time from the default -3h back to last 15 minutes (-15m).
You should now just see information for your own cluster.
Workshop Question How many workloads are running \u0026 how many namespaces are in your Cluster?
2.1 Using the Navigator Selection chart The K8s workloads table is a common feature used across most of the Navigator’s and will offer you a list view of the data you are viewing. In our case, it shows a list of Pods Failed grouped by k8s.namespace.name.
Now let’s change the list view to a heat map view by selecting either the Heat map icon or List icon in the upper-right corner of the screen (as marked with the purple line).
Changing this option will result in the following visualisation:
In this view, you will note that each workload is now a colored square. These squares will change color according to the Color by option you selected, as marked by the first green line in the image above. The colors give a visual indication of health and/or usage. You can check the meaning by hovering over the legend exclamation icon bottom right of the heatmaps.
Another valuable option in this screen is Find Outliers which provides historical analytics of your clusters based on what is selected in the Color by dropdown.
Now, let’s select the File system usage (bytes) from the Color by drop down box, then click on the Find outliers drop down as marked by a yellow line in the above image and make sure you change the Scope in the dialog to Per k8s.namespace.name and Deviation from Median as below:
The Find outliers view is very useful when you need to view a selection of your workloads (or any service depending on the Navigator used) and quickly need to figure out if something has changed.
It will give you fast insight into items (workloads in our case) that are performing differently (both increased or decreased) which helps to make it easier to spot problems.
2.2 The Deployment overview pane The Deployment overview pane gives you a quick insight of the status of your deployments. You can see at once if the pods of your deployments are Pending, Running, Succeeded, Failed or in an Unknown state.
Running: Pod is deployed and in a running state Pending: Waiting to be deployed Succeeded: Pod has been deployed and completed its job and is finished Failed: Containers in the pod have run and returned some kind of error Unknown: Kubernetes isn’t reporting any of the known states. (This may be during the starting or stopping of pods, for example). You can expand the Workload name by hovering your mouse on it, in case the name is longer than the chart allows.
To filter to a specific workload, you can click on three dots … next to the workload name in the k8s.workload.name column and choose Filter from the dropdown box.
This will add the selected workload to your filters. Try this for the splunk-otel-collector-k8s-cluster-receiver workload. It will then list a single workload in the splunk namespace.
The Heat map above will also filter down to a single coloured square. Click on the square to see more information about the workload.
Workshop Question What are the CPU request \u0026 CPU limit units for the otel-collector?
At this point you can drill into the information of the pods, but that is outside the scope of this workshop, for now reset your view by removing the filter for the splunk-otel-collector-k8s-cluster-receiver workload and setting the Color by option to Pods Running.
3. Navigator Sidebar Later in the workshop, you will deploy an Apache server into your cluster which will display an icon in the Navigator Sidebar.
In navigators for Kubernetes, you can track dependent services and containers in the navigator sidebar. To get the most out of the navigator sidebar you configure the services you want to track by configuring an extra dimension called service.name. For this workshop, we have already configured the extraDimensions in the collector configuration for monitoring Apache e.g.
extraDimensions: service.name: php-apache The Navigator Sidebar will expand and a link to the discovered service will be added as seen in the image below:
This will allow for easy switching between Navigators. The same applies for your Apache server instance, it will have a Navigator Sidebar allowing you to quickly jump back to the Kubernetes Navigator.
`,description:"",tags:null,title:"Tour of the Kubernetes Navigator v2",uri:"/en/other/hpa/2-check-new-navigator-short/index.html"},{content:`Environment Setup - Application Clone the workshop repository: git clone -b tko-fy24-distributed-tracing https://github.com/shabuhabs/javashop-otel.git Access the workshop directory: cd javashop-otel Set Environment Variables nano .env Note NO spaces in \u003cyour_name\u003e The shop_user provides us an Environment Tag. To get your access token, go to your Splunk O11y UI -\u003e Settings -\u003eAccess Tokens. It is assumed in this workshop that you can send traces to the org and token you are using. Set the following values: SHOP_USER=\u003cyour_name\u003e SPLUNK_ACCESS_TOKEN=\u003cyour_token\u003e SPLUNK_REALM=\u003cyour_realm\u003e Save in nano with [CTRL]-o [ENTER] Exit nano with [CTRL]-x Build and Deploy Application Let’s get started by building and deploying our Application, the Splunk Instrument Shop. Run the commands below to begin and start reading ahead as your traces are coming up!
Build the app ./BuildAndDeploy.sh `,description:"",tags:null,title:"Setting up your Application",uri:"/en/other/dev-mttr-custom-tags/2-setup-app/index.html"},{content:` Find the Web address of your workshop hosts Online Boutique Generate traffic by shopping for bargains on your workshop hosted Online Boutique web shop. 1. URL of RUM enabled Online Boutique As discussed in the previous section we are going to use an Online Boutique running on a RUM host. If you’re participating in a RUM only workshop, after you have received the RUM instance URL, you can continue to Section 4: Using the Online Boutique to generate load on your system as the system your going to use is already prepared.
2. Obtain RUM Access Token As part of the overall workshop you have installed services for the APM Workshop. We are now going to add the RUM capability to the deployment as well.
The first thing we need to do is obtain a RUM_ACCESS_TOKEN with a RUM Authorization scope. You can find the workshop RUM Access Token by clicking on the Settings Cog menu button and then selecting Access Tokens.
Expand the RUM workshop token that your host has instructed you to use e.g. O11y-Workshop-RUM-TOKEN, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. Please do not use the Default token! Make sure the token has RUM as its Authorization Scope.
Please do not attempt to create your own token We have created a RUM Token specifically for this workshop with the appropriate settings for the exercises you will be performing
Create the RUM_TOKEN environment variable to use in the proceeding shell script to personalize your deployment.
Export Variables export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e 3. Deploy RUM based Online Boutique To deploy the Online Boutique application into your EC2 instance kubernetes (K3s) installation delete the original deployment, then run the apm config script for RUM, then apply the RUM deployment:
Deploy Online Boutique with RUM Partial Deployment Output cd ~/workshop/apm kubectl delete -f deployment.yaml ./apm-config.sh -r kubectl apply -f deployment.yaml ...... Adding RUM_TOKEN to deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created In case of a message about a VARIABLE being unset Please undeploy the APM environment by running kubectl delete -f deployment.yaml
Before exporting the variable as described in the guide and rerunning the deployment script above.
4. Using the Online Boutique to generate load on your system We are all connected to an Online Boutique, together with some synthetic users who are also shopping for this session. This will create more traffic from multiple locations, making the data more realistic.
You should have received the correct URL from your workshop host at this point. Open a new web browser and go to http://{==RUM-HOST-EC2-IP==}:81/ where you will then be able to see the RUM enabled Online Boutique running.
5. Generate traffic The goal of this exercise is for you to browse the RUM enabled Online Boutique and buy different products and different quantities. For extra credit, you may even use the url from different browsers or from your smartphone.
This will create multiple sessions to investigate. Take your time to examine and buy the various products and put them in your cart:
Doesn’t that HOME BARISTA KIT look tempting?… Your time to start shopping now!
`,description:"",tags:null,title:"2. Showcase of RUM with the Online Boutique",uri:"/en/other/o11y4rookies/rum/2-showcase/index.html"},{content:` Find the Web address of your workshop hosts Online Boutique Generate traffic by shopping for bargains on your workshop hosted Online Boutique web shop. 1. URL of RUM enabled Online Boutique As discussed in the previous section we are going to use an Online Boutique running on a RUM host. If you’re participating in a RUM only workshop, after you have received the RUM instance URL, you can continue to Section 4: Using the Online Boutique to generate load on your system as the system your going to use is already prepared.
2. Obtain RUM Access Token As part of the overall workshop you have installed services for the APM Workshop. We are now going to add the RUM capability to the deployment as well.
The first thing we need to do is obtain a RUM_ACCESS_TOKEN with a RUM Authorization scope. You can find the workshop RUM Access Token by clicking on the Settings Cog menu button and then selecting Access Tokens.
Expand the RUM workshop token that your host has instructed you to use e.g. O11y-Workshop-RUM-TOKEN, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. Please do not use the Default token! Make sure the token has RUM as its Authorization Scope.
Please do not attempt to create your own token We have created a RUM Token specifically for this workshop with the appropriate settings for the exercises you will be performing
Create the RUM_TOKEN environment variable to use in the proceeding shell script to personalize your deployment.
Export Variables export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e 3. Deploy RUM based Online Boutique To deploy the Online Boutique application into your EC2 instance kubernetes (K3s) installation delete the original deployment, then run the apm config script for RUM, then apply the RUM deployment:
Deploy Online Boutique with RUM Partial Deployment Output cd ~/workshop/apm kubectl delete -f deployment.yaml ./apm-config.sh -r kubectl apply -f deployment.yaml ...... Adding RUM_TOKEN to deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created In case of a message about a VARIABLE being unset Please undeploy the APM environment by running kubectl delete -f deployment.yaml
Before exporting the variable as described in the guide and rerunning the deployment script above.
4. Using the Online Boutique to generate load on your system We are all connected to an Online Boutique, together with some synthetic users who are also shopping for this session. This will create more traffic from multiple locations, making the data more realistic.
You should have received the correct URL from your workshop host at this point. Open a new web browser and go to http://{==RUM-HOST-EC2-IP==}:81/ where you will then be able to see the RUM enabled Online Boutique running.
5. Generate traffic The goal of this exercise is for you to browse the RUM enabled Online Boutique and buy different products and different quantities. For extra credit, you may even use the url from different browsers or from your smartphone.
This will create multiple sessions to investigate. Take your time to examine and buy the various products and put them in your cart:
Doesn’t that HOME BARISTA KIT look tempting?… Your time to start shopping now!
`,description:"",tags:null,title:"2. Showcase of RUM with the Online Boutique",uri:"/en/rum/2-showcase/index.html"},{content:`1. Spring PetClinic Application First thing we need to setup APM is… well, an application. For this exercise, we will use the Spring PetClinic application. This is a very popular sample java application built with Spring framework (Springboot).
Next we will clone the PetClinic repository, then we will compile, build, package and test the application.
git clone https://github.com/spring-projects/spring-petclinic Change into the spring-petclinic directory:
cd spring-petclinic \u0026\u0026 git checkout 276880e Start a MySQL database for PetClinic to use:
docker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/mysql:5.7.8 Next, run the maven command to compile/build/package PetClinic:
./mvnw package -Dmaven.test.skip=true Note This will take a few minutes the first time you run, maven will download a lot of dependencies before it actually compiles the application. Future executions will be a lot shorter.
Once the compilation is complete, you can run the application with the following command:
java \\ -Dotel.service.name=$(hostname)-petclinic-service \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql If you check the logs of the Splunk OpenTelemetry collector you will see that the collector automatically detected the application running and auto-instrumented it. You can view the logs using the following command:
sudo tail -f /var/log/syslog You can validate if the application is running by visiting http://\u003cVM_IP_ADDRESS\u003e:8080.
Once your validation is complete you can stop the application by pressing Ctrl-c.
2. Generating Traffic Next we will start a Docker container running Locust that will generate some simple traffic to the PetClinic application. Locust is a simple load testing tool that can be used to generate traffic to a web application.
docker run --network="host" -d -p 8089:8089 -v /home/ubuntu/workshop/petclinic:/mnt/locust docker.io/locustio/locust -f /mnt/locust/locustfile.py --headless -u 10 -r 3 -H http://127.0.0.1:8080 3. Enabling AlwaysOn Profiling and Metrics To enable CPU and Memory Profiling on the application we can start the application by passing splunk.profiler.enabled=true and for metrics pass splunk.metrics.enabled=true. Make sure the application is stopped and run the following command to enable metrics and profiling.
java \\ -Dotel.service.name=$(hostname)-petclinic-service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql You can now visit the Splunk APM UI and examine the application components, traces, profiling, DB Query performance and metrics Hamburger Menu → APM → Explore.
Once your validation is complete you can stop the application by pressing Ctrl-c.
4. Adding Resource Attributes to Spans Resource attributes can be added to every reported span. For example version=0.314. A comma separated list of resource attributes can also be defined e.g. key1=val1,key2=val2.
Let’s launch the PetClinic again using a new resource attribute. Note, that adding resource attributes to the run command will override what was defined when we installed the collector. So, we also need to specify our deployment.environment resource attribute along with our new resource attribute. Below you will see we are setting deployment.environment=$(hostname)-petclinic and version=0.314.
java \\ -Dotel.service.name=$(hostname)-petclinic-service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -Dotel.resource.attributes=deployment.environment=$(hostname)-petclinic,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Back in the Splunk APM UI we can drill down on a recent trace and see the new version attribute in a span.
`,description:"",tags:null,title:"Zero Configuration Auto Instrumentation for Java",uri:"/en/other/pet-clinic/apm/index.html"},{content:`Service Map Click on paymentservice in the service map and select version from the breakdown drop down filter underneath paymentservice. This will filter our service map by the custom span tag version.
You will now see the service map has been updated like the below screenshot to show the different versions of the paymentservice.
Splunk Observability shows that not only is paymentservice experiencing errors (you can see request rate vs error rate) but that this service is the root cause.
This happens automatically with our AI-directed triage capabilities once distributed tracing is enabled in your services. You don’t have to set a threshold or anything for it to populate just like this.
This is one example of how customers can detect issues faster and know where to look for errors and hence helps reduce the MTTD and MTTR.
`,description:"",tags:null,title:"2.1 Service Map",uri:"/en/apm/using-splunk-apm/service_map/index.html"},{content:`1. Acknowledge Use your Splunk On-Call App on your phone to acknowledge the Incident by clicking on the push notification …
…to open the alert in the Splunk On-Call mobile app, then clicking on either the single tick in the top right hand corner, or the Acknowledge link to acknowledge the incident and stop the escalation process.
The :fontawesome-solid-check: will then transform into a :fontawesome-solid-check::fontawesome-solid-check:, and the status will change from TRIGGERED to ACKNOWLEDGED.
Triggered Incident Acknowledge Incident 2. Details and Annotations Still on your phone, select the Alert Details tab. Then on the Web UI, navigate back to Timeline, select Team Incidents on the right, then select Acknowledged and click into the new Incident, this will open up the War Room Dashboard view of the Incident.
You should now have the Details tab displayed on both your Phone and the Web UI. Notice how they both show the exact same information.
Now select the Annotations tab on both the Phone and the Web UI, you should have a Graph displayed in the UI which is generated by Splunk Infrastructure Monitoring.
On your phone you should get the same image displayed (sometimes it’s a simple hyperlink depending on the image size)
Splunk On-Call is a ‘Mobile First’ platform meaning the phone app is full functionality and you can manage an incident directly from your phone.
For the remainder of this module we will focus on the Web UI however please spend some time later exploring the phone app features.
3. Link to Alerting System Sticking with the Web UI, click the 2. Alert Details in SignalFx link.
This will open a new browser tab and take you directly to the Alert within Splunk Infrastructure Monitoring where you could then progress your troubleshooting using the powerful tools built into its UI.
However, we are focussing on Splunk On-Call so close this tab and return to the Splunk On-Call UI.
4. Similar Incidents What if Splunk On-Call could identify previous incidents within the system which may give you a clue to the best way to tackle this incident.
The Similar Incidents tab does exactly that, surfacing previous incidents allowing you to look at them and see what actions were taken to resolve them, actions which could be easily repeated for this incident.
5 Timeline On right we have a Time Line view where you can add messages and see the history of previous alerts and interactions.
6 Add Responders On the far left you have the option of allocating additional resources to this incident by clicking on the Add Responders link.
This allows you build a virtual team specific to this incident by adding other Teams or individual Users, and also share details of a Conference Bridge where you can all get together and collaborate.
Once the system has built up some incident data history, it will use Machine Learning to suggest Teams and Users who have historically worked on similar incidents, as they may be best placed to help resolve this incident quickly.
You can select different Teams and/or Users and also choose from a pre-configured conference bridge, or populate the details of a new bridge from your preferred provider.
We do not need to add any Responders in this exercise so close the Add Responders dialogue by clicking Cancel.
7 Reroute If it’s decided that maybe the incident could be better dealt with by a different Team, the call can be Rerouted by clicking the Reroute Button at the top of the left hand panel.
In a similar method to that used in the Add Responders dialogue, you can select Teams or Users to Reroute the Incident to.
We do not need to actually Reroute in this exercise so close the Reroute Incident dialogue by clicking Cancel.
8 Snooze You can also snooze this incident by clicking on the alarm clock Button at the top of the left hand panel.
You can enter an amount of time upto 24 hours to snooze the incident. This action will be tracked in the Timeline, and when the time expires the paging will restart.
This is useful for low priority incidents, enabling you to put them on a back burner for a few hours, but it ensures they do not get forgotten thanks to the paging process starting again.
We do not need to actually Snooze in this exercise so close the Snooze Incident dialogue by clicking Cancel.
9 Action Tracking Now lets fix this issue and update the Incident with what we did. Add a new message at the top of the right hand panel such as Discovered rogue process, terminated it.
All the actions related to the Incident will be recorded here, and can then be summarized is a Post Incident Review Report available from the Reports tab
10 Resolution Now kill off the process we started in the VM to max out the CPU by switching back the Shell session for the VM and pressing ctrl+c
Within no more than 10 seconds SignalFx should detect the new CPU value, clear the alert state in SignalFx, then automatically update the Incident in VictorOps marking it as Resolved.
As we have two way integration between Splunk Infrastructure Monitoring and Splunk On-Call we could have also marked the incident as Resolved in Splunk On-Call, and this would have resulted in the alert in Splunk Infrastructure Monitoring being resolved as well.
That completes this introduction to Splunk On-Call!
`,description:"",tags:null,title:"Manage Incidents",uri:"/en/oncall/incident_lifecycle/manage_incidents/index.html"},{content:`1. Saving a chart To start saving your chart, lets give it a name and description. Click the name of the chart Copy of Latency Histogram and rename it to “Active Latency”.
To change the description click on Spread of latency values across time. and change this to Overview of latency values in real-time.
Click the Save As button. Make sure your chart has a name, it will use the name Active Latency the you defined in the previous step, but you can edit it here if needed.
Press the Ok button to continue.
2. Creating a dashboard In the Choose dashboard dialog, we need to create a new dashboard, click on the New Dashboard button.
You will now see the New Dashboard Dialog. In here you can give you dashboard a name and description, and set Read and Write Permissions.
Please use your own name in the following format to give your dashboard a name e.g. YOUR_NAME-Dashboard.
Please replace YOUR_NAME with your own name, change the dashboard permissions to Restricted Read and Write access, and verify your user can read/write.
You should see you own login information displayed, meaning you are now the only one who can edit this dashboard. Of course you have the option to add other users or teams from the drop box below that may edit your dashboard and charts, but for now make sure you change it back to Everyone can Read or Write to remove any restrictions and press the Save Button to continue.
Your new dashboard is now available and selected so you can save your chart in your new dashboard.
Make sure you have your dashboard selected and press the Ok button.
You will now be taken to your dashboard like below. You can see at the top left that your YOUR_NAME-DASHBOARD is part of a Dashboard Group YOUR_NAME-Dashboard. You can add other dashboards to this dashboard group.
3. Add to Team page It is common practice to link dashboards that are relevant to a Team to a teams page. So let’s add your dashboard to the team page for easy access later. Use the from the navbar again.
This will bring you to your teams dashboard, We use the team Example Team as an example here, the workshop one will be different.
Press the \u003cul\u003e \u003cli\u003e\u003c/li\u003e \u003c/ul\u003e Add Dashboard Group button to add you dashboard to the team page.
This will bring you to the Select a dashboard group to link to this team dialog. Type your name (that you used above) in the search box to find your Dashboard. Select it so its highlighted and click the Ok button to add your dashboard.
Your dashboard group will appear as part of the team page. Pleasu note during the course of the workshop many more will appear here.
Now click on the link for your Dashboard to add more charts!
`,description:"",tags:null,title:"Saving charts",uri:"/en/other/o11y4rookies/imt/dashboards/savingcharts/index.html"},{content:`1. Saving a chart To start saving your chart, lets give it a name and description. Click the name of the chart Copy of Latency Histogram and rename it to “Active Latency”.
To change the description click on Spread of latency values across time. and change this to Overview of latency values in real-time.
Click the Save As button. Make sure your chart has a name, it will use the name Active Latency the you defined in the previous step, but you can edit it here if needed.
Press the Ok button to continue.
2. Creating a dashboard In the Choose dashboard dialog, we need to create a new dashboard, click on the New Dashboard button.
You will now see the New Dashboard Dialog. In here you can give you dashboard a name and description, and set Read and Write Permissions.
Please use your own name in the following format to give your dashboard a name e.g. YOUR_NAME-Dashboard.
Please replace YOUR_NAME with your own name, change the dashboard permissions to Restricted Read and Write access, and verify your user can read/write.
You should see you own login information displayed, meaning you are now the only one who can edit this dashboard. Of course you have the option to add other users or teams from the drop box below that may edit your dashboard and charts, but for now make sure you change it back to Everyone can Read or Write to remove any restrictions and press the Save Button to continue.
Your new dashboard is now available and selected so you can save your chart in your new dashboard.
Make sure you have your dashboard selected and press the Ok button.
You will now be taken to your dashboard like below. You can see at the top left that your YOUR_NAME-DASHBOARD is part of a Dashboard Group YOUR_NAME-Dashboard. You can add other dashboards to this dashboard group.
3. Add to Team page It is common practice to link dashboards that are relevant to a Team to a teams page. So let’s add your dashboard to the team page for easy access later. Use the from the navbar again.
This will bring you to your teams dashboard, We use the team Example Team as an example here, the workshop one will be different.
Press the \u003cul\u003e \u003cli\u003e\u003c/li\u003e \u003c/ul\u003e Add Dashboard Group button to add you dashboard to the team page.
This will bring you to the Select a dashboard group to link to this team dialog. Type your name (that you used above) in the search box to find your Dashboard. Select it so its highlighted and click the Ok button to add your dashboard.
Your dashboard group will appear as part of the team page. Pleasu note during the course of the workshop many more will appear here.
Now click on the link for your Dashboard to add more charts!
`,description:"",tags:null,title:"Saving charts",uri:"/en/imt/dashboards/savingcharts/index.html"},{content:` Discover how you can restrict usage by creating separate Access Tokens and set limits. 1. Access Tokens If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization.
In the UI click on the » bottom left and select the Settings → Access Tokens under General Settings.
The Access Tokens Interface provides an overview of your allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured.
Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume.
The Usage Status Column quickly shows if a token is above or below its assigned limits.
2. Creating a new token Let create a new token by clicking on the New Token button. This will provide you with the Name Your Access Token dialog.
Enter the new name of the new Token by using your Initials e.g. RWC-Token and make sure to tick both Ingest Token and API Token checkboxes!
After you press OK you will be taken back to the Access Token UI. Here your new token should be present, among the ones created by others.
If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the ellipsis (…) menu button behind a token limit to open the manage token menu.
If you made a typo you can use the Rename Token option to correct the name of your token.
3. Disabling a token If you need to make sure a token cannot be used to send Metrics in you can disable a token.
Click on Disable to disable the token, this means the token cannot be used for sending in data to Splunk Observability Cloud.
The line with your token should have become greyed out to indicate that is has been disabled as you can see in the screenshot below.
Go ahead and click on the ellipsis (…) menu button to Disable and Enable your token.
4. Manage token usage limits Now Lets start limiting usage by clicking on Manage Token Limit in the 3 … menu.
This will show the Manage Token Limit Dialog:
In this Dialog you can set the limits per category.
Please go ahead and specify the limits as follows for each usage metric:
Limit Value Host Limit 5 Container Limit 15 Custom Metric Limit 20 High Resolution Metric Limit 0 For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown in the table above.
Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes.
To specify the recipients, click Add Recipient , then select the recipient or notification method you want to use (specifying recipients is optional but highly recommended).
The severity for token alerts is always Critical.
Click on Update to save your Access Tokens limits and The Alert Settings.
Note: Going above token limit When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by Observability Cloud. This will make sure you there will be no unexpected cost due to a team sending in data without restriction.
Note: Advanced alerting If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved.
In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to Observability Cloud.
This will allow you to fine tune the way you consume your Observability Cloud allotment and prevent overages from happening.
Congratulations! You have now have completed the Service Bureau module.
`,description:"",tags:null,title:"Controlling Usage",uri:"/en/other/o11y4rookies/imt/servicebureau/tokens/index.html"},{content:` Discover how you can restrict usage by creating separate Access Tokens and set limits. 1. Access Tokens If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization.
In the UI click on the » bottom left and select the Settings → Access Tokens under General Settings.
The Access Tokens Interface provides an overview of your allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured.
Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume.
The Usage Status Column quickly shows if a token is above or below its assigned limits.
2. Creating a new token Let create a new token by clicking on the New Token button. This will provide you with the Name Your Access Token dialog.
Enter the new name of the new Token by using your Initials e.g. RWC-Token and make sure to tick both Ingest Token and API Token checkboxes!
After you press OK you will be taken back to the Access Token UI. Here your new token should be present, among the ones created by others.
If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the ellipsis (…) menu button behind a token limit to open the manage token menu.
If you made a typo you can use the Rename Token option to correct the name of your token.
3. Disabling a token If you need to make sure a token cannot be used to send Metrics in you can disable a token.
Click on Disable to disable the token, this means the token cannot be used for sending in data to Splunk Observability Cloud.
The line with your token should have become greyed out to indicate that is has been disabled as you can see in the screenshot below.
Go ahead and click on the ellipsis (…) menu button to Disable and Enable your token.
4. Manage token usage limits Now Lets start limiting usage by clicking on Manage Token Limit in the 3 … menu.
This will show the Manage Token Limit Dialog:
In this Dialog you can set the limits per category.
Please go ahead and specify the limits as follows for each usage metric:
Limit Value Host Limit 5 Container Limit 15 Custom Metric Limit 20 High Resolution Metric Limit 0 For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown in the table above.
Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes.
To specify the recipients, click Add Recipient , then select the recipient or notification method you want to use (specifying recipients is optional but highly recommended).
The severity for token alerts is always Critical.
Click on Update to save your Access Tokens limits and The Alert Settings.
Note: Going above token limit When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by Observability Cloud. This will make sure you there will be no unexpected cost due to a team sending in data without restriction.
Note: Advanced alerting If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved.
In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to Observability Cloud.
This will allow you to fine tune the way you consume your Observability Cloud allotment and prevent overages from happening.
Congratulations! You have now have completed the Service Bureau module.
`,description:"",tags:null,title:"Controlling Usage",uri:"/en/imt/servicebureau/tokens/index.html"},{content:` 45 minutes During this technical workshop you will learn how to:
Efficiently deploy complex environments Capture metrics from these environments to Splunk Observability Cloud Auto-instrument a python application Enable OS logging to Splunk Enterprise via Universal Forwarder In order to simplify the workshop modules, a pre-configured AWS EC2 instance is provided.
By the end of this technical workshop you will have an approach to demonstrating metrics collection for complex environments and services.
`,description:"",tags:null,title:"Getting Data In (GDI) with OTel and UF",uri:"/en/other/gdi/index.html"},{content:` 45 minutes This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector. During the workshop you will deploy PHP/Apache and a load generator.
You will learn about OpenTelemetry Receivers, Kubernetes Namespaces, ReplicaSets, Kubernetes Horizontal Pod AutoScaling and how to monitor all this using the Splunk Observability Cloud. The main learnings from the workshop will be a better understanding of the Kubernetes Navigator (and Dashboards) in Splunk Observability Cloud as well as seeing Kubernetes metrics, events and Detectors.
For this workshop Splunk has prepared an Ubuntu Linux instance in AWS/EC2 all pre-configured for you.
To get access to the instance that you will be using in the workshop, please visit the URL provided by the workshop leader.
`,description:"This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector",tags:null,title:"Monitoring Horizontal Pod Autoscaling in Kubernetes",uri:"/en/other/hpa/index.html"},{content:` 45 minutes This workshop will equip you with how a distributed trace is constructed for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis.
We will see how auto-instrumentation works with manual steps to force a Producer function’s context to be sent to Consumer function via a Record put on a Kinesis stream.
For this workshop Splunk has prepared an Ubuntu Linux instance in AWS/EC2 all pre-configured for you.
To get access to the instance that you will be using in the workshop, please visit the URL provided by the workshop leader.d
`,description:"This workshop will equip you with how a distributed trace is constructed for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis",tags:null,title:"Build a Distributed Trace in Lambda and Kinesis",uri:"/en/other/lambda-kinesis/index.html"},{content:`Abstract Adopting OpenTelemetry within your organisation can bring issues such as dealing with metric naming changes, rollout, and where to start. In this workshop, we will be focusing on using the OpenTelemetry collector and starting with the fundamentals of configuring the receivers, processors, and exporters ready to use with Splunk Cloud. The journey will take attendees from novices to being able to start adding custom components to help solve for their business observability needs for their distributed platform.
Target Audience This talk is for developers and system administrators who are interested in learning more about architecture and deployment of the OpenTelemetry Collector.
Prerequisites Attendees should have a basic understanding of distributed systems and data collection. A instance/host/VM running Ubuntu 20.04 LTS or 22.04 LTS. Command line and vim/vi experience. Learning Objectives By the end of this talk, attendees will be able to:
Understand the components of OpenTelemetry Use receivers, processors, and exporters to collect, instrument, and analyze data from distributed systems Identify the benefits of using OpenTelemetry Building a custom component to solve for their business needs %%{ init:{ "theme":"base", "themeVariables": { "primaryColor": "#ffffff", "clusterBkg": "#eff2fb", "defaultLinkColor": "#333333" } } }%% flowchart LR; subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end Overview https://www.aspecto.io/blog/opentelemetry-collector-guide/
https://docs.splunk.com/Observability/gdi/other-ingestion-methods/upstream-collector.html#nav-Send-telemetry-using-OpenTelemetry-Collector-Contrib
OpenTelemetry Collector Contrib - https://github.com/open-telemetry/opentelemetry-collector-releases/releases/tag/v0.75.0 https://opentelemetry.io/docs/collector/configuration/
Extensions Recievers Processors https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor Exporters Pipelines Vanilla/Contrib/Vendor
Host metrics and metadata into O11y Cloud
Research using OTel Log Collection
Metrics into O11y
Logs into Core
Building a custom component
Edit config to include new component
Demonstate metrics from new component
Default configuration extensions: health_check: pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] Splunk OTel Host install default configuration # Default configuration file for the Linux (deb/rpm) and Windows MSI collector packages # If the collector is installed without the Linux/Windows installer script, the following # environment variables are required to be manually defined or configured below: # - SPLUNK_ACCESS_TOKEN: The Splunk access token to authenticate requests # - SPLUNK_API_URL: The Splunk API URL, e.g. https://api.us0.signalfx.com # - SPLUNK_BUNDLE_DIR: The path to the Smart Agent bundle, e.g. /usr/lib/splunk-otel-collector/agent-bundle # - SPLUNK_COLLECTD_DIR: The path to the collectd config directory for the Smart Agent, e.g. /usr/lib/splunk-otel-collector/agent-bundle/run/collectd # - SPLUNK_HEC_TOKEN: The Splunk HEC authentication token # - SPLUNK_HEC_URL: The Splunk HEC endpoint URL, e.g. https://ingest.us0.signalfx.com/v1/log # - SPLUNK_INGEST_URL: The Splunk ingest URL, e.g. https://ingest.us0.signalfx.com # - SPLUNK_TRACE_URL: The Splunk trace endpoint URL, e.g. https://ingest.us0.signalfx.com/v2/trace extensions: health_check: endpoint: 0.0.0.0:13133 http_forwarder: ingress: endpoint: 0.0.0.0:6060 egress: endpoint: "\${SPLUNK_API_URL}" # Use instead when sending to gateway #endpoint: "\${SPLUNK_GATEWAY_URL}" smartagent: bundleDir: "\${SPLUNK_BUNDLE_DIR}" collectd: configDir: "\${SPLUNK_COLLECTD_DIR}" zpages: #endpoint: 0.0.0.0:55679 memory_ballast: # In general, the ballast should be set to 1/3 of the collector's memory, the limit # should be 90% of the collector's memory. # The simplest way to specify the ballast size is set the value of SPLUNK_BALLAST_SIZE_MIB env variable. size_mib: \${SPLUNK_BALLAST_SIZE_MIB} receivers: fluentforward: endpoint: 127.0.0.1:8006 hostmetrics: collection_interval: 10s scrapers: cpu: disk: filesystem: memory: network: # System load average metrics https://en.wikipedia.org/wiki/Load_(computing) load: # Paging/Swap space utilization and I/O metrics paging: # Aggregated system process count metrics processes: # System processes metrics, disabled by default # process: jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 # This section is used to collect the OpenTelemetry Collector metrics # Even if just a Splunk APM customer, these metrics are included prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] metric_relabel_configs: - source_labels: [ __name__ ] regex: '.*grpc_io.*' action: drop smartagent/signalfx-forwarder: type: signalfx-forwarder listenAddress: 0.0.0.0:9080 smartagent/processlist: type: processlist signalfx: endpoint: 0.0.0.0:9943 # Whether to preserve incoming access token and use instead of exporter token # default = false #access_token_passthrough: true zipkin: endpoint: 0.0.0.0:9411 processors: batch: # Enabling the memory_limiter is strongly recommended for every pipeline. # Configuration is based on the amount of memory allocated to the collector. # For more information about memory limiter, see # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiter/README.md memory_limiter: check_interval: 2s limit_mib: \${SPLUNK_MEMORY_LIMIT_MIB} # Detect if the collector is running on a cloud system, which is important for creating unique cloud provider dimensions. # Detector order is important: the \`system\` detector goes last so it can't preclude cloud detectors from setting host/os info. # Resource detection processor is configured to override all host and cloud attributes because instrumentation # libraries can send wrong values from container environments. # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourcedetectionprocessor#ordering resourcedetection: detectors: [system, gcp, ecs, ec2, azure] override: true # Optional: The following processor can be used to add a default "deployment.environment" attribute to the logs and # traces when it's not populated by instrumentation libraries. # If enabled, make sure to enable this processor in the pipeline below. #resource/add_environment: #attributes: #- action: insert #value: staging/production/... #key: deployment.environment exporters: # Traces sapm: access_token: "\${SPLUNK_ACCESS_TOKEN}" endpoint: "\${SPLUNK_TRACE_URL}" # Metrics + Events signalfx: access_token: "\${SPLUNK_ACCESS_TOKEN}" api_url: "\${SPLUNK_API_URL}" ingest_url: "\${SPLUNK_INGEST_URL}" # Use instead when sending to gateway #api_url: http://\${SPLUNK_GATEWAY_URL}:6060 #ingest_url: http://\${SPLUNK_GATEWAY_URL}:9943 sync_host_metadata: true correlation: # Logs splunk_hec: token: "\${SPLUNK_HEC_TOKEN}" endpoint: "\${SPLUNK_HEC_URL}" source: "otel" sourcetype: "otel" # Send to gateway otlp: endpoint: "\${SPLUNK_GATEWAY_URL}:4317" tls: insecure: true # Debug logging: loglevel: debug service: extensions: [health_check, http_forwarder, zpages, memory_ballast, smartagent] pipelines: traces: receivers: [jaeger, otlp, smartagent/signalfx-forwarder, zipkin] processors: - memory_limiter - batch - resourcedetection #- resource/add_environment exporters: [sapm, signalfx] # Use instead when sending to gateway #exporters: [otlp, signalfx] metrics: receivers: [hostmetrics, otlp, signalfx, smartagent/signalfx-forwarder] processors: [memory_limiter, batch, resourcedetection] exporters: [signalfx] # Use instead when sending to gateway #exporters: [otlp] metrics/internal: receivers: [prometheus/internal] processors: [memory_limiter, batch, resourcedetection] # When sending to gateway, at least one metrics pipeline needs # to use signalfx exporter so host metadata gets emitted exporters: [signalfx] logs/signalfx: receivers: [signalfx, smartagent/processlist] processors: [memory_limiter, batch, resourcedetection] exporters: [signalfx] # Use instead when sending to gateway #exporters: [otlp] logs: receivers: [fluentforward, otlp] processors: - memory_limiter - batch - resourcedetection #- resource/add_environment exporters: [splunk_hec] # Use instead when sending to gateway #exporters: [otlp] End goal for metrics only:
extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: cpu: disk: filesystem: memory: network: # System load average metrics https://en.wikipedia.org/wiki/Load_(computing) load: # Paging/Swap space utilization and I/O metrics paging: # Aggregated system process count metrics processes: # System processes metrics, disabled by default # process: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] processors: batch: resourcedetection: detectors: [system] override: true exporters: logging: loglevel: debug otlphttp: metrics_endpoint: https://ingest.eu0.signalfx.com/v2/datapoint/otlp compression: gzip headers: X-SF-TOKEN: \u003cREDACTED\u003e service: pipelines: metrics: receivers: [otlp, opencensus, prometheus, hostmetrics] processors: [batch, resourcedetection] exporters: [logging, otlphttp] extensions: [health_check, pprof, zpages] `,description:"This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector",tags:null,title:"Newbie to Ninja - OpenTelemetry Collector",uri:"/en/conf/opentelemetry-collector/index.html"},{content:`Splunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.
By collecting all traces, instead of a sampled subset, no anomaly goes undetected. Whether a user experiences an error or longer-than-usual latency, you’ll be able to know and act on it within seconds. Furthermore, not all bad behavior results in errors — as your developers create new applications they need to know whether their canary releases provide the expected results. Only by collecting all trace data will you ensure that your cloud-native applications behave the way they are supposed to.
Infrastructure and application performance are interdependent. To see the full picture, Splunk APM provides seamless correlation between cloud infrastructure and the microservices running on top of it. If your application acts out because of memory leakage, a noisy neighbor container or any other infrastructure-related issue, Splunk will let you know. To complete the picture, in-context access to Splunk logs and events enable deeper troubleshooting and root-cause analysis.
1. Deploy the Online BoutiqueDeploy the Online Boutique application into Kubernetes (K3s) and generate some artificial traffic using Locust.
2. Using Splunk APMAn overview of how to use Splunk APM
`,description:"Splunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.",tags:null,title:"Splunk APM",uri:"/en/apm/index.html"},{content:`Splunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.
By collecting all traces, instead of a sampled subset, no anomaly goes undetected. Whether a user experiences an error or longer-than-usual latency, you’ll be able to know and act on it within seconds. Furthermore, not all bad behavior results in errors — as your developers create new applications they need to know whether their canary releases provide the expected results. Only by collecting all trace data will you ensure that your cloud-native applications behave the way they are supposed to.
Infrastructure and application performance are interdependent. To see the full picture, Splunk APM provides seamless correlation between cloud infrastructure and the microservices running on top of it. If your application acts out because of memory leakage, a noisy neighbor container or any other infrastructure-related issue, Splunk will let you know. To complete the picture, in-context access to Splunk logs and events enable deeper troubleshooting and root-cause analysis.
`,description:"Splunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.",tags:null,title:"Splunk APM",uri:"/en/other/o11y4rookies/apm/index.html"},{content:` 15 minutes APM Overview - RED metrics Using the Service Map Introduction to Tag Spotlight Example Traces Contextual Links to Infra 1. Traces and Spans explained A trace is a collection of spans that share the same trace ID, representing a unique transaction handled by your application and its constituent services.
Each span has a name, representing the operation captured by this span, and a service name, representing within which service the operation took place.
Additionally, spans may reference another span as their parent, defining the relationships between the operations captured in the trace that were performed to process that transaction.
Each span contains a lot of information about the method, operation, or block of code that it captures, including:
the operation name the start time of the operation with microsecond precision how long the operation took to execute, also with microsecond precision the logical name of the service on which the operation took place the IP address of the service instance on which the operation took place `,description:"An overview of how to use Splunk APM",tags:null,title:"1. Using Splunk APM",uri:"/en/other/o11y4rookies/apm/using-splunk-apm/index.html"},{content:`Aim Escalation policies determine who is actually on-call for a given team and are the link to utilizing any rotations that have been created.
The aim of this module is for you to create three different Escalation Policies to demonstrate a number of different features and operating models.
The instructor will start by explaining the concepts before you proceed with the configuration.
Navigate to the Escalation Polices tab on the Teams sub menu, you should have no existing Polices so we need to create some.
We are going to create the following Polices to cover off three typical use cases.
1. 24/7 Policy Click Add Escalation Policy
Policy Name: 24/7 Step 1 Immediately Notify the on-duty user(s) in rotation → Senior SRE Escalation Click Save 2. Primary Policy Click Add Escalation Policy
Policy Name: Primary Step 1 Immediately Notify the on-duty user(s) in rotation → Follow the Sun Support - Business Hours Click Add Step Step 2 If still unacked after 15 minutes Notify the next user(s) in the current on-duty shift → Follow the Sun Support - Business Hours Click Add Step Step 3 If still unacked after 15 more minutes Execute Policy → [Your Team Name] : 24/7 Click Save 3. Waiting Room Policy Click Add Escalation Policy
Policy Name: Waiting Room Step 1 If still unacked after 10 more minutes Execute Policy → [Your Team Name] : Primary Click Save You should now have the following three escalation polices:
You may have noticed that when we created each policy there was the following warning message:
Warning There are no routing keys for this policy - it will only receive incidents via manual reroute or when on another escalation policy
This is because there are no Routing Keys linked to these Escalation Polices, so now that we have these polices configured we can create the Routing Keys and link them to our Polices..
Continue and also complete the Creating Routing Keys module.
`,description:"",tags:null,title:"Configure Escalation Policies",uri:"/en/oncall/getting_started/escalation/index.html"},{content:`Example Trace You should now see the entire trace along with the spans for the example trace that was selected. Spans which have errors are indicated by a red exclamation mark beside it. If you have a number such as x6 in a grey box, click it to expand the compacted paymentservice spans.
Now click one of the paymentservice spans with the red exclamation mark to expand it and see the associated metadata and some error details. Note that we are able to see that this error is caused by a 401 error and other useful information such as ‘tenant’ and ‘version’ is also displayed.
So we now know that the error is caused by an Invalid Request but we don’t know what exact request. At the bottom of the page you should see a contextual link to Logs, clink on this link to view the logs associated with this span.
You should now be looking at a Log Observer dashboard simialar to the image below.
We can use the filter to display only the error logs. Click on ERROR in the top right hand corner, then Add to filter
You should now have a shorter list of log entries which have a severity of ERROR
Select any of the entries to view the details. We can now see how the error was caused by the use of an Invalid API Token that our developers have accidentally pushed to production!
Congratulations, you have now completed the APM Workshop.
`,description:"",tags:null,title:"1.3 Example trace",uri:"/en/other/o11y4rookies/apm/using-splunk-apm/example_trace/index.html"},{content:` 15 minutes APM Overview - RED metrics Using the Service Map Introduction to Tag Spotlight Example Traces Contextual Links to Infra 1. Traces and Spans explained A trace is a collection of spans that share the same trace ID, representing a unique transaction handled by your application and its constituent services.
Each span has a name, representing the operation captured by this span, and a service name, representing within which service the operation took place.
Additionally, spans may reference another span as their parent, defining the relationships between the operations captured in the trace that were performed to process that transaction.
Each span contains a lot of information about the method, operation, or block of code that it captures, including:
the operation name the start time of the operation with microsecond precision how long the operation took to execute, also with microsecond precision the logical name of the service on which the operation took place the IP address of the service instance on which the operation took place `,description:"An overview of how to use Splunk APM",tags:null,title:"2. Using Splunk APM",uri:"/en/apm/using-splunk-apm/index.html"},{content:` Deploy a NGINX ReplicaSet into your K3s cluster and confirm the discovery of your NGINX deployment. Run a load test to create metrics and confirm them streaming into Splunk Observability Cloud! 1. Start your NGINX Verify the number of pods running in the Splunk UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster.
Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node!
Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again.
In your AWS/EC2 or Multipass shell session change into the nginx directory:
Change Directory cd ~/workshop/k3s/nginx 2. Create NGINX deployment Create the NGINX ConfigMap1 using the nginx.conf file:
Kubectl Configmap Create Kubectl Create Configmap Output kubectl create configmap nginxconfig --from-file=nginx.conf configmap/nginxconfig created
Then create the deployment:
Kubectl Create Deployment Kubectl Create Deployment Output kubectl create -f nginx-deployment.yaml deployment.apps/nginx created service/nginx created
Next we will deploy Locust2 which is an open source tool used for creating a load test against NGINX:
Kubectl Create Deployment Kubectl Create Deployment Output kubectl create -f locust-deployment.yaml deployment.apps/nginx-loadgenerator created service/nginx-loadgenerator created
Validate the deployment has been successful and that the Locust and NGINX pods are running.
If you have the Splunk UI open you should see new Pods being started and containers being deployed.
It should only take around 20 seconds for the pods to transition into a Running state. In the Splunk UI you will have a cluster that looks like below:
If you select the WORKLOADS tab again you will now see that there is a new ReplicaSet and a deployment added for NGINX:
Let’s validate this in your shell as well:
Kubectl Get Pods Kubectl Get Pods Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-77784c659c-ttmpk 1/1 Running 0 9m19s splunk-otel-collector-agent-249rd 1/1 Running 0 9m19s svclb-nginx-vtnzg 1/1 Running 0 5m57s nginx-7b95fb6b6b-7sb9x 1/1 Running 0 5m57s nginx-7b95fb6b6b-lnzsq 1/1 Running 0 5m57s nginx-7b95fb6b6b-hlx27 1/1 Running 0 5m57s nginx-7b95fb6b6b-zwns9 1/1 Running 0 5m57s svclb-nginx-loadgenerator-nscx4 1/1 Running 0 2m20s nginx-loadgenerator-755c8f7ff6-x957q 1/1 Running 0 2m20s
3. Run Locust load test Locust, an open source load generator, is available on port 8080 of the EC2 instance’s IP address. Open a new tab in your web browser and go to http://{==EC2-IP==}:8080/, you will then be able to see the Locust running.
Set the Spawn rate to be 2 and click Start Swarming.
This will start a gentle continuous load on the application.
As you can see from the above screenshot, most of the calls will report a fail, this is expected, as we have not yet deployed the application behind it, however NGINX is reporting on your attempts and you should be able to see those metrics.
Validate you are seeing those metrics in the UI by selecting Dashboards → Built-in Dashboard Groups → NGINX → NGINX Servers. Using the Overrides filter on k8s.cluster.name:, find the name of your cluster as returned by echo $(hostname)-k3s-cluster in the terminal.
A ConfigMap is an API object used to store non-confidential data in key-value pairs. Pods can consume ConfigMaps as environment variables, command-line arguments, or as configuration files in a volume. A ConfigMap allows you to decouple environment-specific configuration from your container images, so that your applications are easily portable. ↩︎
What is Locust? ↩︎
`,description:"",tags:null,title:"Deploying NGINX in K3s",uri:"/en/imt/gdi/nginx/index.html"},{content:`Tag Spotlight On the right hand side of the screen scroll down on Tag Spotlight, ensure Top Across All Indexed Tags is selected in the dropdown click the full screen button as indicated in the screenshot below.
The Tag Spotlight Page will be displayed. From this page you can view the top tags in your application and their corresponding error rates and request rates.
Note that for the version span tag it appears that version 350.10 has a 100% error rate and for our tenant.level span tag it shows that all three tenants (Gold, Silver \u0026 Bronze) have errors present.
The Tag Spotlight page is interactive and allows you to add a tag as a filter by simply clicking on your desired tag. Click on gold under tenant.level to add it as a filter. Once this is done the page will now only display data with gold as it’s tenant.level.
Tag Spotlight is very useful for analysing your data and spotting trends. We can see that for the Gold Tenant that out of the total number of requests, 55 of them are in error (this number will vary in your workshop).
If we correlate this to the version tag, we can see that version 350.10 served 55 requests and version 350.9 served 17 requests. This means that all of the requests that went through version 350.10 ended up in an error state.
In order to test this theory further that all of the requests from paymentservice version 350.10 result in an error, we can change our filter to another tenant by using the tag selector. Change your filter from gold tenant to silver tenant.
Now we can perform a similar analysis by looking at the number of requests in error for the silver tenant and correlating that with the version number. Note the amount of errors for the silver tenant match the amount of requests for version 350.10.
Tag Spotlight not only allows you to look at request and error rates but also at the latency per service. In order to do this just select the latency button and remove your Silver Tenant Tag so that you can see the latency for all of the Payment Service.
Go back to your service map by pressing the X button on the far right underneath Clear All.
Click anywhere on the pink line in the Services by Error Rate graph in the top right hand corner. Once selected you should see a list of example traces. Click on one of the example traces with an initiating operation of frontend: POST /cart/checkout.
`,description:"",tags:null,title:"2.2 Tag Spotlight",uri:"/en/apm/using-splunk-apm/tag_spotlight/index.html"},{content:`1 Creating a new chart Let’s now create a new chart and save it in our dashboard!
Select the plus icon (top right of the UI) and from the drop down, choose the option Chart. Or click on the \u003cul\u003e \u003cli\u003eNew Chart\u003c/li\u003e \u003c/ul\u003e Button to create a new chart.
You will now see a chart template like the following.
Let’s enter a metric to plot. We are still going to use the metric demo.trans.latency.
In the Plot Editor tab under Signal enter demo.trans.latency.
You should now have a familiar line chart. Please switch the time to 15 mins.
2. Filtering and Analytics Let’s now select the Paris datacenter to do some analytics - for that we will use a filter.
Let’s go back to the Plot Editor tab and click on Add Filter , wait until it automatically populates, choose demo_datacenter, and then Paris.
In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm).
For info on the Percentile function and the other functions see Chart Analytics.
3. Using Timeshift analytical function Let’s now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A.
You will see a new row identical to A, called B, both visible and plotted.
For Signal B, in the F(x) column add the analytic function Timeshift and enter 1w (or 7d for 7 days), and click outside to confirm.
Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B.
Click on Close.
We now see plots for Signal A (the past 15 minutes) as a blue plot, and the plots from a week ago in pink.
In order to make this clearer we can click on the Area chart icon to change the visualization.
We now can see when last weeks latency was higher!
Next, click into the field next to Time on the Override bar and choose Past Hour from the dropdown.
4. Using Formulas Let’s now plot the difference of all metric values for a day with 7 days in between.
Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C.
We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time.
Lets look at the Signalflow that drives our Charts and Detectors!
`,description:"",tags:null,title:"2.3 Using Filters \u0026 Formulas",uri:"/en/other/o11y4rookies/imt/dashboards/filtering/index.html"},{content:`Code to Kubernetes - Python Objective: Understand activities to instrument a python application and run it on Kubernetes.
Verify the code Containerize the app Deploy the container in Kubernetes Note: these steps do not involve Splunk
Duration: 15 Minutes
1. Verify the code - Review service Navigate to the review directory
cd /home/ubuntu/realtime_enrichment/flask_apps/review/ Inspect review.py (realtime_enrichment/flask_apps/review)
cat review.py from flask import Flask, jsonify import random import subprocess review = Flask(__name__) num_reviews = 8635403 num_reviews = 100000 reviews_file = '/var/appdata/yelp_academic_dataset_review.json' @review.route('/') def hello_world(): return jsonify(message='Hello, you want to hit /get_review. We have ' + str(num_reviews) + ' reviews!') @review.route('/get_review') def get_review(): random_review_int = str(random.randint(1,num_reviews)) line_num = random_review_int + 'q;d' command = ["sed", line_num, reviews_file] # sed "7997242q;d" \u003cfile\u003e random_review = subprocess.run(command, stdout=subprocess.PIPE, text=True) return random_review.stdout if __name__ == "__main__": review.run(host ='0.0.0.0', port = 5000, debug = True) Inspect requirements.txt
Flask==2.0.2 Create a virtual environment and Install the necessary python packages
cd /home/ubuntu/realtime_enrichment/workshop/flask_apps_start/review/ pip freeze #note output pip install -r requirements.txt pip freeze #note output Start the REVIEW service. Note: You can stop the app with control+C
python3 review.py * Serving Flask app 'review' (lazy loading) * Environment: production ...snip... * Running on http://10.160.145.246:5000/ (Press CTRL+C to quit) * Restarting with stat 127.0.0.1 - - [17/May/2022 22:46:38] "GET / HTTP/1.1" 200 - 127.0.0.1 - - [17/May/2022 22:47:02] "GET /get_review HTTP/1.1" 200 - 127.0.0.1 - - [17/May/2022 22:47:58] "GET /get_review HTTP/1.1" 200 - Verify that the service is working
Open a new terminal and ssh into your ec2 instance. Then use the curl command in your terminal. curl http://localhost:5000 Or hit the URL http://{Your_EC2_IP_address}:5000 and http://{Your_EC2_IP_address}:5000/get_review with a browser curl localhost:5000 { "message": "Hello, you want to hit /get_review. We have 100000 reviews!" } curl localhost:5000/get_review {"review_id":"NjbiESXotcEdsyTc4EM3fg","user_id":"PR9LAM19rCM_HQiEm5OP5w","business_id":"UAtX7xmIfdd1W2Pebf6NWg","stars":3.0,"useful":0,"funny":0,"cool":0,"text":"-If you're into cheap beer (pitcher of bud-light for $7) decent wings and a good time, this is the place for you. Its generally very packed after work hours and weekends. Don't expect cocktails. \\n\\n-You run into a lot of sketchy characters here sometimes but for the most part if you're chilling with friends its not that bad. \\n\\n-Friendly bouncer and bartenders.","date":"2016-04-12 20:23:24"} Workshop Question What does this application do? Do you see the yelp dataset being used? Why did the output of pip freeze differ each time you ran it? Which port is the REVIEW app listening on? Can other python apps use this same port? 2. Create a REVIEW container To create a container image, you need to create a Dockerfile, run docker build to build the image referencing the Docker file and push it up to a remote repository so it can be pulled by other sources.
Create a Dockerfile Creating a Dockerfile typically requires you to consider the following: Identify an appropriate container image ubuntu vs. python vs. alpine/slim ubuntu - overkill, large image size, wasted resources when running in K8 this is a python app, so pick an image that is optimized for it avoid alpine for python Order matters you’re building layers. re-use the layers as much as possible have items that change often towards the end Other Best practices for writing Dockerfiles Dockerfile for review
FROM python:3.10-slim WORKDIR /app COPY requirements.txt /app RUN pip install -r requirements.txt COPY ./review.py /app EXPOSE 5000 CMD [ "python", "review.py" ] Create a container image (locally) Run ‘docker build’ to build a local container image referencing the Dockerfile
docker build docker build Output docker build -f Dockerfile -t localhost:8000/review:0.01 . [+] Building 35.5s (11/11) FINISHED =\u003e [internal] load build definition from Dockerfile 0.0s ...snip... =\u003e [3/5] COPY requirements.txt /app 0.0s =\u003e [4/5] RUN pip install -r requirements.txt 4.6s =\u003e [5/5] COPY ./review.py /app 0.0s =\u003e exporting to image 0.2s =\u003e =\u003e exporting layers 0.2s =\u003e =\u003e writing image sha256:61da27081372723363d0425e0ceb34bbad6e483e698c6fe439c5 0.0s =\u003e =\u003e naming to docker.io/localhost:8000/review:0.1 0.0 Push the container image into a container repository Run ‘docker push’ to place a copy of the REVIEW container to a remote location
docker push docker push Output docker push localhost:8000/review:0.01 The push refers to repository [docker.io/localhost:8000/review] 02c36dfb4867: Pushed ...snip... fd95118eade9: Pushed 0.1: digest: sha256:3651f740abe5635af95d07acd6bcf814e4d025fcc1d9e4af9dee023a9b286f38 size: 2202 Verify that the image is in Docker Hub. The same info can be found in Docker Desktop
get catalog get catalog Output curl -s http://localhost:8000/v2/_catalog {"repositories":["review"]} 3. Run REVIEW in Kubernetes Create K8 deployment yaml file for the REVIEW app
Reference: Creating a Deployment
review.deployment.yaml
apiVersion: apps/v1 kind: Deployment metadata: name: review labels: app: review spec: replicas: 1 selector: matchLabels: app: review template: metadata: labels: app: review spec: imagePullSecrets: - name: regcred containers: - image: localhost:8000/review:0.01 name: review volumeMounts: - mountPath: /var/appdata name: appdata volumes: - name: appdata hostPath: path: /var/appdata Notes regarding review.deployment.yaml:
labels - K8 uses labels and selectors to tag and identify resources In the next step, we’ll create a service and associate it to this deployment using the label replicas = 1 K8 allows you to scale your deployments horizontally We’ll leverage this later to add load and increase our ingestion rate regcred provides this deployment with the ability to access your dockerhub credentials which is necessary to pull the container image. The volume definition and volumemount make the yelp dataset visible to the container Create a K8 service yaml file for the review app.
Reference: Creating a service:
review.service.yaml
apiVersion: v1 kind: Service metadata: name: review spec: type: NodePort selector: app: review ports: - port: 5000 targetPort: 5000 nodePort: 30000 Notes about review.service.yaml:
the selector associates this service to pods with the label app with the value being review the review service exposes the review pods as a network service other pods can now ping ‘review’ and they will hit a review pod. a pod would get a review if it ran curl http://review:5000 NodePort service the service is accessible to the K8 host by the nodePort, 30000 Another machine that has this can get a review if it ran curl http://\u003ck8 host ip\u003e:30000 Apply the review deployment and service
kubectl apply -f review.service.yaml -f review.deployment.yaml Verify that the deployment and services are running:
kubectl get deployments kubectl get deployments output kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE review 1/1 1 1 19h kubectl get services kubectl get services output kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE review NodePort 10.43.175.21 \u003cnone\u003e 5000:30000/TCP 154d curl localhost curl localhost Output curl localhost:30000 { "message": "Hello, you want to hit /get_review. We have 100000 reviews!" } get review get review Output curl localhost:30000/get_review {"review_id":"Vv9rHtfBrFc-1M1DHRKN9Q","user_id":"EaNqIwKkM7p1bkraKotqrg","business_id":"TA1KUSCu8GkWP9w0rmElxw","stars":3.0,"useful":1,"funny":0,"cool":0,"text":"This is the first time I've actually written a review for Flip, but I've probably been here about 10 times. \\n\\nThis used to be where I would take out of town guests who wanted a good, casual, and relatively inexpensive meal. \\n\\nI hadn't been for a while, so after a long day in midtown, we decided to head to Flip. \\n\\nWe had the fried pickles, onion rings, the gyro burger, their special burger, and split a nutella milkshake. I have tasted all of the items we ordered previously (with the exception of the special) and have been blown away with how good they were. My guy had the special which was definitely good, so no complaints there. The onion rings and the fried pickles were greasier than expected. Though I've thought they were delicious in the past, I probably wouldn't order either again. The gyro burger was good, but I could have used a little more sauce. It almost tasted like all of the ingredients didn't entirely fit together. Something was definitely off. It was a friday night and they weren't insanely busy, so I'm not sure I would attribute it to the staff not being on their A game...\\n\\nDon't get me wrong. Flip is still good. The wait staff is still amazingly good looking. They still make delicious milk shakes. It's just not as amazing as it once was, which really is a little sad.","date":"2010-10-11 18:18:35"} Workshop Question What changes are required if you need to make an update to your Dockerfile now?
`,description:"",tags:null,title:"Code to Kubernetes - Python",uri:"/en/other/gdi/3-code-to-kubernetes/index.html"},{content:` 20 minutes Introduction to the Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Saving charts in a dashboard Introduction to SignalFlow 1. Dashboards Dashboards are groupings of charts and visualizations of metrics. Well-designed dashboards can provide useful and actionable insight into your system at a glance. Dashboards can be complex or contain just a few charts that drill down only into the data you want to see.
During this module we are going to create the following charts and dashboard and connect it to your Team page.
2. Your Teams’ Page Click on the from the navbar. As you have already been assigned to a team, you will land on the team dashboard.
We use the Example Team as an example here. The one in your workshop will be different!
This page shows the total number of team members, how many active alerts for your team and all dashboards that are assigned to your team. Right now they are no dashboards assigned but as stated before, we will add the new dashboard that you will create to your Teams page later.
3. Sample Charts To continue, click on All Dashboards on the top right corner of the screen. This brings you to the view that shows all the available dashboards, including the pre-built ones.
If you are already receiving metrics from a Cloud API integration or another service through the Splunk Agent you will see relevant dashboards for these services.
4. Inspecting the Sample Data Among the dashboards you will see a Dashboard group called Sample Data. Expand the Sample Data dashboard group by clicking on it, and then click on the Sample Charts dashboard.
In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.
Have a look through all the dashboards in this dashboard group (PART 1, PART 2, PART 3 and INTRO TO SPLUNK OBSERVABILITY CLOUD)
`,description:"",tags:null,title:"Working with Dashboards",uri:"/en/imt/dashboards/index.html"},{content:`1. DNS and Services in Kubernetes The Domain Name System (DNS) is a mechanism for linking various sorts of information with easy-to-remember names, such as IP addresses. Using a DNS system to translate request names into IP addresses makes it easy for end-users to reach their target domain name effortlessly.
Most Kubernetes clusters include an internal DNS service configured by default to offer a lightweight approach for service discovery. Even when Pods and Services are created, deleted, or shifted between nodes, built-in service discovery simplifies applications to identify and communicate with services on the Kubernetes clusters.
In short, the DNS system for Kubernetes will create a DNS entry for each Pod and Service. In general, a Pod has the following DNS resolution:
pod-name.my-namespace.pod.cluster-domain.example For example, if a Pod in the default namespace has the Pod name my_pod, and the domain name for your cluster is cluster.local, then the Pod has a DNS name:
my_pod.default.pod.cluster.local Any Pods exposed by a Service have the following DNS resolution available:
my_pod.service-name.my-namespace.svc.cluster-domain.example More information can be found here : DNS for Service and Pods
2. Review OTel receiver for PHP/Apache Inspect the YAML file ~/workshop/k3s/otel-apache.yaml and validate the contents using the following command:
cat ~/workshop/k3s/otel-apache.yaml This file contains the configuration for the OpenTelemetry agent to monitor the PHP/Apache deployment.
agent: config: receivers: receiver_creator: receivers: smartagent/apache: rule: type == "port" \u0026\u0026 pod.name matches "apache" \u0026\u0026 port == 80 config: type: collectd/apache url: http://php-apache-svc.apache.svc.cluster.local/server-status?auto extraDimensions: service.name: php-apache 3. Observation Rules in the OpenTelemetry config The above file contains an observation rule for Apache using the OTel receiver_creator. This receiver can instantiate other receivers at runtime based on whether observed endpoints match a configured rule.
The configured rules will be evaluated for each endpoint discovered. If the rule evaluates to true, then the receiver for that rule will be started as configured against the matched endpoint.
In the file above we tell the OpenTelemetry agent to look for Pods that match the name apache and have port 80 open. Once found, the agent will configure an Apache receiver to read Apache metrics from the configured URL. Note, the K8s DNS based URL in the above YAML for the service.
To use the Apache configuration, you can upgrade the existing Splunk OpenTelemetry Collector Helm chart to use the otel-apache.yaml file with the following command:
Helm Upgrade helm upgrade splunk-otel-collector \\ --set="splunkObservability.realm=$REALM" \\ --set="splunkObservability.accessToken=$ACCESS_TOKEN" \\ --set="clusterName=$(hostname)-k3s-cluster" \\ --set="splunkObservability.logsEnabled=true" \\ --set="splunkObservability.infrastructureMonitoringEventsEnabled=true" \\ splunk-otel-collector-chart/splunk-otel-collector \\ --namespace splunk \\ -f ~/workshop/k3s/splunk-defaults.yaml \\ -f ~/workshop/k3s/otel-apache.yaml NOTE The REVISION number of the deployment has changed, which is a helpful way to keep track of your changes.
Release "splunk-otel-collector" has been upgraded. Happy Helming! NAME: splunk-otel-collector LAST DEPLOYED: Tue Jan 31 16:57:22 2023 NAMESPACE: splunk STATUS: deployed REVISION: 2 TEST SUITE: None 4. Kubernetes ConfigMaps A ConfigMap is an object in Kubernetes consisting of key-value pairs which can be injected into your application. With a ConfigMap, you can separate configuration from your Pods.
Using ConfigMap, you can prevent hardcoding configuration data. ConfigMaps are useful for storing and sharing non-sensitive, unencrypted configuration information.
The OpenTelemetry collector/agent uses ConfigMaps to store the configuration of the agent and the K8s Cluster receiver. You can/will always verify the current configuration of an agent after a change by running the following commands:
kubectl get cm -n splunk Workshop Question How many ConfigMaps are used by the collector?
When you have list of ConfigMaps from the namespace, select the one for the otel-agent and view it with the following command:
kubectl get cm splunk-otel-collector-otel-agent -n splunk -o yaml NOTE The option -o yaml will output the content of the ConfigMap in a readable YAML format.
Workshop Question Is the configuration from otel-apache.yaml visible in the ConfigMap for the collector agent?
5. Review PHP/Apache deployment YAML Inspect the YAML file ~/workshop/k3s/php-apache.yaml and validate the contents using the following command:
cat ~/workshop/k3s/php-apache.yaml This file contains the configuration for the PHP/Apache deployment and will create a new StatefulSet with a single replica of the PHP/Apache image.
A stateless application is one that does not care which network it is using, and it does not need permanent storage. Examples of stateless apps may include web servers such as Apache, Nginx, or Tomcat.
apiVersion: apps/v1 kind: StatefulSet metadata: name: php-apache spec: updateStrategy: type: RollingUpdate selector: matchLabels: run: php-apache serviceName: "php-apache-svc" replicas: 1 template: metadata: labels: run: php-apache spec: containers: - name: php-apache image: ghcr.io/splunk/php-apache:latest ports: - containerPort: 80 resources: limits: cpu: "8" memory: "9Mi" requests: cpu: "6" memory: "4Mi" --- apiVersion: v1 kind: Service metadata: name: php-apache-svc labels: run: php-apache spec: ports: - port: 80 selector: run: php-apache 6. Deploy PHP/Apache Create an apache namespace then deploy the PHP/Apache application to the cluster.
Create the apache namespace:
kubectl create namespace apache Deploy the PHP/Apache application:
kubectl apply -f ~/workshop/k3s/php-apache.yaml -n apache Ensure the deployment has been created:
kubectl get statefulset -n apache Workshop Question What metrics for your Apache instance are being reported in the Apache Navigator?
Tip: Use the Navigator Sidebar and click on the service name.
Workshop Question Using Log Observer what is the issue with the PHP/Apache deployment?
Tip: Adjust your Table settings by clicking on the cog to use only object.involvedObject.name, object.message and k8s.cluster.name. Make sure you unselect _raw!
`,description:"",tags:null,title:"Deploying PHP/Apache",uri:"/en/other/hpa/3-deploy-apache/index.html"},{content:` 10 minutes Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules 1. Introduction Splunk Observability Cloud uses detectors, events, alerts, and notifications to keep you informed when certain criteria are met. For example, you might want a message sent to a Slack channel or to an email address for the Ops team when CPU Utilization has reached 95%, or when the number of concurrent users is approaching a limit that might require you to spin up an additional AWS instance.
These conditions are expressed as one or more rules that trigger an alert when the conditions in the rules are met. Individual rules in a detector are labeled according to criticality: Info, Warning, Minor, Major, and Critical.
2. Creating a Detector In Dashboards click on your Custom Dashboard Group (that you created in the previous module) and then click on the dashboard name.
We are now going to create a new detector from a chart on this dashboard. Click on the bell icon on the Latency vs Load chart, and then click New Detector From Chart.
In the text field next to Detector Name, ADD YOUR INITIALS before the proposed detector name.
Naming the detector It’s important that you add your initials in front of the proposed detector name.
It should be something like this: XYZ’s Latency Chart Detector.
Click on Create Alert Rule In the Detector window, inside Alert signal, the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert.
Click on Proceed to Alert Condition 3. Setting Alert condition In Alert condition, click on Static Threshold and then on Proceed to Alert Settings In Alert Settings, enter the value 290 in the Threshold field. In the same window change Time on top right to past day (-1d).
4. Alert pre-flight check A pre-flight check will take place after 5 seconds. See the Estimated alert count. Based on the current alert settings, the amount of alerts we would have received in 1 day would have been 3.
About pre-flight checks Once you set an alert condition, the UI estimates how many alerts you might get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day.
Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using the Splunk Observability Cloud.
To read more about detector previewing, please visit this link Preview detector alerts.
Click on Proceed to Alert Message 5. Alert message In Alert message, under Severity choose Major.
Click on Proceed to Alert Recipients Click on Add Recipient and then on your email address displayed as the first option.
Notification Services That’s the same as entering that email address OR you can enter another email address by clicking on E-mail….
This is just one example of the many Notification Services the suite has available. You can check this out by going to the Integrations tab of the top menu, and see Notification Services.
6. Alert Activation Click on Proceed to Alert Activation In Activate… click on Activate Alert Rule If you want to get alerts quicker you edit the rule and lower the value from 290 to say 280.
If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metrics from the last 1 hour.
Click on the in the navbar and then click on Detectors. You can optionally filter for your initials. You will see you detector listed here. If you don’t then please refresh your browser.
Congratulations! You have created your first detector and activated it!
`,description:"",tags:null,title:"Working with Detectors",uri:"/en/other/o11y4rookies/imt/detectors/index.html"},{content:`Lambdas in Splunk APM Now it’s time to check how your Lambda traffic has been captured in Splunk APM.
Navigate to your Splunk Observability Cloud Select APM from the Main Menu and then select your APM Environment. Your APM environment should be in the format $(hostname)-apm-lambda where the hostname value is a four letter name of your lab host. (Check it by looking at your command prompt, or by running echo $(hostname)).
Note It may take a few minutes for you traces to appear in Splunk APM. Try hitting refresh on your browser until you find your environement name in the list of Envrionments Go to Explore the Service Map to see the Dependencies between your Lambda Functions.
You should be able to see the producer-lambda and the call it is making to Kinesis service.
Workshop Question What about your consumer-lambda?
Click into Traces and examine some traces that container procuder function calls and traces with consumer function calls.
We can see the producer-lambda putting a Record on the Kinesis stream. But the action of consumer-function is disconnected!
This is because the Trace Context is not being propagated.
This is not something that is supported automatically Out-of-the-Box by Kinesis service at the time of this lab. Our Distributed Trace stops at Kinesis inferred service, and we can’t see the propagation any further.
Not yet…
Let’s see how we work around this in the next section of this lab.
`,description:"",tags:null,title:"Lambdas in Splunk APM",uri:"/en/other/lambda-kinesis/3-lambdas-in-splunk/index.html"},{content:`Users and Workflows As we go through this workshop we will be switching roles from SRE to Developer. First we will start with alert responders or SREs who will identify an issue in Splunk Observability UI. Next, we will jump to a Developer Role to see how a Developer will debug and repair/fix a software problem using trace data provided by our SRE.
Of course, we are not requiring 2 people for this workshop as each participant will play both roles.
Today we will learn Today we will learn how Splunk APM with Full Fidelity tracing can accelerate the time to repair for Development teams. We will focus on the full fidelity data ( In the form of traces ) that an SRE or alert responder would send to a developer to then repair/fix software. We will do this with both Auto-Instrumentation data and Custom attributes or Custom Tags, via Manual Instrumentation data.
While we will be spending time Debugging code, …. Don’t worry, …there is no programming experience necessary, as our goal here is for every participant to understand how using Custom Attributes/Tags in Splunk APM @ Full Fidelity accelerates Mean Time to Repair Software problems for Development Teams.
Important Definitions Let’s define a few terms for those new to APM / Software Development or Java
What Are Custom Attributes / Custom Tags in Splunk APM ? First, you will hear poeple refer to Custom Attributes in the context of Splunk Enterprise, however in Splunk APM Custom Attributes are called Custom Tags as defined in Opentelemetry and shown in Splunk APM Tag Splotlight.
What is a Function or a method in Java? A Function in most languages, including Java, is a logical chunk of code that – when executed – solves a repeatable task. This is basically what development teams spend thier time building and where software issues will most commonly be.
What is an Exception in Java? An exception is an exceptional error condition that indicates abonormal behavior, or an unhandled condition, that interrupts program execution abnormally.
`,description:"",tags:null,title:"Overview of the Workshop",uri:"/en/other/dev-mttr-custom-tags/3-overview/index.html"},{content:`1. Enable RUM For the Real User Monitoring (RUM) instrumentation, we will add the Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web snippet in the pages, we will use the wizard again Data Management → Add Integration → RUM Instrumentation → Browser Instrumentation.
Select the preconfigured RUM ACCESS TOKEN from the dropdown, click Next. Enter App name and Environment using the following syntax:
[hostname]-petclinic-service - replacing [hostname] with your actual hostname. [hostname]-petclinic-env - replacing [hostname] with your actual hostname. Then you’ll need to select the workshop RUM token and define the application and environment names. The wizard will then show a snipped of HTML code that needs to be place at the top at the pages in the \u003chead\u003e section. In this example we are using:
Application Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env Copy the generated code snippet in the wizard or copy and edit the snippet below accordingly. You need to replace \u003cREALM\u003e, \u003cRUM_ACCESS_TOKEN\u003e and \u003chostname\u003e with the actual values.
\u003cscript src="https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js" crossorigin="anonymous"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: "https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum", rumAuth: "\u003cRUM_ACCESS_TOKEN\u003e", app: "\u003chostname\u003e-petclinic-service", environment: "\u003chostname\u003e-petclinic-env" }); \u003c/script\u003e The Spring PetClinic application uses a single HTML page as the “layout” page, that is reused across all pages of the application. This is the perfect location to insert the Splunk RUM Instrumentation Library as it will be loaded in all pages automatically.
Let’s then edit the layout page:
vi src/main/resources/templates/fragments/layout.html Next, insert the snippet we generated above in the \u003chead\u003e section of the page. Now we need to rebuild the application and run it again:
2. Rebuild PetClinic Run the maven command to compile/build/package PetClinic:
./mvnw package -Dmaven.test.skip=true java \\ -Dotel.service.name=$(hostname)-petclinic-service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -Dotel.resource.attributes=deployment.environment=$(hostname)-petclinic,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Then let’s visit the application using a browser to generate real-user traffic http://\u003cVM_IP_ADDRESS\u003e:8080, now we should see RUM traces being reported.
Let’s visit RUM and see some of the traces and metrics Hamburger Menu → RUM and you will see some of the Spring PetClinic URLs showing up in the UI.
When you drill down into a RUM trace you will see a link to APM in the spans. Clicking on the trace ID will take you to the corresponding APM trace for the current RUM trace.
`,description:"",tags:null,title:"3. Real User Monitoring",uri:"/en/other/pet-clinic/rum/index.html"},{content:`A receiver, which can be push or pull based, is how data gets into the Collector. Receivers may support one or more data sources. Generally, a receiver accepts data in a specified format, translates it into the internal format and passes it to processors and exporters defined in the applicable pipelines.
Host Metrics Receiver The Host Metrics Receiver generates metrics about the host system scraped from various sources. This is intended to be used when the collector is deployed as an agent which is what we will be doing in this workshop.
Let’s edit our /etc/otelcontribcol/config.yaml file and configure the hostmetrics receiver. Insert the following YAML under the receivers section, taking care to indent by two spaces e.g.
Host Metrics Receiver Configuration Host Metrics Receiver Configuration Complete receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] You will also notice another receiver called prometheus. Prometheus is an open-source toolkit used by the OpenTelemetry Collector. This receiver is used to scrape metrics from the OpenTelemetry Collector itself. These metrics can then be used to monitor the health of the collector.
Let’s modify the prometheus receiver to clearly show that it is for collecting metrics from the collector itself. Change the config.yaml file to look like this:
Prometheus Receiver Configuration Prometheus Receiver Configuration Complete prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] Example Dashboard - Prometheus metrics The following screenshot shows an example dashboard of the metrics the Prometheus internal receiver collects from the OpenTelemetry Collector. Here, we can see accepted and sent spans, metrics and log records.
Other Receivers You will notice in the default configuration there are other receivers (otlp, opencensus, jaeger and zipkin). These are used to receive telemetry data from other sources. We will not be using these receivers in this workshop and can be left as they are.
`,description:"",tags:null,title:"OpenTelemetry Collector Receivers",uri:"/en/conf/opentelemetry-collector/3-receivers/index.html"},{content:` Visit the RUM landing page and and check the overview of the performance of all your RUM enabled applications with the Application Summary Dashboard (Both Mobile and Web based) 1. Visit the RUM Landing Page Login into your Splunk IM/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your the RUM Landing Page.
The goal of this page is to give you in a single page, a clear indication of the health, performance and potential errors found in your application(s) and allow you to dive deeper into the information about your User Sessions collected from your web page/App. You will have a pane for each of your active RUM applications. (The view below is the default expanded view)
If you have multiple applications, (which will be the case when every attendee is using their own ec2 instance for the RUM workshop), the pane view may be automatically reduced by collapsing the panes as shown below:
You can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.
First find the right application to use for the workshop:
If you are participating in a stand alone RUM workshop, the workshop leader will tell you the name of the application to use, in the case of a combined workshop, it will follow the naming convention we used for IM and APM and use the ec2 node name as a unique id like jmcj-rum-app as shown as the last app in the screenshot above.
2. Configure the RUM Application Summary Dashboard Header Section RUM Application Summary Dashboard consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:
A drop down for the Time Window you’re reviewing (You are looking at the past 15 minutes by default) A drop down to select the Environment1 you want to look at. This allows you to focus on just the subset of applications belonging to that environment, or Select all to view all available. A drop down list with the various Apps being monitored. You can use the one provided by the workshop host or select your own. This will focus you on just one application. A drop down to select the Source, Browser or Mobile applications to view. For the Workshop leave All selected. A hamburger menu located at the right of the header allowing you to configure some settings of your Splunk RUM application. (We will visit this in a later section). For the workshop lets do a deeper dive into the Application Summary screen in the next section: Check Health Browser Application
A deployment environment is a distinct deployment of your system or application that allows you to set up configurations that don’t overlap with configurations in other deployments of the same application. Separate deployment environments are often used for different stages of the development process, such as development, staging, and production.A common application deployment pattern is to have multiple, distinct application environments that don’t interact directly with each other but that are all being monitored by Splunk APM or RUM: for instance, quality assurance (QA) and production environments, or multiple distinct deployments in different datacenters, regions or cloud providers.  ↩︎
`,description:"",tags:null,title:"3. RUM Landing Page",uri:"/en/other/o11y4rookies/rum/4-rum-landing/index.html"},{content:` Check the original HEAD section of your Online-boutique webpage (or use the examples here) in your browser Find the Web address of your workshop hosts Online Boutique Compare the changes made to the hosts Online-Boutique and compare with the base one. 1. Review the original code of your NON RUM Online-Boutique If you have access to an EC2 instance and have previously installed the Online Boutique as part of the APM session, you can view it on port 81 of the EC2 instance’s IP address.
If you have not got access to an EC2 instance with the Online Boutique installed then your workshop instructor will provide you with the Online Boutique URL that does not have RUM installed so that you can complete the next steps.
2. Obtain RUM Access Token As this Deployment we are about to do is also used as part of the RUM workshop section, you will need to obtain your RUM Access Token from the Splunk UI. You can find the workshop Access Token by clicking » bottom left or the menu option and then selecting Settings → Access Tokens.
Expand the RUM workshop token that your host has instructed you to use e.g. O11y-Workshop-RUM-TOKEN, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. Please do not use the Default token! Make sure the token has RUM as its Authorization Scope.
Please do not attempt to create your own token We have created a RUM Token specifically for this workshop with the appropriate settings for the exercises you will be performing
Create the RUM_TOKEN environment variable to use in the proceeding shell script to personalize your deployment.
Export Variables export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e 2. Deploy Online Boutique To deploy the Online Boutique application into K3s, run the apm config script, then apply the deployment:
Deploy Online Boutique Deployment Output cd ~/workshop/apm ./apm-config.sh -r kubectl apply -f deployment.yaml deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/paymentservice created service/paymentservice created deployment.apps/emailservice created service/emailservice created deployment.apps/adservice created service/adservice created deployment.apps/cartservice created service/cartservice created deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created In case of a message about a VARIABLE being unset Please undeploy the APM environment by running kubectl delete -f deployment.yaml Before exporting the variable as described in the guide and rerunning the deployment script above.
Open your web browser and go to the Online Boutique. (The one you previously used, or the one provided by the Workshop instructor). You will see the Non RUM Online Boutique running.
Follow the instructions for your preferred browser below:
1.1 Chrome, FireFox \u0026 Microsoft Edge Users - Check the Web page source In Chrome \u0026 Firefox or Microsoft Edge you can right click on the Online-Boutique site, you will have an option to “View Page Source”
Selecting it will show you the HTML page source code in a separate Tab.
If successful you can skip to 2 - Review the unchanged HEAD section.
1.2 Safari Users - Check the Web page source For Safari users, you may have to enable the extra menu in Safari by selecting ‘Preferences’ under Safari in the OS X menu bar.
Then in the dialog that pops up, under the ‘Advanced’ pane select the checkbox that says ‘Show Develop menu in menu bar. ‘ and close the Dialog box.
You can now right click on the Online-Boutique and you now will have an option ‘Show Page Source’.
If you select that option on the Online-Boutique you will see the HTML source code as shown below:
If successful you can skip to 2 - Review the unchanged HEAD section.
1.3 Internet Explorer Users - Check the Web page source For Internet Explorer 11 Users, you may have trouble with this exercise as it will require a specific version of the Splunk Open Telemetry Javascript for Web/RUM.
However you will be able to see the changes required by right clicking on the Online-Boutique site, you see an option to “View Source”
If you select that option on the Online-Boutique you will see the HTML source code as shown below:
2 - Review the unchanged HEAD section The changes for RUM will be placed in the HEAD section of your Web page, Below are the original lines as you should have it in your local Base version.
There is no reference to the Splunk or Open Telemetry Beacon (The function that is used to send RUM Metrics and Traces )
3. Find the web (URL) of the RUM enabled Online Boutique The Online Boutique we are going to use for RUM is viewable on port 81 of the RUM Enabled instance’s IP address and the url will be provided to you by the workshop instructor at this point.
We are all connecting to the extra RUM Enabled Online Boutique provided by the workshops instructor for this RUM session. Open a new web browser and go to http://{==RUM-HOST-EC2-IP==}:81/ where you will then be able to see the RUM enabled Online Boutique running. Again, view the source of the HTML Page as described in the previous section:
4. Review the Changes made to enable RUM in the HEAD section of the RUM enabled Online-Boutique The changes needed for RUM are placed in the HEAD section of the hosts Web page, Below is the hosts updated HEAD section with the changes required to enable RUM:
The first three lines (marked in red) have been added to the HEAD section of the host Web page to enable RUM Tracing, the last three (marked in blue) are optional and used to enable Custom RUM events.
\u003cscript src="https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js" type="text/javascript"\u003e\u003c/script\u003e \u003cscript\u003ewindow.SplunkRum \u0026\u0026 window.SplunkRum.init({beaconUrl: "https://rum-ingest.eu0.signalfx.com/v1/rum", rumAuth: "1wCqZVUWIP5XSdNjPoQRFg", app: "ksnq-rum-app", environment: "ksnq-rum-env"});\u003c/script\u003e \u003cscript\u003e const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); \u003c/script\u003e The first part is to indicate where to download the Splunk Open Telemetry Javascript file from: https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js (This can also be loaded locally if so required) The second line defines the location where to send the traces to in the beacon url: {beaconUrl: "https://rum-ingest.eu0.signalfx.com/v1/rum" It also adds an Access Token to : rumAuth: "1wCqZVUWIP5XSdNjPoQRFg" (this of course is an example, you can create multiple RUM Access Tokens for all your applications) And it is used to add identification tags like the application Name and environment to the RUM trace for use in the SPLUNK RUM UI: app: "ksnq-rum-app", environment: "ksnq-rum-env"} Info In this example the app name is ksnq-rum-app, this will be different in the Workshop. Check with your host what the app name and environment to use in the RUM session will be and make a note of it!
The above two lines are all that is required to enable RUM on your website!
The (blue) optional section that uses var tracer=Provider.getTracer('appModuleLoader'); will add a custom event for every page change allow you to better track your website conversions and usage.
`,description:"",tags:null,title:"3. Example of RUM enablement in your Website",uri:"/en/rum/3-setup/index.html"},{content:`1 Creating a new chart Let’s now create a new chart and save it in our dashboard!
Select the plus icon (top right of the UI) and from the drop down, choose the option Chart. Or click on the \u003cul\u003e \u003cli\u003eNew Chart\u003c/li\u003e \u003c/ul\u003e Button to create a new chart.
You will now see a chart template like the following.
Let’s enter a metric to plot. We are still going to use the metric demo.trans.latency.
In the Plot Editor tab under Signal enter demo.trans.latency.
You should now have a familiar line chart. Please switch the time to 15 mins.
2. Filtering and Analytics Let’s now select the Paris datacenter to do some analytics - for that we will use a filter.
Let’s go back to the Plot Editor tab and click on Add Filter , wait until it automatically populates, choose demo_datacenter, and then Paris.
In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm).
For info on the Percentile function and the other functions see Chart Analytics.
3. Using Timeshift analytical function Let’s now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A.
You will see a new row identical to A, called B, both visible and plotted.
For Signal B, in the F(x) column add the analytic function Timeshift and enter 1w (or 7d for 7 days), and click outside to confirm.
Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B.
Click on Close.
We now see plots for Signal A (the past 15 minutes) as a blue plot, and the plots from a week ago in pink.
In order to make this clearer we can click on the Area chart icon to change the visualization.
We now can see when last weeks latency was higher!
Next, click into the field next to Time on the Override bar and choose Past Hour from the dropdown.
4. Using Formulas Let’s now plot the difference of all metric values for a day with 7 days in between.
Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C.
We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time.
Lets look at the Signalflow that drives our Charts and Detectors!
`,description:"",tags:null,title:"3.3 Using Filters \u0026 Formulas",uri:"/en/imt/dashboards/filtering/index.html"},{content:` 45 minutes This workshop will ..
For this workshop Splunk has prepared an Ubuntu Linux instance in AWS/EC2 all pre-configured for you.
To get access to the instance that you will be using in the workshop, please visit the URL provided by the workshop leader.
Splunk Observability Cloud You must have the ability to send traces to Splunk Observability Cloud. If you do not have an account already, please start a trial here: https://www.splunk.com/en_us/download/apm-free-trial.html
Workshop Story Here at Splunk Instruments, our business is expanding!
We have recently added 3 new locations: Two locations in the USA (Colorado and Chicago) and one international location in Sri Lanka.
Our technical staff has already on-boarded the data from these new locations and incorporated them into our inventory application and it is our job to review these improvements and send any issues back to our developers for repairs.
We now have a total of 6 locations!
`,description:"This workshop will equip you with...",tags:null,title:"Improving MTTR with Custom Tags",uri:"/en/other/dev-mttr-custom-tags/index.html"},{content:`Splunk RUM is the industry’s only end to end, full fidelity Real User Monitoring solution. It is built to optimize performance and aid in faster troubleshooting, giving you full visibility into end-user experiences.
Splunk RUM allows you to identify performance problems in your Web and or Mobile applications that impact the customer experience. We support benchmarking and measuring page performance with core web vitals. This includes but not limited to: W3C timings, the ability to identify long running tasks, along with everything that can impact your page load.
With Splunk’s end to end monitoring capabilities you are able to view the latency between all of the services that make up your application, from the service itself through to infrastructure metrics such as database calls and everything in between.
Our full fidelity end to end monitoring solution captures 100% of your span data. We do not sample, we are framework agnostic and Open Telemetry standardized.
More often than not we find that the frontend and backend application’s performance are interdependent. Fully understanding and being able to visualize the link between your backend services and your user experience is increasingly important. To see the full picture, Splunk RUM provides seamless correlation between our front end and back end microservices. If your users are experiencing less than optimal conditions on your web based application due to an issue related to your microservice or infrastructure, Splunk will be able to detect this issue and alert you.
To complete the picture and offer full visibility, Splunk is also able to show in-context logs and events to enable deeper troubleshooting and root-cause analysis.
`,description:"End-to-end visibility helps you pinpoint customer-impacting issues from web browsers and native mobile apps to your backend services.",tags:null,title:"Splunk RUM",uri:"/en/other/o11y4rookies/rum/index.html"},{content:`Splunk RUM is the industry’s only end to end, full fidelity Real User Monitoring solution. It is built to optimize performance and aid in faster troubleshooting, giving you full visibility into end-user experiences.
Splunk RUM allows you to identify performance problems in your Web and or Mobile applications that impact the customer experience. We support benchmarking and measuring page performance with core web vitals. This includes but not limited to: W3C timings, the ability to identify long running tasks, along with everything that can impact your page load.
With Splunk’s end to end monitoring capabilities you are able to view the latency between all of the services that make up your application, from the service itself through to infrastructure metrics such as database calls and everything in between.
Our full fidelity end to end monitoring solution captures 100% of your span data. We do not sample, we are framework agnostic and Open Telemetry standardized.
More often than not we find that the frontend and backend application’s performance are interdependent. Fully understanding and being able to visualize the link between your backend services and your user experience is increasingly important. To see the full picture, Splunk RUM provides seamless correlation between our front end and back end microservices. If your users are experiencing less than optimal conditions on your web based application due to an issue related to your microservice or infrastructure, Splunk will be able to detect this issue and alert you.
To complete the picture and offer full visibility, Splunk is also able to show in-context logs and events to enable deeper troubleshooting and root-cause analysis.
`,description:"End-to-end visibility helps you pinpoint customer-impacting issues from web browsers and native mobile apps to your backend services.",tags:null,title:"Splunk RUM",uri:"/en/rum/index.html"},{content:`Aim Routing Keys map the incoming alert messages from your monitoring system to an Escalation Policy which in turn sends the notifications to the appropriate team.
Note that routing keys are case insensitive and should only be composed of letters, numbers, hyphens, and underscores.
The aim of this module is for you to create some routing keys and then link them to your Escalation Policies you have created in the previous exercise.
1. Instance ID Each participant requires a unique Routing Key so we use the Hostname of the EC2 Instance you were allocated. We are only doing this to ensure your Routing Key is unique and we know all Hostnames are unique. In a production deployment the Routing Key would typically reflect the name of a System or Service being monitored, or a Team such as 1st Line Support etc.
Your welcome e-mail informed you of the details of your EC2 Instance that has been provided for you to use during this workshop and you should have logged into this as part of the 1st exercise.
The e-mail also contained the Hostname of the Instance, but you can also obtain it from the Instance directly. To get your Hostname from within the shell session connected to your Instance run the following command:
Export Hostname Example Output echo \${HOSTNAME} zevn It is very important that when creating the Routing Keys you use the 4 letter hostname allocated to you as a Detector has been configured within Splunk Infrastructure Monitoring using this hostname, so any deviation will cause future exercises to fail.
2 Create Routing Keys Navigate to Settings on the main menu bar, you should now be at the Routing Keys page.
You are going to create the following two Routing Keys using the naming conventions listed in the following table, but replacing {==HOSTNAME==} with the value from above and replace TEAM_NAME with the team you were allocated or created earlier.
Routing Key Escalation Policies HOSTNAME_PRI TEAM_NAME : Primary HOSTNAME_WR TEAM_NAME : Waiting Room There will probably already be a number of Routing Keys configured, but to add a new one simply scroll to the bottom of the page and then click Add Key
In the left hand box, enter the name for the key as per the table above. In the Routing Key column, select your Teams Primary policy from the drop down in the Escalation Polices column. You can start typing your Team Name to filter the results.
Note If there are a large number of participants on the workshop, resulting in an unusually large number of Escalation Policies sometimes the search filter does not list all the Policies under your Team Name. If this happens instead of using the search feature, simply scroll down to your team name, all the policies will then be listed.
Repeat the above steps for both Keys, xxxx_PRI and xxxx_WR, mapping them to your Teams Primary and Waiting Room policies.
You should now have two Routing Keys configured, similar to the following:
Tip You can assign a Routing Key to multiple Escalation Policies if required by simply selecting more from the list
If you now navigate back to Teams → [Your Team Name] → Escalation Policies and look at the settings for your Primary and Waiting Room polices you will see that these now have Routes assigned to them.
The 24/7 policy does not have a Route assigned as this will only be triggered via an Execute Policy escalation from the Primary policy.
Please wait for the instructor before proceeding to the Incident Lifecycle/Overview module.
`,description:"",tags:null,title:"Creating Routing Keys",uri:"/en/oncall/getting_started/routing/index.html"},{content:`Example Trace You should now see the entire trace along with the spans for the example trace that was selected. Spans which have errors are indicated by a red exclamation mark beside it. If you have a number such as x6 in a grey box, click it to expand the compacted paymentservice spans.
Now click one of the paymentservice spans with the red exclamation mark to expand it and see the associated metadata and some error details. Note that we are able to see that this error is caused by a 401 error and other useful information such as ‘tenant’ and ‘version’ is also displayed.
So we now know that the error is caused by an Invalid Request but we don’t know what exact request. At the bottom of the page you should see a contextual link to Logs, clink on this link to view the logs associated with this span.
You should now be looking at a Log Observer dashboard simialar to the image below.
We can use the filter to display only the error logs. Click on ERROR in the top right hand corner, then Add to filter
You should now have a shorter list of log entries which have a severity of ERROR
Select any of the entries to view the details. We can now see how the error was caused by the use of an Invalid API Token that our developers have accidentally pushed to production!
Congratulations, you have now completed the APM Workshop.
`,description:"",tags:null,title:"2.3 Example trace",uri:"/en/apm/using-splunk-apm/example_trace/index.html"},{content:`1. Introduction Let’s take a look at SignalFlow - the analytics language of Observability Cloud that can be used to setup monitoring as code.
The heart of Splunk Infrastructure Monitoring is the SignalFlow analytics engine that runs computations written in a Python-like language. SignalFlow programs accept streaming input and produce output in real time. SignalFlow provides built-in analytical functions that take metric time series (MTS) as input, perform computations, and output a resulting MTS.
Comparisons with historical norms, e.g. on a week-over-week basis Population overviews using a distributed percentile chart Detecting if the rate of change (or other metric expressed as a ratio, such as a service level objective) has exceeded a critical threshold Finding correlated dimensions, e.g. to determine which service is most correlated with alerts for low disk space Infrastructure Monitoring creates these computations in the Chart Builder user interface, which lets you specify the input MTS to use and the analytical functions you want to apply to them. You can also run SignalFlow programs directly by using the SignalFlow API.
SignalFlow includes a large library of built-in analytical functions that take a metric time series as an input, performs computations on its datapoints, and outputs time series that are the result of the computation.
Info For more information on SignalFlow see Analyze incoming data using SignalFlow.
2. View SignalFlow In the chart builder, click on View SignalFlow.
You will see the SignalFlow code that composes the chart we were working on. You can now edit the SignalFlow directly within the UI. Our documentation has the full list of SignalFlow functions and methods.
Also, you can copy the SignalFlow and use it when interacting with the API or with Terraform to enable Monitoring as Code
SignalFlow A = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).publish(label='A', enable=False) B = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).timeshift('1w').publish(label='B', enable=False) C = (A-B).publish(label='C') Click on View Builder to go back to the Chart Builder UI.
Let’s save this new chart to our Dashboard!
`,description:"",tags:null,title:"2.4 SignalFlow",uri:"/en/other/o11y4rookies/imt/dashboards/signalflow/index.html"},{content:`1. Introduction Let’s take a look at SignalFlow - the analytics language of Observability Cloud that can be used to setup monitoring as code.
The heart of Splunk Infrastructure Monitoring is the SignalFlow analytics engine that runs computations written in a Python-like language. SignalFlow programs accept streaming input and produce output in real time. SignalFlow provides built-in analytical functions that take metric time series (MTS) as input, perform computations, and output a resulting MTS.
Comparisons with historical norms, e.g. on a week-over-week basis Population overviews using a distributed percentile chart Detecting if the rate of change (or other metric expressed as a ratio, such as a service level objective) has exceeded a critical threshold Finding correlated dimensions, e.g. to determine which service is most correlated with alerts for low disk space Infrastructure Monitoring creates these computations in the Chart Builder user interface, which lets you specify the input MTS to use and the analytical functions you want to apply to them. You can also run SignalFlow programs directly by using the SignalFlow API.
SignalFlow includes a large library of built-in analytical functions that take a metric time series as an input, performs computations on its datapoints, and outputs time series that are the result of the computation.
Info For more information on SignalFlow see Analyze incoming data using SignalFlow.
2. View SignalFlow In the chart builder, click on View SignalFlow.
You will see the SignalFlow code that composes the chart we were working on. You can now edit the SignalFlow directly within the UI. Our documentation has the full list of SignalFlow functions and methods.
Also, you can copy the SignalFlow and use it when interacting with the API or with Terraform to enable Monitoring as Code
SignalFlow A = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).publish(label='A', enable=False) B = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).timeshift('1w').publish(label='B', enable=False) C = (A-B).publish(label='C') Click on View Builder to go back to the Chart Builder UI.
Let’s save this new chart to our Dashboard!
`,description:"",tags:null,title:"3.4 SignalFlow",uri:"/en/imt/dashboards/signalflow/index.html"},{content:` Get familiar with the UI and options available from this landing page Identify Page Views/Errors and Request/Errors and Java Script Errors in a single view Check the Web Vitals metrics and any Detector that has fired for in relation to your Browser Application 1. Application Summary Dashboard Overview 1.1. Header Bar As seen in the previous section the RUM Application Summary Dashboard consists of 5 major sections. The first section is the selection header, where you can collapse the Pane via the Browser icon or the \u003e in front of the application name, which is jmcj-rum-app in the example below. It also provides access to the Application Overview page if you click the link with your application name which is jmcj-rum-app in the example below.
Further, you can also open the Application Overview or App Health Dashboard via the triple dot menu on the right.
First use the View Dashboard link to open the Browser App Health Dashboard which should open in a new tab. Then switch back to original RUM tab, and then use the Open Application Overview link, or click on the name of the app to launch the Application Overview dashboard.
We will looking at the Application Overview and Browser App Health Dashboards in detail in the following sections.
2. Application Overview The RUM Application Overview Dashboard is focused on providing you with at a glance overview of the status of your application.
2.1. Page Views / Errors \u0026 Network Requests / Errors The first section shows Page Views / Errors, \u0026 Network Requests and Errors charts show the quantity and trend of these issues in your application. This could be Javascript errors, or failed network calls to back end services.
In the example above you can see that there are no failed network calls in the Network chart, but in the Page View chart you can see that a number of pages do experience some errors. These are often not visible for regular users, but can seriously impact the performance of your web site.
You can see the count of the Page Views / Network Requests / Errors by hovering over the charts.
2.2. JavaScript Errors With the second section of the RUM Application Summary Dashboard we are showing you an overview of the JavaScript errors occurring in your application, along with a count of each error.
In the example above you can see there are three JavaScript errors, one that appears 29 times in the selected time slot, and the other two each appear 12 times.
If you click on one of the errors a pop-out opens that will show a summary (below) of the errors over time, along with a Stack Trace of the JavaScript error, giving you an indication of where the problems occurred. (We will see this in more detail in one of the following sections)
2.3. Web Vitals The third section of the RUM Application Summary Dashboard is showing you the crucial (google) Web Vitals, three metrics, that are used by Google in its ranking system, and give a very good indication of the speed of your site for your end users.
As you can see our site is well behaved and scores Good for all three Metrics. These metrics can be used to identify the effect changes to your application have, and help you improve the performance of your site.
If you click on any of the Metrics shown in the Web Vitals pane you will be taken to the corresponding Tag Spotlight Dashboard. e.g. clicking on the Largest Contentful Paint (LCP) chartlet, you will be taken to a dashboard similar to the screen shot below, that gives you timeline and table views for how this metric has performed. This should allow you to spot trends and identify where the problem may be more common, such as an OS or browser version, .
2.4. Most Recent Detectors The fourth and final section of the RUM Application Summary Dashboard is focused on providing you an overview of any detector that has triggered for your application. We have created a detector for this screen shot but your pane will be empty for now, but we will add some detectors to your site and make sure they are triggered in one of the next sections.
In the screen shot you can see we have a critical alert for the RUM Aggregated View Detector, and a Count, how often this alert has triggered in the selected time window. If you happen to have an alert listed, you can click on the name of the Alert (that is shown as a blue link) and you will be taken to the Alert Overview page showing the details of the alert (Note: this will move you away from the current page, Please use the Back option of your browser to return to the overview page).
Please take a few minutes to experiment with the RUM Application Summary Dashboard and the underlying chart and dashboards before going on to the next section.
`,description:"",tags:null,title:"4. Check Browser Applications health at a glance",uri:"/en/other/o11y4rookies/rum/5-browser-app-summary/index.html"},{content:` 10 minutes Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules 1. Introduction Splunk Observability Cloud uses detectors, events, alerts, and notifications to keep you informed when certain criteria are met. For example, you might want a message sent to a Slack channel or to an email address for the Ops team when CPU Utilization has reached 95%, or when the number of concurrent users is approaching a limit that might require you to spin up an additional AWS instance.
These conditions are expressed as one or more rules that trigger an alert when the conditions in the rules are met. Individual rules in a detector are labeled according to criticality: Info, Warning, Minor, Major, and Critical.
2. Creating a Detector In Dashboards click on your Custom Dashboard Group (that you created in the previous module) and then click on the dashboard name.
We are now going to create a new detector from a chart on this dashboard. Click on the bell icon on the Latency vs Load chart, and then click New Detector From Chart.
In the text field next to Detector Name, ADD YOUR INITIALS before the proposed detector name.
Naming the detector It’s important that you add your initials in front of the proposed detector name.
It should be something like this: XYZ’s Latency Chart Detector.
Click on Create Alert Rule In the Detector window, inside Alert signal, the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert.
Click on Proceed to Alert Condition 3. Setting Alert condition In Alert condition, click on Static Threshold and then on Proceed to Alert Settings In Alert Settings, enter the value 290 in the Threshold field. In the same window change Time on top right to past day (-1d).
4. Alert pre-flight check A pre-flight check will take place after 5 seconds. See the Estimated alert count. Based on the current alert settings, the amount of alerts we would have received in 1 day would have been 3.
About pre-flight checks Once you set an alert condition, the UI estimates how many alerts you might get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day.
Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using the Splunk Observability Cloud.
To read more about detector previewing, please visit this link Preview detector alerts.
Click on Proceed to Alert Message 5. Alert message In Alert message, under Severity choose Major.
Click on Proceed to Alert Recipients Click on Add Recipient and then on your email address displayed as the first option.
Notification Services That’s the same as entering that email address OR you can enter another email address by clicking on E-mail….
This is just one example of the many Notification Services the suite has available. You can check this out by going to the Integrations tab of the top menu, and see Notification Services.
6. Alert Activation Click on Proceed to Alert Activation In Activate… click on Activate Alert Rule If you want to get alerts quicker you edit the rule and lower the value from 290 to say 280.
If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metrics from the last 1 hour.
Click on the in the navbar and then click on Detectors. You can optionally filter for your initials. You will see you detector listed here. If you don’t then please refresh your browser.
Congratulations! You have created your first detector and activated it!
`,description:"",tags:null,title:"Working with Detectors",uri:"/en/imt/detectors/index.html"},{content:`1. Kubernetes Resources Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.
You do this by placing a Resource section in the deployment of you application/Pod
Example:
resources: limits: # Maximum amount of CPU \u0026 memory for peek use cpu: "8" # Maximum of 8 cores of CPU allowed at for peek use memory: "9Mi" # Maximum allowed 9Mb of memory requests: # Request are the expected amount of CPU \u0026 memory for normal use cpu: "6" # Requesting 4 cores of a CPU memory: "4Mi" # Requesting 4Mb of memory More information can be found here : Resource Management for Pods and Containers
If your application or Pod will go over the limits set in your deployment, Kubernetes will kill and restart your Pod to protect the other applications on the Cluster.
Another scenario that you will run into is when there is not enough Memory or CPU on a Node. In that case, the Cluster will try to reschedule your Pod(s) on a different Node with more space.
If that fails, or if there is not enough space when you deploy your application, the Cluster will put your workload/deployment in schedule mode until there is enough room on any of the available Nodes to deploy the Pods according their limits.
2. Fix PHP/Apache Deployment Workshop Question Before we start, let’s check the current status of the PHP/Apache deployment. Under Alerts \u0026 Detectors which detector has fired? Where else can you find this information?
To fix the PHP/Apache StatefulSet, edit ~/workshop/k3s/php-apache.yaml using the following commands to reduce the CPU resources:
vim ~/workshop/k3s/php-apache.yaml Find the resources section and reduce the CPU limits to 1 and the CPU requests to 0.5:
resources: limits: cpu: "1" memory: "9Mi" requests: cpu: "0.5" memory: "4Mi" Save the changes youhave made. (Hint: Use Esc followed by :wq! to save your changes).
Now, we must delete the existing StatefulSet and re-create it. StatefulSets are immutable, so we must delete the existing one and re-create it with the new changes.
kubectl delete statefulset php-apache -n apache Now, deploy your changes:
kubectl apply -f ~/workshop/k3s/php-apache.yaml -n apache 3. Validate the changes You can validate the changes have been applied by running the following command:
kubectl describe statefulset php-apache -n apache Validate the Pod is now running in Splunk Observability Cloud.
Workshop Question Is the Apache Web Servers dashboard showing any data now?
Tip: Don’t forget to use filters and time frames to narrow down your data.
Monitor the Apache web servers Navigator dashboard for a few minutes.
Workshop Question What is happening with the # Hosts reporting chart?
4. Fix memory issue If you navigate back to the Apache dashboard, you will notice that metrics are no longer coming in. We have another resource issue and this time we are Out of Memory. Let’s edit the stateful set and increase the memory to what is shown in the image below:
kubectl edit statefulset php-apache -n apache resources: limits: cpu: "1" memory: 16Mi requests: cpu: 500m memory: 12Mi Save the changes you have made.
Hint kubectl edit will open the contents in the vi editor, use Esc followed by :wq! to save your changes.
Because StatefulSets are immutable, we must delete the existing Pod and let the StatefulSet re-create it with the new changes.
kubectl delete pod php-apache-0 -n apache Validate the changes have been applied by running the following command:
kubectl describe statefulset php-apache -n apache `,description:"",tags:null,title:"Fix PHP/Apache Issue",uri:"/en/other/hpa/4-fix-apache/index.html"},{content:`1. Use Data Setup to instrument a Python application Within the O11y Cloud UI:
Data Management -\u003e Add Integration -\u003e Monitor Applications -\u003e Python (traces) -\u003e Add Integration
Provide the following to the Configure Integration Wizard:
Service: review
Django: no
collector endpoint: http://localhost:4317
Environment: rtapp-workshop-[YOURNAME]
Kubernetes: yes
Legacy Agent: no
We are instructed to:
Install the instrumentation packages for your Python environment. pip install splunk-opentelemetry[all] splunk-py-trace-bootstrap Configure the Downward API to expose environment variables to Kubernetes resources.
For example, update a Deployment to inject environment variables by adding .spec.template.spec.containers.env like:
apiVersion: apps/v1 kind: Deployment spec: selector: matchLabels: app: your-application template: spec: containers: - name: myapp env: - name: SPLUNK_OTEL_AGENT valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: "http://$(SPLUNK_OTEL_AGENT):4317" - name: OTEL_SERVICE_NAME value: "review" - name: OTEL_RESOURCE_ATTRIBUTES value: "deployment.environment=rtapp-workshop-stevel" Enable the Splunk OTel Python agent by editing your Python service command.
splunk-py-trace python3 main.py --port=8000 The actions we must perform include:
Update the Dockerfile to install the splunk-opentelemetry packages Update the deployment.yaml for each service to include these environment variables which will be used by the pod and container. Update our Dockerfile for REVIEW so that our program is bootstrapped with splunk-py-trace Note We will accomplish this by:
generating a new requirements.txt file generating a new container image with an updated Dockerfile for REVIEW and then update the review.deployment.yaml to capture all of these changes. 2. Update the REVIEW container Generate a new container image
Update the Dockerfile for REVIEW (/workshop/flask_apps_finish/review)
FROM python:3.10-slim WORKDIR /app COPY requirements.txt /app RUN pip install -r requirements.txt RUN pip install splunk-opentelemetry[all] RUN splk-py-trace-bootstrap COPY ./review.py /app EXPOSE 5000 ENTRYPOINT [ "splunk-py-trace" ] CMD [ "python", "review.py" ] Note Note that the only lines, in bold, added to the Dockerfile
Generate a new container image with docker build in the ‘finished’ directory Notice that I have changed the repository name from localhost:8000/review:0.01 to localhost:8000/review-splkotel:0.01 Ensure you are in the correct directory.
pwd ./workshop/flask_apps_finish/review docker build docker build Output docker build -f Dockerfile.review -t localhost:8000/review-splkotel:0.01 . [+] Building 27.1s (12/12) FINISHED =\u003e [internal] load build definition from Dockerfile 0.0s =\u003e =\u003e transferring dockerfile: 364B 0.0s =\u003e [internal] load .dockerignore 0.0s =\u003e =\u003e transferring context: 2B 0.0s =\u003e [internal] load metadata for docker.io/library/python:3.10-slim 1.6s =\u003e [auth] library/python:pull token for registry-1.docker.io 0.0s =\u003e [1/6] FROM docker.io/library/python:3.10-slim@sha256:54956d6c929405ff651516d5ebbc204203a6415c9d2757aad 0.0s =\u003e [internal] load build context 0.3s =\u003e =\u003e transferring context: 1.91kB 0.3s =\u003e CACHED [2/6] WORKDIR /app 0.0s =\u003e [3/6] COPY requirements.txt /app 0.0s =\u003e [4/6] RUN pip install -r requirements.txt 15.3s =\u003e [5/6] RUN splk-py-trace-bootstrap 9.0s =\u003e [6/6] COPY ./review.py /app 0.0s =\u003e exporting to image 0.6s =\u003e =\u003e exporting layers 0.6s =\u003e =\u003e writing image sha256:164977dd860a17743b8d68bcc50c691082bd3bfb352d1025dc3a54b15d5f4c4d 0.0s =\u003e =\u003e naming to docker.io/localhost:8000/review-splkotel:0.01 0.0s Push the image to Docker Hub with docker push command docker push docker push Output docker push localhost:8000/review-splkotel:0.01 The push refers to repository [docker.io/localhost:8000/review-splkotel] 682f0e550f2c: Pushed dd7dfa312442: Pushed 917fd8334695: Pushed e6782d51030d: Pushed c6b19a64e528: Mounted from localhost:8000/review 8f52e3bfc0ab: Mounted from localhost:8000/review f90b85785215: Mounted from localhost:8000/review d5c0beb90ce6: Mounted from localhost:8000/review 3759be374189: Mounted from localhost:8000/review fd95118eade9: Mounted from localhost:8000/review 0.01: digest: sha256:3b251059724dbb510ea81424fc25ed03554221e09e90ef965438da33af718a45 size: 2412 3. Update the REVIEW deployment in Kubernetes review.deployment.yaml must be updated with the following changes:
Load the new container image on Docker Hub Add environment variables so traces can be emitted to the OTEL collector The deployment must be replaced using the updated review.deployment.yaml
Update review.deployment.yaml (updates highlighted in bold)
apiVersion: apps/v1 kind: Deployment metadata: name: review labels: app: review spec: replicas: 1 selector: matchLabels: app: review template: metadata: labels: app: review spec: imagePullSecrets: - name: regcred containers: - image: localhost:8000/review-splkotel:0.01 name: review volumeMounts: - mountPath: /var/appdata name: appdata env: - name: SPLUNK_OTEL_AGENT valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_SERVICE_NAME value: 'review' - name: SPLUNK_METRICS_ENDPOINT value: "http://$(SPLUNK_OTEL_AGENT):9943" - name: OTEL_EXPORTER_OTLP_ENDPOINT value: "http://$(SPLUNK_OTEL_AGENT):4317" - name: OTEL_RESOURCE_ATTRIBUTES value: 'deployment.environment=rtapp-workshop-stevel' volumes: - name: appdata hostPath: path: /var/appdata Apply review.deployment.yaml. Kubernetes will automatically pick up the changes to the deployment and redeploy new pods with these updates
Notice that the review-* pod has been restarted kubectl apply -f review.deployment.yaml kubectl get pods NAME READY STATUS RESTARTS AGE kafka-client 0/1 Unknown 0 155d curl 0/1 Unknown 0 155d kafka-zookeeper-0 1/1 Running 0 26h kafka-2 2/2 Running 0 26h kafka-exporter-647bddcbfc-h9gp5 1/1 Running 2 26h mongodb-6f6c78c76-kl4vv 2/2 Running 0 26h kafka-1 2/2 Running 1 26h kafka-0 2/2 Running 1 26h splunk-otel-collector-1653114277-agent-n4dfn 2/2 Running 0 26h splunk-otel-collector-1653114277-k8s-cluster-receiver-5f48v296j 1/1 Running 0 26h splunk-otel-collector-1653114277-agent-jqxhh 2/2 Running 0 26h review-6686859bd7-4pf5d 1/1 Running 0 11s review-5dd8cfd77b-52jbd 0/1 Terminating 0 2d10h kubectl get pods NAME READY STATUS RESTARTS AGE kafka-client 0/1 Unknown 0 155d curl 0/1 Unknown 0 155d kafka-zookeeper-0 1/1 Running 0 26h kafka-2 2/2 Running 0 26h kafka-exporter-647bddcbfc-h9gp5 1/1 Running 2 26h mongodb-6f6c78c76-kl4vv 2/2 Running 0 26h kafka-1 2/2 Running 1 26h kafka-0 2/2 Running 1 26h splunk-otel-collector-1653114277-agent-n4dfn 2/2 Running 0 26h splunk-otel-collector-1653114277-k8s-cluster-receiver-5f48v296j 1/1 Running 0 26h splunk-otel-collector-1653114277-agent-jqxhh 2/2 Running 0 26h review-6686859bd7-4pf5d 1/1 Running 0 15s `,description:"",tags:null,title:"Instrument REVIEWS for Tracing",uri:"/en/other/gdi/4-instrument/index.html"},{content:`1. Introduction For the Splunk Log Observer component, we will configure the Spring PetClinic application to write logs to a file in the filesystem and configure the Splunk OpenTelemetry Collect to read (tail) that log file and report the information to the Splunk Observability Platform.
2. FluentD Configuration We need to configure the Splunk OpenTelemetry Collector to tail the Spring PetClinic log file and report the data to the Splunk Observability Cloud endpoint.
The Splunk OpenTelemetry Collector uses FluentD to consume/report logs and to configure the proper setting to report Spring PetClinic logs, we just need to add a FluentD configuration file in the default directory (/etc/otel/collector/fluentd/conf.d/).
So we need to create the a new FluentD configuration file:
sudo vi /etc/otel/collector/fluentd/conf.d/petclinic.conf Copy and paste in the following configuration, this will read the file /tmp/spring-petclinic.log that will be configured in the next section.
\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e We now need to change permission and ownership of the petclinic.conf file so the agent can read it:
sudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf Now that we have created the new configuration and changed the permissions we need to restart the FluentD process:
sudo systemctl restart td-agent 3. Logback Settings The Spring PetClinic application can be configured to use a number of different java logging libraries. In this scenario, we are using logback. We just need to create a file named logback.xml in the configuration folder:
vi src/main/resources/logback.xml Copy and paste the following XML content:
\u003c?xml version="1.0" encoding="UTF-8"?\u003e \u003c!DOCTYPE xml\u003e \u003cconfiguration scan="true" scanPeriod="30 seconds"\u003e \u003ccontextListener class="ch.qos.logback.classic.jul.LevelChangePropagator"\u003e \u003cresetJUL\u003etrue\u003c/resetJUL\u003e \u003c/contextListener\u003e \u003clogger name="org.springframework.samples.petclinic" level="debug"/\u003e \u003cappender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"\u003e \u003cfile\u003e/tmp/spring-petclinic.log\u003c/file\u003e \u003crollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"\u003e \u003cfileNamePattern\u003espringLogFile.%d{yyyy-MM-dd}.log\u003c/fileNamePattern\u003e \u003cmaxHistory\u003e5\u003c/maxHistory\u003e \u003ctotalSizeCap\u003e1GB\u003c/totalSizeCap\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e %d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg trace_id=%X{trace_id} span_id=%X{span_id} trace_flags=%X{trace_flags} %n service.name=%property{otel.resource.service.name}, deployment.environment=%property{otel.resource.deployment.environment}: %m%n \u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level="debug"\u003e \u003cappender-ref ref="file" /\u003e \u003c/root\u003e \u003c/configuration\u003e Now we need to rebuild the application and run it again:
./mvnw package -Dmaven.test.skip=true And then run the application again:
java \\ -Dotel.service.name=$(hostname)-petclinic-service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -Dotel.resource.attributes=deployment.environment=$(hostname)-petclinic,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Then let’s visit the application again to generate more traffic, now we should see log messages being reported http://\u003cVM_IP_ADDRESS\u003e:8080 (feel free to navigate and click around).
Then visit: Hamburger Menu \u003e Log Observer
And you can add a filter to select only log messages from your host and the Spring PetClinic Application:
Add Filter → Fields → host.name → \u003cyour host name\u003e Add Filter → Fields → service.name → \u003cyour host name\u003e-petclinic.service 4. Summary This the end of the exercise and we have certainly covered a lot of ground. At this point you should have metrics, traces (APM \u0026 RUM), logs, database query performance and code profiling being reported into Splunk Observability Cloud. Congratulations!
`,description:"",tags:null,title:"4. Log Observer",uri:"/en/other/pet-clinic/logobserver/index.html"},{content:`Manual Instrumentation Navigate to the manual directory that contains manually instrumentated code.
Command cd ~/o11y-lambda-lab/manual Inspect the contents of the files in this directory. Take a look at the serverless.yml template.
Command cat serverless.yml Workshop Question Do you see any difference from the same file in your auto directory?
You can try to compare them with a diff command:
Diff Command Expected Output diff ~/o11y-lambda-lab/auto/serverless.yml ~/o11y-lambda-lab/manual/serverless.yml 19c19 \u003c #====================================== --- \u003e #====================================== There is no difference! (Well, there shouldn’t be. Ask your lab facilitator to assist you if there is)
Now compare handler.js it with the same file in auto directory using the diff command:
Diff Command diff ~/o11y-lambda-lab/auto/handler.js ~/o11y-lambda-lab/manual/handler.js Look at all these differences!
You may wish to view the entire file with cat handler.js command and examine its content.
Notice how we are now importing some OpenTelemetry libraries directly into our function to handle some of the manual instrumenation tasks we require.
const otelapi = require('@opentelemetry/api'); const otelcore = require('@opentelemetry/core'); We are using https://www.npmjs.com/package/@opentelemetry/api to manipulate the tracing logic in our functions. We are using https://www.npmjs.com/package/@opentelemetry/core to access the Propagator objects that we will use to manually propagate our context with.
Inject Trace Context in Producer Function The below code executes the following steps inside the Producer function:
Get the current Active Span. Create a Propagator. Initialize a context carrier object. Inject the context of the active span into the carrier object. Modify the record we are about to put on our Kinesis stream to include the carrier that will carry the active span’s context to the consumer. const activeSpan = otelapi.trace.getSpan(otelapi.context.active()); const propagator = new otelcore.W3CTraceContextPropagator(); let carrier = {}; propagator.inject(otelapi.trace.setSpanContext(otelapi.ROOT_CONTEXT, activeSpan.spanContext()), carrier, otelapi.defaultTextMapSetter ); const data = "{\\"tracecontext\\": " + JSON.stringify(carrier) + ", \\"record\\":" + event.body + "}"; console.log(\`Record with Trace Context added: \${data}\`); Extract Trace Context in Consumer Function The bellow code executes the following steps inside the Consumer function:
Extract the context that we obtained from the Producer into a carrier object. Create a Propagator. Extract the context from the carrier object in Customer function’s parent span context. Start a new span with the parent span context. Bonus: Add extra attributes to your span, including custom ones with the values from your message! Once completed, end the span. const carrier = JSON.parse( message ).tracecontext; const propagator = new otelcore.W3CTraceContextPropagator(); const parentContext = propagator.extract(otelapi.ROOT_CONTEXT, carrier, otelapi.defaultTextMapGetter); const tracer = otelapi.trace.getTracer(process.env.OTEL_SERVICE_NAME); const span = tracer.startSpan("Kinesis.getRecord", undefined, parentContext); span.setAttribute("span.kind", "server"); const body = JSON.parse( message ).record; if (body.name) { span.setAttribute("custom.tag.name", body.name); } if (body.superpower) { span.setAttribute("custom.tag.superpower", body.superpower); } --- function does some work span.end(); Now let’s see the difference this makes.
`,description:"",tags:null,title:"Manual Instrumentation",uri:"/en/other/lambda-kinesis/4-manual-instrumentation/index.html"},{content:`Processors are run on data between being received and being exported. Processors are optional though some are recommended. There are a large number of processors included in the OpenTelemetry contrib Collector.
Batch Processor By default, only the batch processor is enabled. This processor is used to batch up data before it is exported. This is useful for reducing the number of network calls made to exporters. For this workshop we will accept the defaults (send_batch_size: 8192, timeout: 200ms, send_batch_size_max: 0).
Resource Detection Processor The resource detection processor can be used to detect resource information from the host and append or override the resource value in telemetry data with this information.
By default, the hostname is set to the FQDN if possible, otherwise the hostname provided by the OS is used as a fallback. This logic can be changed from using using the hostname_sources configuration option. To avoid getting the FQDN and use the hostname provided by the OS, we will set the hostname_sources to os.
Resource Detection Processor Configuration Resource Detection Processor Configuration Complete processors: batch: resourcedetection: detectors: [system] system: hostname_sources: [os] extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection: detectors: [system] system: hostname_sources: [os] exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] Robert, thoughts on metrics transform processor example here?
https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor
`,description:"",tags:null,title:"OpenTelemetry Collector Processors",uri:"/en/conf/opentelemetry-collector/4-processors/index.html"},{content:`View Service Map Next step is open your Observability UI, accessing the proper org ( where you sent the traces to ) and click APM and Access the Environemnnt that matches the username you put in .env.
Please note it may take 4-5 minutes or more for traces to show up and you will see full map “form” as traces are coming in, so you may have to refresh the page a few times each time we Build and Deploy.
It is recommended to use a -15m look back during this lab. You may need to change it from time to time (for example to -5m or a custom -10m) to make sure you are only looking at the newer traces after your changes.
NOTE: You may have to refresh the page several times to see your Environment Tag in the UI. The prefix of the Environment tag should match what you entered for SHOP_USER in the .env file.
NOTE: Typically, to identify root cause and route an issue, an SRE or alert responder would check metrics and logs to determine if it is a software or hardware related issue, and thus route to the correct party. In this excercise we are ONLY handling software issues, so we are skipping the metrics and logs parts of normal triage.
If your instrumentation was successful, the service-map will show latency from the shop service to the products service.
Ok let’s triage this SOFTWARE ISSUE and skip directly to the traces.
Click on shop service Click Traces (on the right side) Sort by Duration Select the longest duration trace Or one of the obvious much longer ones Now we can see the long latency occurred in the products service and if we click on products: /products we can see the offending method was products:ProductResource.getAllProducts
Our next step here would be to send that trace to a developer by clicking download trace and they will have to debug the function. Since we will be the developer there is no need to download the trace. Just remember that is normal workflow for alert responders to route an issue to the “Repairers” while providing trace data.
Before we do that please take note of the Tags available for the developer to leverage to find root cause. We see standard out of the box Otel tags on the span, environmental information, but no indications of data specific to something inside custom code (which is where the problem often is).
`,description:"",tags:null,title:"Review APM in the UI",uri:"/en/other/dev-mttr-custom-tags/4-review-apm/index.html"},{content:` Visit the RUM landing page and and check the overview of the performance of all your RUM enabled applications with the Application Summary Dashboard (Both Mobile and Web based) 1. Visit the RUM Landing Page Login into your Splunk IM/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your the RUM Landing Page.
The goal of this page is to give you in a single page, a clear indication of the health, performance and potential errors found in your application(s) and allow you to dive deeper into the information about your User Sessions collected from your web page/App. You will have a pane for each of your active RUM applications. (The view below is the default expanded view)
If you have multiple applications, (which will be the case when every attendee is using their own ec2 instance for the RUM workshop), the pane view may be automatically reduced by collapsing the panes as shown below:
You can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.
First find the right application to use for the workshop:
If you are participating in a stand alone RUM workshop, the workshop leader will tell you the name of the application to use, in the case of a combined workshop, it will follow the naming convention we used for IM and APM and use the ec2 node name as a unique id like jmcj-rum-app as shown as the last app in the screenshot above.
2. Configure the RUM Application Summary Dashboard Header Section RUM Application Summary Dashboard consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:
A drop down for the Time Window you’re reviewing (You are looking at the past 15 minutes by default) A drop down to select the Environment1 you want to look at. This allows you to focus on just the subset of applications belonging to that environment, or Select all to view all available. A drop down list with the various Apps being monitored. You can use the one provided by the workshop host or select your own. This will focus you on just one application. A drop down to select the Source, Browser or Mobile applications to view. For the Workshop leave All selected. A hamburger menu located at the right of the header allowing you to configure some settings of your Splunk RUM application. (We will visit this in a later section). For the workshop lets do a deeper dive into the Application Summary screen in the next section: Check Health Browser Application
A deployment environment is a distinct deployment of your system or application that allows you to set up configurations that don’t overlap with configurations in other deployments of the same application. Separate deployment environments are often used for different stages of the development process, such as development, staging, and production.A common application deployment pattern is to have multiple, distinct application environments that don’t interact directly with each other but that are all being monitored by Splunk APM or RUM: for instance, quality assurance (QA) and production environments, or multiple distinct deployments in different datacenters, regions or cloud providers.  ↩︎
`,description:"",tags:null,title:"4. RUM Landing Page",uri:"/en/rum/4-rum-landing/index.html"},{content:` 10 minutes How to keep track of the usage of Observability Cloud in your organization Learn how to keep track of spend by exploring the Subscription Usage interface Creating Teams Adding notification rules to Teams Controlling usage 1. Understanding engagement To fully understand Observability Cloud engagement inside your organization, click on the » bottom left and select the Settings → Organization Overview, this will provide you with the following dashboards that shows you how your Observability Cloud organization is being used:
You will see various dashboards such as Throttling, System Limits, Entitlements \u0026 Engagement. The workshop organization you’re using now may have less data to work with as this is cleared down after each workshop.
Take a minute to explore the various dashboards and charts in the Organization Overview of this workshop instance.
2. Subscription Usage If you want to see what your usage is against your subscription you can select Subscription Usage.
This screen may take a few seconds to load whilst it calculates and pulls in the usage.
3. Understanding usage You will see a screen similar to the one below that will give you an overview of the current usage, the average usage and your entitlement per category: Hosts, Containers, Custom Metrics and High Resolution Metrics.
For more information about these categories please refer to Monitor Splunk Infrastructure Monitoring subscription usage.
4. Examine usage in detail The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below).
Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart).
In this example you can see that there are 25 Hosts, 0 Containers, 100 Custom Metrics and 0 High Resolution Metrics.
In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart).
The blue line marked Average Usage indicates what Observability Cloud will use to calculate your average usage for the current Subscription Usage Period.
Info As you can see from the screenshot, Observability Cloud does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges.
To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the Subscription Usage Period with the drop down on the right.
Please take a minute to explore the different time periods \u0026 categories and their views.
Finally, the pane on the right shows you information about your Subscription.
`,description:"",tags:null,title:"Service Bureau",uri:"/en/other/o11y4rookies/imt/servicebureau/index.html"},{content:`Splunk Synthetic Monitoring offers the most comprehensive and in-depth capabilities for uptime and web performance optimization as part of the only complete observability suite, Splunk Observability Cloud.
Easily set up monitoring for APIs, service endpoints and end-user-experience. With Splunk Synthetic monitoring, go beyond basic uptime and performance monitoring and focus on proactively finding and fixing issues, optimizing web performance, and ensuring customers get the best user experience.
With Splunk Synthetic Monitoring you can:
Detect and resolve issues fast across critical user flows, business transactions and API endpoints Prevent web performance issues from affecting customers with an intelligence web optimization engine And improve performance of all page resources and third-party dependencies `,description:"Proactively find and fix performance issues across user flows, business transactions and APIs to deliver better digital experiences.",tags:null,title:"Splunk Synthetics",uri:"/en/other/o11y4rookies/synthetics/index.html"},{content:`Splunk Synthetic Monitoring offers the most comprehensive and in-depth capabilities for uptime and web performance optimization as part of the only complete observability suite, Splunk Observability Cloud.
Easily set up monitoring for APIs, service endpoints and end-user-experience. With Splunk Synthetic monitoring, go beyond basic uptime and performance monitoring and focus on proactively finding and fixing issues, optimizing web performance, and ensuring customers get the best user experience.
With Splunk Synthetic Monitoring you can:
Detect and resolve issues fast across critical user flows, business transactions and API endpoints Prevent web performance issues from affecting customers with an intelligence web optimization engine And improve performance of all page resources and third-party dependencies `,description:"Proactively find and fix performance issues across user flows, business transactions and APIs to deliver better digital experiences.",tags:null,title:"Splunk Synthetics",uri:"/en/synthetics/index.html"},{content:`1. Save to existing dashboard Check that you have YOUR_NAME-Dashboard: YOUR_NAME-Dashboard in the top left corner. This means you chart will be saved in this Dashboard.
Name the Chart Latency History and add a Chart Description if you wish.
Click on Save And Close . This returns you to your dashboard that now has two charts!
Now let’s quickly add another Chart based on the previous one.
2. Copy and Paste a chart Click on the three dots ... on the Latency History chart in your dashboard and then on Copy.
You see the chart being copied, and you should now have a red circle with a white 1 next to the + on the top left of the page.
Click on the plus icon the top of the page, and then in the menu on Paste Charts (There should also be a red dot with a 1 visible at the end of the line).
This will place a copy of the previous chart in your dashboard.
3. Edit the pasted chart Click on the three dots ... on one of the Latency History charts in your dashboard and then on Open (or you can click on the name of the chart which here is Latency History).
This will bring you to the editor environment again.
First set the time for the chart to -1 hour in the Time box at the top right of the chart. Then to make this a different chart, click on the eye icon in front of signal “A” to make it visible again, and then hide signal “C” via the eye icon and change the name for Latency history to Latency vs Load.
Click on the Add Metric Or Event button. This will bring up the box for a new signal. Type and select demo.trans.count for Signal D.
This will add a new Signal D to your chart, It shows the number of active requests. Add the filter for the demo_datacenter:Paris, then change the Rollup type by clicking on the Configure Plot button and changing the roll-up from Auto (Delta) to Rate/sec. Change the name from demo.trans.count to Latency vs Load.
Finally press the Save And Close button. This returns you to your dashboard that now has three different charts!
Let’s add an “instruction” note and arrange the charts!
`,description:"",tags:null,title:"Adding charts to dashboards",uri:"/en/other/o11y4rookies/imt/dashboards/adding-charts/index.html"},{content:`1. Save to existing dashboard Check that you have YOUR_NAME-Dashboard: YOUR_NAME-Dashboard in the top left corner. This means you chart will be saved in this Dashboard.
Name the Chart Latency History and add a Chart Description if you wish.
Click on Save And Close . This returns you to your dashboard that now has two charts!
Now let’s quickly add another Chart based on the previous one.
2. Copy and Paste a chart Click on the three dots ... on the Latency History chart in your dashboard and then on Copy.
You see the chart being copied, and you should now have a red circle with a white 1 next to the + on the top left of the page.
Click on the plus icon the top of the page, and then in the menu on Paste Charts (There should also be a red dot with a 1 visible at the end of the line).
This will place a copy of the previous chart in your dashboard.
3. Edit the pasted chart Click on the three dots ... on one of the Latency History charts in your dashboard and then on Open (or you can click on the name of the chart which here is Latency History).
This will bring you to the editor environment again.
First set the time for the chart to -1 hour in the Time box at the top right of the chart. Then to make this a different chart, click on the eye icon in front of signal “A” to make it visible again, and then hide signal “C” via the eye icon and change the name for Latency history to Latency vs Load.
Click on the Add Metric Or Event button. This will bring up the box for a new signal. Type and select demo.trans.count for Signal D.
This will add a new Signal D to your chart, It shows the number of active requests. Add the filter for the demo_datacenter:Paris, then change the Rollup type by clicking on the Configure Plot button and changing the roll-up from Auto (Delta) to Rate/sec. Change the name from demo.trans.count to Latency vs Load.
Finally press the Save And Close button. This returns you to your dashboard that now has three different charts!
Let’s add an “instruction” note and arrange the charts!
`,description:"",tags:null,title:"Adding charts to dashboards",uri:"/en/imt/dashboards/adding-charts/index.html"},{content:` See RUM Metrics and Session information in the RUM UI See correlated APM traces in the RUM \u0026 APM UI 1. RUM Overview Pages From your RUM Application Summary Dashboard you can see detailed information by opening the Application Overview Page via the tripple dot menu on the right by selecting Open Application Overview or by clicking the link with your application name which is jmcj-rum-app in the example below.
This will take you to the RUM Application Overview Page screen as shown below.
2. RUM Browser Overview 2.1. Header The RUM UI consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:
A drop down for the time window you’re reviewing (You are looking at the past hour in this case) A drop down to select the Comparison window (You are comparing current performance on a rolling window - in this case compared to 1 hour ago) A drop down with the available Environments to view: (Choose the one provided by the workshop host or All like in the example) A drop down list with the Various Web apps (You can use the one provided by the workshop host or use All) Optionally a drop down to select Browser or Mobile metrics (Might not be available in your workshop) 2.2. Overview Pane The Overview Panes, down the left hand side of the page, give you a summary of the pages which have increased load times.
In the example here you can see that the checkout and cart pages have errors due to the yellow triangles, and you can see that the load time has increased by 2.38 to 5.50 seconds.
You also see an overview of the number of Front end Error and Backend Errors per minute, and we appear to have three JavaScript errors on our site.
The last two panes show you the Top Page Views and the Top Network Requests.
2.3. Key Metrics Pane The Key Metrics View is the location where you will find the metrics for the number of JavaScript Errors per second, Network Errors per second an the Backend/Resource Request Duration. These Metrics are very useful to guide you to the location of an issue if you are experiencing problems with your site.
2.4. Web Vitals Pane The Web Vitals view is the location where you go if you wish to get insight into the experience you are delivering to your End users based on Web Vitals metrics. Web Vitals is an initiative by Google to provide unified guidance for quality signals that are essential to delivering a great user experience on the web and focuses on three key parameters:
Largest Contentful Paint (LCP), measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID), measures interactivity. To provide a good user experience, pages should have a FID of 100 milliseconds or less. Cumulative Layout Shift (CLS), measures visual stability. To provide a good user experience, pages should maintain a CLS of 0.1. or less. 2.5. Other Metrics Pane The Other Metrics Pane is the location where you find other performance metrics, with a focus on initial load time of your page or tasks that are taking too long to complete.
Time To First Byte (TTFB), measures how long it takes for a client’s browser to receive the first byte of the response from the server. The longer it takes for the server to process the request and send a response, the slower your visitors’ browser is at displaying your page. Long Task Duration, a performance metric that can be used help developers to understand the bad user experience on the website, or can be an indication of a problem. Long Task Count, a metric to indicate how often a long task occurs, again used for exploring user experiences or problem detection. 2.6. Custom Event Pane The Custom Event View is the location where you will find the metrics for any event you may have added yourself to the web pages you are monitoring.
As we have seen in the RUM enabled website, we have added the following two lines:
const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); These lines will automatically create custom Events for every new Page, and you can also add these to pieces of custom code that are not part of a framework or an event you created so you can better understand the flow though your application. We support Custom Event Requests, Custom Event Error Rates and Custom Event Latency metrics.
`,description:"",tags:null,title:"5. Analyzing RUM Metrics",uri:"/en/other/o11y4rookies/rum/6-analyzing-metrics/index.html"},{content:` Get familiar with the UI and options available from this landing page Identify Page Views/Errors and Request/Errors and Java Script Errors in a single view Check the Web Vitals metrics and any Detector that has fired for in relation to your Browser Application 1. Application Summary Dashboard Overview 1.1. Header Bar As seen in the previous section the RUM Application Summary Dashboard consists of 5 major sections. The first section is the selection header, where you can collapse the Pane via the Browser icon or the \u003e in front of the application name, which is jmcj-rum-app in the example below. It also provides access to the Application Overview page if you click the link with your application name which is jmcj-rum-app in the example below.
Further, you can also open the Application Overview or App Health Dashboard via the triple dot menu on the right.
First use the View Dashboard link to open the Browser App Health Dashboard which should open in a new tab. Then switch back to original RUM tab, and then use the Open Application Overview link, or click on the name of the app to launch the Application Overview dashboard.
We will looking at the Application Overview and Browser App Health Dashboards in detail in the following sections.
2. Application Overview The RUM Application Overview Dashboard is focused on providing you with at a glance overview of the status of your application.
2.1. Page Views / Errors \u0026 Network Requests / Errors The first section shows Page Views / Errors, \u0026 Network Requests and Errors charts show the quantity and trend of these issues in your application. This could be Javascript errors, or failed network calls to back end services.
In the example above you can see that there are no failed network calls in the Network chart, but in the Page View chart you can see that a number of pages do experience some errors. These are often not visible for regular users, but can seriously impact the performance of your web site.
You can see the count of the Page Views / Network Requests / Errors by hovering over the charts.
2.2. JavaScript Errors With the second section of the RUM Application Summary Dashboard we are showing you an overview of the JavaScript errors occurring in your application, along with a count of each error.
In the example above you can see there are three JavaScript errors, one that appears 29 times in the selected time slot, and the other two each appear 12 times.
If you click on one of the errors a pop-out opens that will show a summary (below) of the errors over time, along with a Stack Trace of the JavaScript error, giving you an indication of where the problems occurred. (We will see this in more detail in one of the following sections)
2.3. Web Vitals The third section of the RUM Application Summary Dashboard is showing you the crucial (google) Web Vitals, three metrics, that are used by Google in its ranking system, and give a very good indication of the speed of your site for your end users.
As you can see our site is well behaved and scores Good for all three Metrics. These metrics can be used to identify the effect changes to your application have, and help you improve the performance of your site.
If you click on any of the Metrics shown in the Web Vitals pane you will be taken to the corresponding Tag Spotlight Dashboard. e.g. clicking on the Largest Contentful Paint (LCP) chartlet, you will be taken to a dashboard similar to the screen shot below, that gives you timeline and table views for how this metric has performed. This should allow you to spot trends and identify where the problem may be more common, such as an OS or browser version, .
2.4. Most Recent Detectors The fourth and final section of the RUM Application Summary Dashboard is focused on providing you an overview of any detector that has triggered for your application. We have created a detector for this screen shot but your pane will be empty for now, but we will add some detectors to your site and make sure they are triggered in one of the next sections.
In the screen shot you can see we have a critical alert for the RUM Aggregated View Detector, and a Count, how often this alert has triggered in the selected time window. If you happen to have an alert listed, you can click on the name of the Alert (that is shown as a blue link) and you will be taken to the Alert Overview page showing the details of the alert (Note: this will move you away from the current page, Please use the Back option of your browser to return to the overview page).
Please take a few minutes to experiment with the RUM Application Summary Dashboard and the underlying chart and dashboards before going on to the next section.
`,description:"",tags:null,title:"5. Check Browser Applications health at a glance",uri:"/en/rum/5-browser-app-summary/index.html"},{content:`Now let’s play the role of the developer As a developer we must debug the function products:ProductResource.getAllProducts to find the problem.
Debugging 101, the Line by Line method Without anything to go on other than “BAD FUNCTION”, a Developer must then look at code visually line by line to find and fix the problem. To make this worse, functions call other functions, and it can get very messy in bad code scenarios.
We will do the visual inspection mehtod next.
Using Nano: nano products/src/main/java/com/shabushabu/javashop/products/resources/ProductResource.java Search in Nano: [CTRL]-w Enter in: getAllProducts [Enter] You will be taken here: @GET public Response getAllProducts(@DefaultValue("California") @QueryParam("location") String location) { // STEP X: All we know right now is somewhere in this function, latency was introduced. myCoolFunction1(location); myCoolFunction2(location); myCoolFunction10(location); myCoolFunction13(location); myCoolFunction5(location); myCoolFunction6(location); We can see here in getAllProducts, the first call is to myCoolFunction1(), so as may have guessed our next step is to go look at myCoolFunction1().
Search in Nano: [CTRL]-w Enter in: myCoolFunction1 [Enter] Find the next occurrence: [CTRL]-w [Enter] Keep repeating [CTRL]-w [Enter] until you get to the actual function definition It looks like this:
private void myCoolFunction1(String location) { // Generate a FAST sleep of 0 time ! int sleepy = lookupLocation1(location); try{ Thread.sleep(sleepy); } catch (Exception e){ } } Now, myCoolFunction1 calls lookupLocation1(location)
Search in Nano: [CTRL]-w Enter in: lookupLocation1 [Enter] I think you get the picture by now, you have no choice but to inspect every line of code and every function called and visually inspect them for problems. This can be a VERY long process and kills our customers Mean Time to Repair. This happens quite often to our customers with our competition beacsue they can’t provide all the traces 100% of the time and most can’t scale to add more data, via Custom Attributes on top of that!
Remember, without Full Fidelty, you have to either reproduce errors / latency in another environment or inspect code line by line.
So they are stuck where we are, quite often.
OK, enough fun. Let’s make this easier for our developer, and show off some Splunk APM Scale!
Exit your editor: Exit nano: [CTRL]-X Optional: If it asks you to save, hit N `,description:"",tags:null,title:"Debugging 101",uri:"/en/other/dev-mttr-custom-tags/5-debugging101/index.html"},{content:`Now let’s apply some load against the php-apache pod. To do this, you will need start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending HTTP GETs to the php-apache service.
1. Review loadgen YAML Inspect the YAML file ~/workshop/k3s/loadgen.yaml and validate the contents using the following command:
cat ~/workshop/k3s/loadgen.yaml This file contains the configuration for the load generator and will create a new ReplicaSet with a two replicas of the load generator image.
apiVersion: apps/v1 kind: ReplicaSet metadata: name: loadgen labels: app: loadgen spec: replicas: 2 selector: matchLabels: app: loadgen template: metadata: name: loadgen labels: app: loadgen spec: containers: - name: infinite-calls image: busybox command: - /bin/sh - -c - "while true; do wget -q -O- http://php-apache-svc.apache.svc.cluster.local; done" 2. Create a new namespace kubectl create namespace loadgen 3. Deploy the loadgen YAML kubectl apply -f ~/workshop/k3s/loadgen.yaml --namespace loadgen Once you have deployed the load generator, you can see the Pods running in the loadgen namespace. Use previous similar commands to check the status of the Pods from the command line.
Workshop Question Which metrics in the Apache Navigator have now significantly increased?
4. Scale the load generator A ReplicaSet is a process that runs multiple instances of a Pod and keeps the specified number of Pods constant. Its purpose is to maintain the specified number of Pod instances running in a cluster at any given time to prevent users from losing access to their application when a Pod fails or is inaccessible.
ReplicaSet helps bring up a new instance of a Pod when the existing one fails, scale it up when the running instances are not up to the specified number, and scale down or delete Pods if another instance with the same label is created. A ReplicaSet ensures that a specified number of Pod replicas are running continuously and helps with load-balancing in case of an increase in resource usage.
Let’s scale our ReplicaSet to 4 replicas using the following command:
kubectl scale replicaset/loadgen --replicas 4 -n loadgen Validate the replicas are running from both the command line and Splunk Observability Cloud:
kubectl get replicaset loadgen -n loadgen Workshop Question What impact can you see in the Apache Navigator?
Let the load generator run for around 2-3 minutes and keep observing the metrics in the Kubernetes Navigator and the Apache Navigator.
`,description:"",tags:null,title:"Deploy Load Generator",uri:"/en/other/hpa/5-deploy-loadgen/index.html"},{content:`An exporter, which can be push or pull based, is how you send data to one or more backends/destinations. Exporters may support one or more data sources.
exporters: logging: verbosity: detailed otlphttp: metrics_endpoint: https://ingest.eu0.signalfx.com/v2/datapoint/otlp compression: gzip headers: X-SF-TOKEN: \u003credacted\u003e `,description:"",tags:null,title:"OpenTelemetry Collector Exporters",uri:"/en/conf/opentelemetry-collector/5-exporters/index.html"},{content:` 10 minutes Use Terraform1 to manage Observability Cloud Dashboards and Detectors Initialize the Terraform Splunk Provider2. Run Terraform to create detectors and dashboards from code using the Splunk Terraform Provider. See how Terraform can also delete detectors and dashboards. 1. Initial setup Monitoring as code adopts the same approach as infrastructure as code. You can manage monitoring the same way you do applications, servers, or other infrastructure components.
You can use monitoring as code to build out your visualisations, what to monitor, and when to alert, among other things. This means your monitoring setup, processes, and rules can be versioned, shared, and reused.
Full documentation for the Splunk Terraform Provider is available here.
Remaining in your AWS/EC2 instance, change into the o11y-cloud-jumpstart directory
Change directory cd observability-content-contrib/integration-examples/terraform-jumpstart The environment variables needed should already be set from Installation using Helm. If not, create the following environment variables to use in the Terraform steps below
Export ACCESS TOKEN export ACCESS_TOKEN="\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e" Export REALM export REALM="\u003creplace_with_REALM\u003e" Initialize Terraform and upgrade to the latest version of the Splunk Terraform Provider
Note: Upgrading the SignalFx Terraform Provider You will need to run the command below each time a new version of the Splunk Terraform Provider is released. You can track the releases on GitHub.
Initialise Terraform Initialise Output terraform init -upgrade Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kafka in modules/kafka - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - rum_and_synthetics_dashboard in modules/dashboards/rum_and_synthetics - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Finding latest version of splunk-terraform/signalfx... - Installing splunk-terraform/signalfx v6.20.0... - Installed splunk-terraform/signalfx v6.20.0 (self-signed, key ID CE97B6074989F138) Partner and community providers are signed by their developers. If you'd like to know more about provider signing, you can read about it here: https://www.terraform.io/docs/cli/plugins/signing.html Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run "terraform init" in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running "terraform plan" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. 2. Create execution plan The terraform plan command creates an execution plan. By default, creating a plan consists of:
Reading the current state of any already-existing remote objects to make sure that the Terraform state is up-to-date. Comparing the current configuration to the prior state and noting any differences. Proposing a set of change actions that should, if applied, make the remote objects match the configuration. The plan command alone will not actually carry out the proposed changes, and so you can use this command to check whether the proposed changes match what you expected before you apply the changes
Execution Plan Execution Plan Output terraform plan -var="access_token=$ACCESS_TOKEN" -var="realm=$REALM" -var="o11y_prefix=[$(hostname)]" Plan: 146 to add, 0 to change, 0 to destroy. If the plan executes successfully, we can go ahead and apply:
3. Apply execution plan The terraform apply command executes the actions proposed in the Terraform plan above.
The most straightforward way to use terraform apply is to run it without any arguments at all, in which case it will automatically create a new execution plan (as if you had run terraform plan) and then prompt you to provide the Access Token, Realm (the prefix defaults to Splunk) and approve the plan, before taking the indicated actions.
Due to this being a workshop it is required that the prefix is to be unique so you need to run the terraform apply below.
Apply Plan Apply Plan Output terraform apply -var="access_token=$ACCESS_TOKEN" -var="realm=$REALM" -var="o11y_prefix=[$(hostname)]" Apply complete! Resources: 146 added, 0 changed, 0 destroyed. Once the apply has completed, validate that the detectors were created, under the Alerts \u0026 Detectors and click on the Detectors tab. They will be prefixed by the hostname of your instance. To check the prefix value run:
echo $(hostname) You will see a list of the new detectors and you can search for the prefix that was output from above.
3. Destroy all your hard work The terraform destroy command is a convenient way to destroy all remote objects managed by your Terraform configuration.
While you will typically not want to destroy long-lived objects in a production environment, Terraform is sometimes used to manage ephemeral infrastructure for development purposes, in which case you can use terraform destroy to conveniently clean up all of those temporary objects once you are finished with your work.
Now go and destroy all the Detectors and Dashboards that were previously applied!
Destroy Destroy Output terraform destroy -var="access_token=$ACCESS_TOKEN" -var="realm=$REALM" Destroy complete! Resources: 146 destroyed. Validate all the detectors have been removed by navigating to Alerts → Detectors
Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. ↩︎
A provider is responsible for understanding API interactions and exposing resources. Providers generally are an IaaS (e.g. Alibaba Cloud, AWS, GCP, Microsoft Azure, OpenStack), PaaS (e.g. Heroku), or SaaS services (e.g. Splunk, Terraform Cloud, DNSimple, Cloudflare). ↩︎
`,description:"",tags:null,title:"Monitoring as Code",uri:"/en/imt/monitoring-as-code/index.html"},{content:`Re-deploy your Lambdas While remaining in your manual directory, run the following commandd to re-deploy your Lambda Functions:
Deploy Producer Code Expected Output sls deploy -f producer Deploying function producer to stage dev (us-east-1) ✔ Function code deployed (6s) Configuration did not change. Configuration update skipped. (6s) Deploy Consumer Code Expected Output sls deploy -f consumer Deploying function consumer to stage dev (us-east-1) ✔ Function code deployed (6s) Configuration did not change. Configuration update skipped. (6s) Note that this deployment now only updates the code changes within the function. Our configuration remains the same.
Check the details of your serverless functions:
Command sls info You endpoint value should remain the same:
Send some Traffic again Use the curl command to send a payload to your producer function. Note the command option -d is followed by your message payload.
Try changing the value of name to your name and telling the Lambda function about your superpower. Replace YOUR_ENDPOINT with the endpoint from your previous step.
Command curl -d '{ "name": "CHANGE_ME", "superpower": "CHANGE_ME" }' YOUR_ENDPOINT For example:
curl -d '{ "name": "Kate", "superpower": "Distributed Tracing" }' https://xvq043lj45.execute-api.us-east-1.amazonaws.com/dev/producer You should see the following output if your message is successful:
{"message":"Message placed in the Event Stream: hostname-eventSteam"} If unsuccessful, you will see:
{"message": "Internal server error"} If this occurs, ask one of the lab facilitators for assistance.
If you see a success message, generate more load: re-send that messate 5+ times. You should keep seeing a success message after each send.
Check the lambda logs output:
Producer Function Logs sls logs -f producer Consumer Function Logs sls logs -f consumer Examine the logs carefully.
Workshop Question Do you notice the difference?
Note that we are logging our Record together with the Trace context that we have added to it. Copy one of the underlined sub-sections of your trace parent context, and save it for later.
`,description:"",tags:null,title:"Redeploy Lambdas",uri:"/en/other/lambda-kinesis/5-redeploy-lambdas/index.html"},{content:'Objective: Learn how to monitor Linux system logs with the Universal Forwarder sending logs to Splunk Enterprise\nDuration: 10 Minutes\nScenario You’ve been tasked with monitoring the OS logs of the host running your Kubernetes cluster. We are going to utilize a script that will autodeploy the Splunk Universal Forwarder. You will then configure the Universal Forwarder to send logs to the Splunk Enterprise instance assigned to you.\n1. Ensure You’re in the Correct Directory we will need to be in /home/ubuntu/session-2 cd /home/ubuntu/session-2 2. Review the Universal Forwarder Install Script Let’s take a look at the script that will install the Universal Forwarder and Linux TA automatically for you. This script is primarily used for remote instances. Note we are not using a deployment server in this lab, however it is recommended in production we do that. What user are we installing Splunk as? #!/bin/sh # This EXAMPLE script shows how to deploy the Splunk universal forwarder # to many remote hosts via ssh and common Unix commands. # For "real" use, this script needs ERROR DETECTION AND LOGGING!! # --Variables that you must set ----- # Set username using by splunkd to run. SPLUNK_RUN_USER="ubuntu" # Populate this file with a list of hosts that this script should install to, # with one host per line. This must be specified in the form that should # be used for the ssh login, ie. username@host # # Example file contents: # splunkuser@10.20.13.4 # splunkker@10.20.13.5 HOSTS_FILE="myhost.txt" # This should be a WGET command that was *carefully* copied from splunk.com!! # Sign into splunk.com and go to the download page, then look for the wget # link near the top of the page (once you have selected your platform) # copy and paste your wget command between the "" WGET_CMD="wget -O splunkforwarder-9.0.3-dd0128b1f8cd-Linux-x86_64.tgz \'https://download.splunk.com/products/universalforwarder/releases/9.0.3/linux/splunkforwarder-9.0.3-dd0128b1f8cd-Linux-x86_64.tgz\'" # Set the install file name to the name of the file that wget downloads # (the second argument to wget) INSTALL_FILE="splunkforwarder-9.0.3-dd0128b1f8cd-Linux-x86_64.tgz" # After installation, the forwarder will become a deployment client of this # host. Specify the host and management (not web) port of the deployment server # that will be managing these forwarder instances. # Example 1.2.3.4:8089 # DEPLOY_SERVER="x.x.x.x:8089" # After installation, the forwarder can have additional TA\'s added to the # /app directory please provide the local where TA\'s will be. TA_INSTALL_DIRECTORY="/home/ubuntu/session-2" # Set the seed app folder name for deploymentclien.conf # DEPLOY_APP_FOLDER_NAME="seed_all_deploymentclient" # Set the new Splunk admin password PASSWORD="buttercup" REMOTE_SCRIPT_DEPLOY=" cd /opt sudo $WGET_CMD sudo tar xvzf $INSTALL_FILE sudo rm $INSTALL_FILE #sudo useradd $SPLUNK_RUN_USER sudo find $TA_INSTALL_DIRECTORY -name \'*.tgz\' -exec tar xzvf {} --directory /opt/splunkforwarder/etc/apps \\; sudo chown -R $SPLUNK_RUN_USER:$SPLUNK_RUN_USER /opt/splunkforwarder echo \\"[user_info] USERNAME = admin PASSWORD = $PASSWORD\\" \u003e /opt/splunkforwarder/etc/system/local/user-seed.conf #sudo cp $TA_INSTALL_DIRECTORY/*.tgz /opt/splunkforwader/etc/apps/ #sudo find /opt/splunkforwarder/etc/apps/ -name \'*.tgz\' -exec tar xzvf {} \\; #sudo -u splunk /opt/splunkforwarder/bin/splunk start --accept-license --answer-yes --auto-ports --no-prompt /opt/splunkforwarder/bin/splunk start --accept-license --answer-yes --auto-ports --no-prompt #sudo /opt/splunkforwarder/bin/splunk enable boot-start -user $SPLUNK_RUN_USER /opt/splunkforwarder/bin/splunk enable boot-start -user $SPLUNK_RUN_USER #sudo cp $TA_INSTALL_DIRECTORY/*.tgz /opt/splunkforwarder/etc/apps/ exit " DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" \u003e/dev/null \u0026\u0026 pwd )" #=============================================================================================== echo "In 5 seconds, will run the following script on each remote host:" echo echo "====================" echo "$REMOTE_SCRIPT_DEPLOY" echo "====================" echo sleep 5 echo "Reading host logins from $HOSTS_FILE" echo echo "Starting." for DST in `cat "$DIR/$HOSTS_FILE"`; do if [ -z "$DST" ]; then continue; fi echo "---------------------------" echo "Installing to $DST" echo "Initial UF deployment" sudo ssh -t "$DST" "$REMOTE_SCRIPT_DEPLOY" done echo "---------------------------" echo "Done" echo "Please use the following app folder name to override deploymentclient.conf options: $DEPLOY_APP_FOLDER_NAME" 3. Run the install script We will run the install script now. You will see some Warnings at the end. This is totally normal. The script is built for use on remote machines, however for todays lab you will be using localhost.\n./install.sh You will be asked Are you sure you want to continue connecting (yes/no/[fingerprint])? Answer Yes.\nEnter your ssh password when prompted.\n4. Verify installation of the Universal Forwarader We need to verify that the Splunk Universal Forwarder is installed and running. You should see a couple PID’s return and a “Splunk is currently running.” message. /opt/splunkforwarder/bin/splunk status 5. Configure the Universal Forwarder to Send Data to Splunk Enterprise We will be able to send the data to our Splunk Enterprise environment easily by entering one line into the cli. Universal Forwarder Config Guide /opt/splunkforwarder/bin/splunk add forward-server \u003cyour_splunk_enterprise_ip\u003e:9997 6. Verify the Data in Your Splunk Enterprise Environment We are now going to take a look at the Splunk Enterprise environment to verify logs are coming in.\nLogs will be coming into index=main Open your web browser and navigate to: http://\u003cyour_splunk_enterprise_ip:8000\nYou will use the credentials admin:\u003cyour_ssh_password\u003e In the search bar, type in the following:\nindex=main host=\u003cyour_host_name\u003e\nYou should see data from your host. Take note of the interesting fields and the different data sources flowing in.\n',description:"",tags:null,title:"Monitor System Logs with Splunk Universal Forwarder",uri:"/en/other/gdi/5-forwarder/index.html"},{content:`Aim This module is simply to ensure you have access to the Splunk On-Call UI (formerly known as VictorOps), Splunk Infrastructure Monitoring UI (formerly known as SignalFx) and the EC2 Instance which has been allocated to you.
Once you have access to each platform, keep them open for the duration of the workshop as you will be switching between them and the workshop instructions.
1. Activate your Splunk On-Call Login You should have received an invitation to Activate your Splunk On-Call account via e-mail, if you have not already done so, click the Activate Account link and follow the prompts.
If you did not receive an invitation it is probably because you already have a Splunk On-Call login, linked to a different organisation.
If so login to that Org, then use the organisation dropdown next to your username in the top left to switch to the Observability Workshop Org.
Note If you do not see the Organisation dropdown menu item next to your name with Observability Workshop EMEA that is OK, it simply means you only have access to a single Org so that menu is not visible to you.
If you have forgotten your password go to the https://portal.victorops.com/membership/#/ page and use the forgotten password link to reset your password.
2. Activate your Splunk Infrastructure Monitoring Login You should have received an invitation to join the Splunk Infrastructure Monitoring - Observability Workshop. If you have not already done so click the JOIN NOW button and follow the prompts to set a password and activate your login.
3. Access your EC2 Instance Splunk has provided you with a dedicated EC2 Instance which you can use during this workshop for triggering Incidents the same way the instructor did during the introductory demo. This VM has Splunk Infrastructure Monitoring deployed and has an associated Detector configured. The Detector will pass Alerts to Splunk On-Call which will then create Incidents and page the on-call user.
The welcome e-mail you received providing you all the details for this Workshop contain the instructions for accessing your allocated EC2 Instance.
SSH (Mac OS/Linux) Most attendees will be able to connect to the workshop by using SSH from their Mac or Linux device.
To use SSH, open a terminal on your system and type ssh ubuntu@x.x.x.x (replacing x.x.x.x with the IP address found in your welcome e-mail).
When prompted Are you sure you want to continue connecting (yes/no/[fingerprint])? please type yes.
Enter the password provided in the welcome e-mail.
Upon successful login you will be presented with the Splunk logo and the Linux prompt.
At this point you are ready to continue with the workshop when instructed to do so by the instructor
Putty (Windows users only) If you do not have ssh preinstalled or if you are on a Windows system, the best option is to install putty, you can find the downloads here.
!!! important If you cannot install Putty, please go to Web Browser (All).
Open Putty and in the Host Name (or IP address) field enter the IP address provided in the welcome e-mail.
You can optionally save your settings by providing a name and pressing Save.
To then login to your instance click on the Open button as shown above.
If this is the first time connecting to your EC2 instance, you will be presented with a security dialog, please click Yes.
Once connected, login in as ubuntu using the password provided in the welcome e-mail.
Once you are connected successfully you should see a screen similar to the one below:
At this point you are ready to continue with the workshop when instructed to do so by the instructor
Web Browser (All) If you are blocked from using SSH (Port 22) or unable to install Putty you may be able to connect to the workshop instance by using a web browser.
!!! note This assumes that access to port 6501 is not restricted by your company’s firewall.
Open your web browser and type http://x.x.x.x:650 (where x.x.x.x is the IP address from the welcome e-mail).
Once connected, login in as ubuntu and the password is the one provided in the welcome e-mail.
Once you are connected successfully you should see a screen similar to the one below:
Copy \u0026 Paste in browser Unlike when you are using regular SSH, copy and paste does require a few extra steps to complete when using a browser session. This is due to cross browser restrictions.
When the workshop asks you to copy instructions into your terminal, please do the following:
Copy the instruction as normal, but when ready to paste it in the web terminal, choose Paste from browser as show below:
This will open a dialog box asking for the text to be pasted into the web terminal:
Paste the text in the text box as show, then press OK to complete the copy and paste process.
Unlike regular SSH connection, the web browser has a 60 second time out, and you will be disconnected, and a Connect button will be shown in the center of the web terminal.
Simply click the Connect button and you will be reconnected and will be able to continue.
At this point you are ready to continue with the workshop when instructed to do so by the instructor
`,description:"Make expensive service outages a thing of the past. Remediate issues faster, reduce on-call burnout and keep your services up and running.",tags:null,title:"Splunk OnCall",uri:"/en/oncall/index.html"},{content:`1. Adding Notes Often on dashboards it makes sense to place a short “instruction” pane that helps users of a dashboard.
Lets add one now by clicking on the New Text Note Button.
This will open the notes editor.
To allow you to add more then just text to you notes, Splunk is allowing you to use Markdown in these notes/panes. Markdown is a lightweight markup language for creating formatted text using plain-text often used in Webpages.
This includes (but not limited to):
Headers. (in various sizes) Emphasis styles. Lists and Tables. Links. These can be external webpages (for documentation for example) or directly to other Splunk IM Dashboards Below is an example of above Markdown options you can use in your note.
Sample Markdown text # h1 Big headings ###### h6 To small headings ##### Emphasis **This is bold text**, *This is italic text* , ~~Strikethrough~~ ##### Lists Unordered + Create a list by starting a line with \`+\`, \`-\`, or \`*\` - Sub-lists are made by indenting 2 spaces: - Marker character change forces new list start: * Ac tristique libero volutpat at + Facilisis in pretium nisl aliquet * Very easy! Ordered 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa ##### Tables | Option | Description | | ------ | ----------- | | chart | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | #### Links [link to webpage](https://www.splunk.com) [link to dashboard with title](https://app.eu0.signalfx.com/#/dashboard/EaJHrbPAEAA?groupId=EaJHgrsAIAA\u0026configId=EaJHsHzAEAA "Link to the Sample chart Dashboard!") Copy the above by using the copy button and paste it in the Edit box. the preview will show you how it will look.
2. Saving our chart Give the Note chart a name, in our example we used Example text chart, then press the Save And Close Button.
This will bring you back to you Dashboard, that now includes the note.
3. Ordering \u0026 sizing of charts If you do not like the default order and sizes of your charts you can simply use window dragging technique to move and size them to the desired location.
Grab the top border of a chart and you should see the mouse pointer change to a drag icon (see picture below).
Now drag the Latency vs Load chart to sit between the Latency History Chart and the Example text chart.
You can also resize windows by dragging from the left, right and bottom edges.
As a last exercise reduce the width of the note chart to about a third of the other charts. The chart will automatically snap to one of the sizes it supports. Widen the 3 other charts to about a third of the Dashboard. Drag the notes to the right of the others and resize it to match it to the 3 others.
Set the time to -1 h hour and you should have the following dashboard!
On to Detectors!
`,description:"",tags:null,title:"Adding Notes and Dashboard Layout",uri:"/en/other/o11y4rookies/imt/dashboards/notes-and-layout/index.html"},{content:`1. Adding Notes Often on dashboards it makes sense to place a short “instruction” pane that helps users of a dashboard.
Lets add one now by clicking on the New Text Note Button.
This will open the notes editor.
To allow you to add more then just text to you notes, Splunk is allowing you to use Markdown in these notes/panes. Markdown is a lightweight markup language for creating formatted text using plain-text often used in Webpages.
This includes (but not limited to):
Headers. (in various sizes) Emphasis styles. Lists and Tables. Links. These can be external webpages (for documentation for example) or directly to other Splunk IM Dashboards Below is an example of above Markdown options you can use in your note.
Sample Markdown text # h1 Big headings ###### h6 To small headings ##### Emphasis **This is bold text**, *This is italic text* , ~~Strikethrough~~ ##### Lists Unordered + Create a list by starting a line with \`+\`, \`-\`, or \`*\` - Sub-lists are made by indenting 2 spaces: - Marker character change forces new list start: * Ac tristique libero volutpat at + Facilisis in pretium nisl aliquet * Very easy! Ordered 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa ##### Tables | Option | Description | | ------ | ----------- | | chart | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | #### Links [link to webpage](https://www.splunk.com) [link to dashboard with title](https://app.eu0.signalfx.com/#/dashboard/EaJHrbPAEAA?groupId=EaJHgrsAIAA\u0026configId=EaJHsHzAEAA "Link to the Sample chart Dashboard!") Copy the above by using the copy button and paste it in the Edit box. the preview will show you how it will look.
2. Saving our chart Give the Note chart a name, in our example we used Example text chart, then press the Save And Close Button.
This will bring you back to you Dashboard, that now includes the note.
3. Ordering \u0026 sizing of charts If you do not like the default order and sizes of your charts you can simply use window dragging technique to move and size them to the desired location.
Grab the top border of a chart and you should see the mouse pointer change to a drag icon (see picture below).
Now drag the Latency vs Load chart to sit between the Latency History Chart and the Example text chart.
You can also resize windows by dragging from the left, right and bottom edges.
As a last exercise reduce the width of the note chart to about a third of the other charts. The chart will automatically snap to one of the sizes it supports. Widen the 3 other charts to about a third of the Dashboard. Drag the notes to the right of the others and resize it to match it to the 3 others.
Set the time to -1 h hour and you should have the following dashboard!
On to Detectors!
`,description:"",tags:null,title:"Adding Notes and Dashboard Layout",uri:"/en/imt/dashboards/notes-and-layout/index.html"},{content:` See RUM Metrics and Session information in the RUM UI See correlated APM traces in the RUM \u0026 APM UI 1. RUM Overview Pages From your RUM Application Summary Dashboard you can see detailed information by opening the Application Overview Page via the tripple dot menu on the right by selecting Open Application Overview or by clicking the link with your application name which is jmcj-rum-app in the example below.
This will take you to the RUM Application Overview Page screen as shown below.
2. RUM Browser Overview 2.1. Header The RUM UI consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:
A drop down for the time window you’re reviewing (You are looking at the past hour in this case) A drop down to select the Comparison window (You are comparing current performance on a rolling window - in this case compared to 1 hour ago) A drop down with the available Environments to view: (Choose the one provided by the workshop host or All like in the example) A drop down list with the Various Web apps (You can use the one provided by the workshop host or use All) Optionally a drop down to select Browser or Mobile metrics (Might not be available in your workshop) 2.2. Overview Pane The Overview Panes, down the left hand side of the page, give you a summary of the pages which have increased load times.
In the example here you can see that the checkout and cart pages have errors due to the yellow triangles, and you can see that the load time has increased by 2.38 to 5.50 seconds.
You also see an overview of the number of Front end Error and Backend Errors per minute, and we appear to have three JavaScript errors on our site.
The last two panes show you the Top Page Views and the Top Network Requests.
2.3. Key Metrics Pane The Key Metrics View is the location where you will find the metrics for the number of JavaScript Errors per second, Network Errors per second an the Backend/Resource Request Duration. These Metrics are very useful to guide you to the location of an issue if you are experiencing problems with your site.
2.4. Web Vitals Pane The Web Vitals view is the location where you go if you wish to get insight into the experience you are delivering to your End users based on Web Vitals metrics. Web Vitals is an initiative by Google to provide unified guidance for quality signals that are essential to delivering a great user experience on the web and focuses on three key parameters:
Largest Contentful Paint (LCP), measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID), measures interactivity. To provide a good user experience, pages should have a FID of 100 milliseconds or less. Cumulative Layout Shift (CLS), measures visual stability. To provide a good user experience, pages should maintain a CLS of 0.1. or less. 2.5. Other Metrics Pane The Other Metrics Pane is the location where you find other performance metrics, with a focus on initial load time of your page or tasks that are taking too long to complete.
Time To First Byte (TTFB), measures how long it takes for a client’s browser to receive the first byte of the response from the server. The longer it takes for the server to process the request and send a response, the slower your visitors’ browser is at displaying your page. Long Task Duration, a performance metric that can be used help developers to understand the bad user experience on the website, or can be an indication of a problem. Long Task Count, a metric to indicate how often a long task occurs, again used for exploring user experiences or problem detection. 2.6. Custom Event Pane The Custom Event View is the location where you will find the metrics for any event you may have added yourself to the web pages you are monitoring.
As we have seen in the RUM enabled website, we have added the following two lines:
const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); These lines will automatically create custom Events for every new Page, and you can also add these to pieces of custom code that are not part of a framework or an event you created so you can better understand the flow though your application. We support Custom Event Requests, Custom Event Error Rates and Custom Event Latency metrics.
`,description:"",tags:null,title:"6. Analyzing RUM Metrics",uri:"/en/rum/6-analyzing-metrics/index.html"},{content:`Custom Attribution (Custom Tags) To take a deeper look at this issue and make this much easier to debug we will implement Custom Attributes via Opentelemetry Manual Instrumentation.
To speed up manual instrumentation in Java you can leverage OpenTelemetry Annotations, which automatically create a span around a method without modifying the actual code inside the method. This can be very valuable if you are working with an SRE that may have limited access to source code changes.
To add even more information to help our developers find the root cause faster, OpenTelemetry Annotations can be used to generate span tags with parameter values for the method in question. This is incredibly important to mean time to Repair, because as a Developer, if I know the parameter values of a function at the time of latency or error, I can debug this without having to reproduce an issue in another environment if I have Full Fidelity Tracing.
Splunk Full Fidelity APM allows our customers development teams to debug their code as it ran in production, 100% of the time. Add with Custom Attribution, you are providing repeatable Mean Time to Repair reduction… 100% of the time, only with Full Fidelity tracing.
To expedite manual instrumentation implementation for this exercise, we have provided a tool which will annotate the entirety of the “shop” and “products” services with OpenTelemetry standard annotations for every function call without having to write any code. This “annotator” tool will also tag every parameter in every function, which adds a span tag with Parameter=Value.
Run Manual Instrumentation Tool ./AutomateManualInstrumentation.sh Rebuild and Deploy the Application ./BuildAndDeploy.sh Visualize in Splunk APM Now that we have rebuilt and deployed our application, traffic is being sent once again.
Go back to the Splunk Observability UI and let’s see if these annotations help us narrow down the root cause more quickly.
Let’s try to find our latency root cause again, this time with every function and every parameter spanned and tagged respectively…. You will see exactly what this means and how it benefits developers in a moment.
Click on shop service Click Traces ( on the right side ) Sort by Duration Select the longest duration trace ( or one of the obvious much longer ones ) We can see that the actual function call that has the latency was not ProductResource.getAllProducts but the function call ProductResource.myCoolFunction234234234.
Since we now have the parameter tagged as part of our span metadata the actual root cause is seemingly related to the “location” Colorado. And it appears the one custom attribute that was tagged for function ProductResource.myCoolFunction234234234 was myInt with a value of 999. With this information a developer can debug very quickly.
Note We added additional span information, which we call Custom Attributes here at Splunk. In this case our Custom Attributes are Parameter Values at Time of Latency.
In our exmaple the myInt tag was created due our handy Annotator, that did the OpenTelemetry Annotations for us.
Using nano: nano products/src/main/java/com/shabushabu/javashop/products/resources/ProductResource.java Search in Nano: [CTRL]-w Enter in: 999 [Enter] We can see here, someone wrote some very bad code in the form of a long Sleep!
if (999==myInt) Thread.sleep( sleepy.nextInt(5000 - 3000) + 3000); `,description:"",tags:null,title:"Custom Tags",uri:"/en/other/dev-mttr-custom-tags/6-custom-tags/index.html"},{content:`The Service section is used to configure what components are enabled in the Collector based on the configuration found in the receivers, processors, exporters, and extensions sections. If a component is configured, but not defined within the service section then it is not enabled. The service section consists of three sub-sections:
extensions pipelines telemetry In the default configuration the extension section has been configured to enable health_check, pprof and zpages which we configured in the Extensions module earlier.
service: extensions: [health_check, pprof, zpages] Configure Metric Pipeline Hostmetrics Receiver service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [logging] Prometheus Internal Receiver service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging] Resource Detection Processor service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection] exporters: [logging] OTLPHTTP Exporter service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection] exporters: [logging, otlphttp] Final configuration extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection: detectors: [system] system: hostname_sources: [os] exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection] exporters: [logging, otlphttp] extensions: [health_check, pprof, zpages] Now that we have a working configuration, let’s restart the collector and then check to see what zPages is reporting.
`,description:"",tags:null,title:"OpenTelemetry Collector Service",uri:"/en/conf/opentelemetry-collector/6-service/index.html"},{content:` 10 minutes How to keep track of the usage of Observability Cloud in your organization Learn how to keep track of spend by exploring the Subscription Usage interface Creating Teams Adding notification rules to Teams Controlling usage 1. Understanding engagement To fully understand Observability Cloud engagement inside your organization, click on the » bottom left and select the Settings → Organization Overview, this will provide you with the following dashboards that shows you how your Observability Cloud organization is being used:
You will see various dashboards such as Throttling, System Limits, Entitlements \u0026 Engagement. The workshop organization you’re using now may have less data to work with as this is cleared down after each workshop.
Take a minute to explore the various dashboards and charts in the Organization Overview of this workshop instance.
2. Subscription Usage If you want to see what your usage is against your subscription you can select Subscription Usage.
This screen may take a few seconds to load whilst it calculates and pulls in the usage.
3. Understanding usage You will see a screen similar to the one below that will give you an overview of the current usage, the average usage and your entitlement per category: Hosts, Containers, Custom Metrics and High Resolution Metrics.
For more information about these categories please refer to Monitor Splunk Infrastructure Monitoring subscription usage.
4. Examine usage in detail The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below).
Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart).
In this example you can see that there are 25 Hosts, 0 Containers, 100 Custom Metrics and 0 High Resolution Metrics.
In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart).
The blue line marked Average Usage indicates what Observability Cloud will use to calculate your average usage for the current Subscription Usage Period.
Info As you can see from the screenshot, Observability Cloud does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges.
To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the Subscription Usage Period with the drop down on the right.
Please take a minute to explore the different time periods \u0026 categories and their views.
Finally, the pane on the right shows you information about your Subscription.
`,description:"",tags:null,title:"Service Bureau",uri:"/en/imt/servicebureau/index.html"},{content:`In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.
Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.
If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.
1. Setup HPA Inspect the ~/workshop/k3s/hpa.yaml file and validate the contents using the following command:
cat ~/workshop/k3s/hpa.yaml This file contains the configuration for the Horizontal Pod Autoscaler and will create a new HPA for the php-apache deployment.
apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: php-apache namespace: apache spec: maxReplicas: 4 metrics: - type: Resource resource: name: cpu target: averageUtilization: 50 type: Utilization - type: Resource resource: name: memory target: averageUtilization: 75 type: Utilization minReplicas: 1 scaleTargetRef: apiVersion: apps/v1 kind: StatefulSet name: php-apache Once deployed, php-apache will autoscale when either the average CPU usage goes above 50% and average memory usage for the deployment goes above 75%, with a minimum of 1 pod and a maximum of 4 pods.
kubectl apply -f ~/workshop/k3s/hpa.yaml 2. Validate HPA kubectl get hpa -n apache Go to the Workloads or Node Detail tab in Kubernetes and check the HPA deployment.
Workshop Question How many additional php-apache-x pods have been created?
Workshop Question Which metrics in the Apache Navigator have significantly increased again?
3. Increase the HPA replica count Increase the maxReplicas to 8
kubectl edit hpa php-apache -n apache Save the changes you have made. (Hint: Use Esc followed by :wq! to save your changes).
Workshop Questions How many pods are now in a running state?
How many are pending?
Why are they pending?
Congratulations! You have successfully completed the workshop.
`,description:"",tags:null,title:"Setup Horizontal Pod Autoscaling (HPA)",uri:"/en/other/hpa/6-setup-hpa/index.html"},{content:`Navigate back to APM in Splunk Observabilty Cloud
Go back to your Service Dependency map.
Workshop Question Notice the difference?
You should be able to see the consumer-lambda now clearly connected to the producer-lambda.
Remember the value you copied from your producer logs? You can run sls logs -f consumer command again on your EC2 lab host to fetch one.
Take that value, and paste it into trace search:
Click on Go and you should be able to find the logged Trace:
Notice that the Trace ID is something that makes up the trace context that we propagated.
You can read up on the two common propagation standards:
W3C: https://www.w3.org/TR/trace-context/#traceparent-header B3: https://github.com/openzipkin/b3-propagation#overall-process Workshop Question Which one are we using?
It should be self-explanatory from the Propagator we are creating in the Functions
Workshop Question Bonus Question: What happens if we mix and match the W3C and B3 headers?
Expand the consumer-lambda span.
Workshop Question Can you find the attributes from your message?
`,description:"",tags:null,title:"Updated Lambdas in Splunk APM",uri:"/en/other/lambda-kinesis/6-updated-in-splunk/index.html"},{content:` Look into the Metrics views for the various endpoints and use the Tags sent via the Tag spotlight for deeper analysis 1. Find an url for the Cart endpoint From the RUM Overview page, please select the url for the Cart endpoint to dive deeper into the information available for this endpoint.
Once you have selected and clicked on the blue url, you will find yourself in the Tag Spotlight overview
Here you will see all of the tags that have been sent to Splunk RUM as part of the RUM traces. The tags displayed will be relevant to the overview that you have selected. These are generic Tags created automatically when the Trace was sent, and additional Tags you have added to the trace as part of the configuration of your website.
Additional Tags We are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website: app: "[nodename]-rum-app", environment: "[nodename]-rum-env" in the first section of this workshop! You can add additional tags in a similar way.
In our example we have selected the Document Load Latency view as shown here:
You can select any of the following Tag views, each focused on a specific metric.
2. Explore the information in the Tag Spotlight view The Tag spotlight is designed to help you identify problems, either through the chart view,, where you may quickly identify outliers or via the TAGs.
In the Document Load Latency view, if you look at the Browser, Browser Version \u0026 OS Name Tag views,you can see the various browser types and versions, as well as for the underlying OS.
This makes it easy to identify problems related to specific browser or OS versions, as they would be highlighted.
In the above example you can see that Firefox had the slowest response, various Browser versions ( Chrome) that have different response times and the slow response of the Android devices.
A further example are the regional Tags that you can use to identify problems related to ISP or locations etc. Here you should be able to find the location you have been using to access the Online Boutique. Drill down by selecting the town or country you are accessing the Online Boutique from by clicking on the name as shown below (City of Amsterdam):
This will select only the traces relevant to the city selected as shown below:
By selecting the various Tag you build up a filter, you can see the current selection below
To clear the filter and see every trace click on Clear All at the top right of the page.
If the overview page is empty or shows , no traces have been received in the selected timeslot. You need to increase the time window at the top left. You can start with the Last 12 hours for example.
You can then use your mouse to select the time slot you want like show in the view below and activate that time filter by clicking on the little spyglass icon.
`,description:"",tags:null,title:"6. Analyzing RUM Tags in the Tag Spotlight view",uri:"/en/other/o11y4rookies/rum/7-tag-spotlight/index.html"},{content:` Dive into RUM Session information in the RUM UI Identify Javascript errors in the Span of an user interaction 1. Again select the cart URL After you have focussed the time slot with the time selector, you need to reselect the cart url from Url Name view, as shown below:
In the example above we selected http://34.246.124.162:81/cart
2. Drill down in the Sessions After you have analyzed the information and drilled down via the Tag Spotlight to a subset of the traces, you can view the actual session as it was run by the end-user’s browser.
You do this by clicking on the link Example Sessions as shown below:
This will give you a list of sessions that matched both the time filter and the subset selected in the Tag Profile.
Select one by clicking on the session ID, It is a good idea to select one that has the longest duration (preferably over 700 ms).
Once you have selected the session, you will be taken to the session details page. As you are selecting a specific action that is part of the session, you will likely arrive somewhere in the middle of the session, at the moment of the interaction.
You can see the URL http://34.246.124.162:81/cart, the one you selected earlier, is where we are focusing on in the session stream.
Scroll down a little bit on the page, so you see the end of the operation as shown below.
You can see that we have received a few Javascript Console errors that may not have been detected or visible to the end users. To examine these in more detail click on the middle one that says: *Cannot read properties of undefined (reading ‘Prcie’)
This will cause the page to expand and show the Span detail for this interaction, It will contain a detailed error.stack you can pass on the developer to solve the issue. You may have noticed when buying in the Online Boutique that the final total always was $0.00.
`,description:"",tags:null,title:"7. Analyzing RUM Sessions",uri:"/en/other/o11y4rookies/rum/8-rum-sessions/index.html"},{content:`Finding the Problem How did we get here? How did the 999 end up in the trace as a Custom Attribute?
Take a look at the function signature
private void myCoolFunction234234234(@SpanAttribute("myInt") int myInt) @SpanAttribute("myint") is an OpenTelemetry Annotation that was added by our Java Otel Annotator tool.
Fixing the code Change this: private void myCoolFunction234234234(@SpanAttribute("myInt") int myInt) { // Generate a FAST sleep of 0 time ! Random sleepy = new Random(); try{ if (999==myInt) Thread.sleep( sleepy.nextInt(5000 - 3000) + 3000); } catch (Exception e){ to this: private void myCoolFunction234234234(@SpanAttribute("myInt") int myInt) { // Generate a FAST sleep of 0 time ! Random sleepy = new Random(); try{ // if (999==myInt) // Thread.sleep( // sleepy.nextInt(5000 - 3000) // + 3000); } catch (Exception e){ which is basically placing comments (//) before the lines in myCoolFunction234234234 that are causing the slowness:
// if (999==myInt) // Thread.sleep( // sleepy.nextInt(5000 - 3000) // + 3000); Save the changes: [CTRL]-o [Enter] Exit: [CTRL]-x Note Until we rebuild and restart our application this change isn’t implemented.
Find Other Issues Let’s go see if our manual instrumentation uncovered any other issues we did not see before
So you may be asking yourself: “How does manual instrumentation alone show us “more problems” than before? Latency is latency, isn’t it?”
The answer is with auto-instrumentation you are in most situations NOT covering functions our customers’ development teams wrote, which is of course the bulk of what developers do. They write functions…. and of course this is where the bulk of software problems occur.
You may have noticed a new exception in our trace that was not present with Auto-Instrumentation during our latency fix use-case. Since we skipped over this, let’s walk you through it.
Return to the service map Click on shop service Click Traces (on the right side) Click Errors Only Click on a trace with an error present We can see our exception is InvalidLocaleException.
The real problem must be related to the new data associated with Sri Lanka as the Exception says “Non English Characters found in Instrument Data”.
This exception had not surfaced in previous traces based on ONLY Auto-Instrumentation because the method where it was thrown was NOT covered with Auto-Instrumentation.
Once we completed the Manual Instrumentation via the Otel Annotator, this method was instrumented and we can now see we had a buried Exception being thrown.
Fixing more code We already know exactly what file to look in and what method to look at as it is called out in the trace.
Using nano: nano shop/src/main/java/com/shabushabu/javashop/shop/model/Instrument.java Search in Nano: [CTRL]-w Enter in: buildForLocale [Enter] Look just above the buildForLocale function.
Notice the Annotation @WithSpan? @WithSpan is an OpenTelemetry Annotation for Java that automatically generates a span around a the function that follows.
@WithSpan public Instrument buildForLocale( @SpanAttribute("id") long id, ... @SpanAttribute("seller_type") ... this.id= id; Now let’s fix this code. We are going to simply comment this out for now and see if it fixes our latency issue.
Change this: if (!isEnglish(title)) { throw new InvalidLocaleException("Non English Characters found in Instrument Data"); } else { System.out.println("Characters OK "); } to this (comment out if block): // if (!isEnglish(title)) { // throw new InvalidLocaleException("Non English Characters found in Instrument Data"); // } else { // System.out.println("Characters OK "); // } Save the changes: [CTRL]-o [Enter] Exit: [CTRL]-x `,description:"",tags:null,title:"Fixing Code",uri:"/en/other/dev-mttr-custom-tags/7-fixing-code/index.html"},{content:`Before you Go Please kindly clean up your lab using the following command:
Remove Functions sls remove Conclusion Congratuations on finishing the lab. You have seen how we complement auto-instrumentation with manual steps to force Producer function’s context to be sent to Consumer function via a Record put on a Kinesis stream. This allowed us to build the expected Distributed Trace.
You can now build out a Trace manually by linking two different functions together. This is very powerful when your auto-instrumenation, or third-party systems, do not support context propagation out of the box.
`,description:"",tags:null,title:"Summary",uri:"/en/other/lambda-kinesis/7-summary/index.html"},{content:` Look into the Metrics views for the various endpoints and use the Tags sent via the Tag spotlight for deeper analysis 1. Find an url for the Cart endpoint From the RUM Overview page, please select the url for the Cart endpoint to dive deeper into the information available for this endpoint.
Once you have selected and clicked on the blue url, you will find yourself in the Tag Spotlight overview
Here you will see all of the tags that have been sent to Splunk RUM as part of the RUM traces. The tags displayed will be relevant to the overview that you have selected. These are generic Tags created automatically when the Trace was sent, and additional Tags you have added to the trace as part of the configuration of your website.
Additional Tags We are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website: app: "[nodename]-rum-app", environment: "[nodename]-rum-env" in the first section of this workshop! You can add additional tags in a similar way.
In our example we have selected the Document Load Latency view as shown here:
You can select any of the following Tag views, each focused on a specific metric.
2. Explore the information in the Tag Spotlight view The Tag spotlight is designed to help you identify problems, either through the chart view,, where you may quickly identify outliers or via the TAGs.
In the Document Load Latency view, if you look at the Browser, Browser Version \u0026 OS Name Tag views,you can see the various browser types and versions, as well as for the underlying OS.
This makes it easy to identify problems related to specific browser or OS versions, as they would be highlighted.
In the above example you can see that Firefox had the slowest response, various Browser versions ( Chrome) that have different response times and the slow response of the Android devices.
A further example are the regional Tags that you can use to identify problems related to ISP or locations etc. Here you should be able to find the location you have been using to access the Online Boutique. Drill down by selecting the town or country you are accessing the Online Boutique from by clicking on the name as shown below (City of Amsterdam):
This will select only the traces relevant to the city selected as shown below:
By selecting the various Tag you build up a filter, you can see the current selection below
To clear the filter and see every trace click on Clear All at the top right of the page.
If the overview page is empty or shows , no traces have been received in the selected timeslot. You need to increase the time window at the top left. You can start with the Last 12 hours for example.
You can then use your mouse to select the time slot you want like show in the view below and activate that time filter by clicking on the little spyglass icon.
`,description:"",tags:null,title:"7. Analyzing RUM Tags in the Tag Spotlight view",uri:"/en/rum/7-tag-spotlight/index.html"},{content:" Attachments dashboard_OTel-Contrib-Dashboard.json (37 KB) ",description:"",tags:null,title:"Data Visualisations",uri:"/en/conf/opentelemetry-collector/7-visualisation/index.html"},{content:` Continue with the RUM Session information in the RUM UI See correlated APM traces and logs in the APM \u0026 Log Observer UI 1. Finding backend service issues Click on the to close the Span view. Now continue to scroll down and find the POST /cart/checkout line.
Click on the blue link, this should pop up a dialog showing information on the backend services that were part of the checkout action taken by the end user.
In this popup, there are multiple sections available, providing you with a quick insight in the behavior of your backend services. For example the Performance Summary section will tell you where the time was spent during the backend call.
In the above example you can see that more than 77,9% was spent in external services.
If you scroll down to the bottom of the dialog, you can see the complete Trace and Services section like shown below:
in the Services map, you can see two services flagged red, the Checkout Service and the Payment Service in both in dark red. Light red means it received an error and dark red means an error originated from that service.
So already it is obvious there is a problem in the back end services.
Let’s investigate!
2. Follow the Trace to the Backend service You can now click on the Trace Id link:
This will bring you to the Waterfall APM view that will show you what occurred in detail in a call to the backend services. On the right you see the Trace Id: and again the Performance Summary, as we saw before. In the waterfall, you can identify the various backend services that were part of this call from the frontend.
As you can see there are red error indicators before the Checkout Service and the Payment Service.
Click on the after the paymentservice: grpc.hipstershop.PaymentService/Charge line.
This will open the span detail page to show you the detailed information about this service call. You wil see that the call returned a 401 error code or Invalid Request.
3. Use the Related Content - Logs As the Splunk Observability cloud suite correlates trace metrics and logs automatically, the system will show you in the related content bar at the bottom of the page, the corresponding logs for this trace.
Click on the Log link to see the logs.
When the logs are shown, notice that the filter at the top of the page contains the logs for the trace. Next select one of the lines indicating an error for the payment service. This should open the log message on the right.
It clearly shows the reason why the payment service fails: we are using an invalid token towards the service:
*Failed payment processing through ButtercupPayments: Invalid API Token (test-20e26e90-356b-432e-a2c6-956fc03f5609)
4. Conclusion In the workshop, you have seen how to add RUM functionality to you website. We investigate the performance of your Website using RUM Metrics. Using the Tag profile, you have searched for your own session, and with the session waterfall, you identified two problems:
A Java script error that caused your price calculation to be zero. An issue in the payment backend service that caused payments to fail. Using the ability to correlate RUM traces with the Backend APM trace and Logs, you have found the reason for the payment failure.
This concludes the RUM workshop.
`,description:"",tags:null,title:"8. Correlate between Splunk RUM and APM backend services",uri:"/en/other/o11y4rookies/rum/9-apm-correlation/index.html"},{content:` Dive into RUM Session information in the RUM UI Identify Javascript errors in the Span of an user interaction 1. Again select the cart URL After you have focussed the time slot with the time selector, you need to reselect the cart url from Url Name view, as shown below:
In the example above we selected http://34.246.124.162:81/cart
2. Drill down in the Sessions After you have analyzed the information and drilled down via the Tag Spotlight to a subset of the traces, you can view the actual session as it was run by the end-user’s browser.
You do this by clicking on the link Example Sessions as shown below:
This will give you a list of sessions that matched both the time filter and the subset selected in the Tag Profile.
Select one by clicking on the session ID, It is a good idea to select one that has the longest duration (preferably over 700 ms).
Once you have selected the session, you will be taken to the session details page. As you are selecting a specific action that is part of the session, you will likely arrive somewhere in the middle of the session, at the moment of the interaction.
You can see the URL http://34.246.124.162:81/cart, the one you selected earlier, is where we are focusing on in the session stream.
Scroll down a little bit on the page, so you see the end of the operation as shown below.
You can see that we have received a few Javascript Console errors that may not have been detected or visible to the end users. To examine these in more detail click on the middle one that says: *Cannot read properties of undefined (reading ‘Prcie’)
This will cause the page to expand and show the Span detail for this interaction, It will contain a detailed error.stack you can pass on the developer to solve the issue. You may have noticed when buying in the Online Boutique that the final total always was $0.00.
`,description:"",tags:null,title:"8. Analyzing RUM Sessions",uri:"/en/rum/8-rum-sessions/index.html"},{content:`Rebuild and Deploy Run ./BuildAndDeploy.sh Wait a few minutes . . . Return to the service map If you do NOT see RED in your service map, you have completed the Latency Repair for the Colorado Location!
Now let’s check for our exception in the traces.
Click on shop service Click Traces (on the right side) Click Errors Only If you do not have red in your service map and you do not see Errors in traces, you have successfully completed our Inventory application review for Sri Lanka and Colorado locations.
Well done!
`,description:"",tags:null,title:"Rebuild and Deploy",uri:"/en/other/dev-mttr-custom-tags/8-rebuild-and-deploy/index.html"},{content:` Use RUM Metrics to set up Alerts to be warned in case of an issue Create a Custom Chart based on RUM Metrics 1. Overview The fact that Splunk’s RUM is designed as a full fidelity solution, and thus can take 100% of your traces, allows it to detect and alert you to any change to the behavior of your website. It also give you the ability to to give you accurate insight in how your website is behaving by allowing you to creating custom Chart and Dashboards. This allows you to combine data from your Website, Backend service and underlying Infrastructure. Allowing you to observe the complete stack that makes up your application/solution.
Creating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert.
If you previously done the Splunk IM Part of the Workshop, you will find this section very familiar. If you have not done the Splunk IM workshop before, it is recommended that you run though the Dashboards and Detectors modules after completing the RUM workshop to get a better understanding of the capabilities.
2. Create an alert on one of the RUM Metrics From the top left hamburger menu icon click Alerts in the menu and then select Detectors.
3. Create a Chart based on Rum Metrics 3.1 Overview Creating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert If you previously done the Splunk IM Part of the Workshop, you will find this section very familiar.
u have added to the trace as part of the configuration of your website.
Addtional Tags We are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website in the first section of this workshop! You can add additional tag in a similar way.
app: "[nodename]-rum-app", environment: "[nodename]-rum-env" `,description:"",tags:null,title:"9. Custom alerts and charts based on RUM Metrics",uri:"/en/other/o11y4rookies/rum/10-alerting/index.html"},{content:` Continue with the RUM Session information in the RUM UI See correlated APM traces and logs in the APM \u0026 Log Observer UI 1. Finding backend service issues Click on the to close the Span view. Now continue to scroll down and find the POST /cart/checkout line.
Click on the blue link, this should pop up a dialog showing information on the backend services that were part of the checkout action taken by the end user.
In this popup, there are multiple sections available, providing you with a quick insight in the behavior of your backend services. For example the Performance Summary section will tell you where the time was spent during the backend call.
In the above example you can see that more than 77,9% was spent in external services.
If you scroll down to the bottom of the dialog, you can see the complete Trace and Services section like shown below:
in the Services map, you can see two services flagged red, the Checkout Service and the Payment Service in both in dark red. Light red means it received an error and dark red means an error originated from that service.
So already it is obvious there is a problem in the back end services.
Let’s investigate!
2. Follow the Trace to the Backend service You can now click on the Trace Id link:
This will bring you to the Waterfall APM view that will show you what occurred in detail in a call to the backend services. On the right you see the Trace Id: and again the Performance Summary, as we saw before. In the waterfall, you can identify the various backend services that were part of this call from the frontend.
As you can see there are red error indicators before the Checkout Service and the Payment Service.
Click on the after the paymentservice: grpc.hipstershop.PaymentService/Charge line.
This will open the span detail page to show you the detailed information about this service call. You wil see that the call returned a 401 error code or Invalid Request.
3. Use the Related Content - Logs As the Splunk Observability cloud suite correlates trace metrics and logs automatically, the system will show you in the related content bar at the bottom of the page, the corresponding logs for this trace.
Click on the Log link to see the logs.
When the logs are shown, notice that the filter at the top of the page contains the logs for the trace. Next select one of the lines indicating an error for the payment service. This should open the log message on the right.
It clearly shows the reason why the payment service fails: we are using an invalid token towards the service:
*Failed payment processing through ButtercupPayments: Invalid API Token (test-20e26e90-356b-432e-a2c6-956fc03f5609)
4. Conclusion In the workshop, you have seen how to add RUM functionality to you website. We investigate the performance of your Website using RUM Metrics. Using the Tag profile, you have searched for your own session, and with the session waterfall, you identified two problems:
A Java script error that caused your price calculation to be zero. An issue in the payment backend service that caused payments to fail. Using the ability to correlate RUM traces with the Backend APM trace and Logs, you have found the reason for the payment failure.
This concludes the RUM workshop.
`,description:"",tags:null,title:"9. Correlate between Splunk RUM and APM backend services",uri:"/en/rum/9-apm-correlation/index.html"},{content:`Don’t forget Chicago We are nearly done, one more location to go… Chicago.
Since we have been having so many issues related to “location” and we have added that custom attribute via Opentelemetry Manual Instrumentation, lets go to the Splunk Observability UI and look at an APM metric set around that tag that I created for us.
Open a browser and navigate to http://[EC2-Address]:8010 Replace [EC2-Address] with the ip address of your host Select a few locations and hit the Login button. Make sure to also select the Chicago Location and hit the Login button. Uh oh! We received a 500 error, something is wrong there as well.
Return to the Splunk Observability UI and lets look once again at our Service Map Select the Instruments Service Click the Breakdowns dropdown on the right and select location We see there was an un-handled exception thrown in the Instruments service, and some latency from our database that is related to the Chicago location!
Click on Traces on the right Click Errors Only Click one of the traces We can see the exception was thrown by Hibernate, however it was thrown in our method instruments: InstrumentRepository.findInstruments
Let’s play developer again Edit the file instruments: InstrumentRepository.findInstruments using nano: nano instruments/src/main/java/com/shabushabu/javashop/instruments/repositories/FindInstrumentRepositoryImpl.java Find the method: findInstruments You know how to do this now, right? We can see the developer accidently added the Instruments database with the Chicago Instruments database!
Let’s change the query and fix this, remove instruments_for_sale from our query.
Change this: public Object findInstruments() { LOGGER.info("findInstruments Called (All)"); Object obj = entityManager.createNativeQuery( "SELECT * FROM instruments_for_sale, instruments_for_sale_chicago").getResultList(); return obj; } to this: public Object findInstruments() { LOGGER.info("findInstruments Called (All)"); Object obj = entityManager.createNativeQuery( "SELECT * FROM instruments_for_sale_chicago").getResultList(); return obj; } Save the changes: [CTRL]-o [Enter]
Exit: [CTRL]-x
Build and Deploy Application
./BuildAndDeploy.sh Now let’s test the Chicago location once again
Open a browser and navigate to http://[EC2-Address]:8010 Select the Chicago location and Login We now see the 500 error is gone!
Let’s confirm a clean Service Map: If you see a clean service map, free of errors and Latency you have successfully completed the Java Instrumentation Workshop!
Congratulations!!!
`,description:"",tags:null,title:"Don't Forget Chicago",uri:"/en/other/dev-mttr-custom-tags/9-chicago/index.html"},{content:` Use RUM Metrics to set up Alerts to be warned in case of an issue Create a Custom Chart based on RUM Metrics 1. Overview The fact that Splunk’s RUM is designed as a full fidelity solution, and thus can take 100% of your traces, allows it to detect and alert you to any change to the behavior of your website. It also give you the ability to to give you accurate insight in how your website is behaving by allowing you to creating custom Chart and Dashboards. This allows you to combine data from your Website, Backend service and underlying Infrastructure. Allowing you to observe the complete stack that makes up your application/solution.
Creating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert.
If you previously done the Splunk IM Part of the Workshop, you will find this section very familiar. If you have not done the Splunk IM workshop before, it is recommended that you run though the Dashboards and Detectors modules after completing the RUM workshop to get a better understanding of the capabilities.
2. Create an alert on one of the RUM Metrics From the top left hamburger menu icon click Alerts in the menu and then select Detectors.
3. Create a Chart based on Rum Metrics 3.1 Overview Creating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert If you previously done the Splunk IM Part of the Workshop, you will find this section very familiar.
u have added to the trace as part of the configuration of your website.
Addtional Tags We are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website in the first section of this workshop! You can add additional tag in a similar way.
app: "[nodename]-rum-app", environment: "[nodename]-rum-env" `,description:"",tags:null,title:"10. Custom alerts and charts based on RUM Metrics",uri:"/en/rum/10-alerting/index.html"},{content:` Short introduction to Mobile RUM See an overview of the performance of your Mobile Application(s) in the Application Summary Dashboard 1. Visit your RUM Application Summary Dashboard Visit and login into your Splunk IM/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your RUM Application Summary Page.
The goal of this page is to give you in a single pane/dashboard, a clear indication of the health, performance and potential errors found in your application(s) and allow you dive deeper into the information about your User Session ran against your web site.
You will have a pane for each of your active RUM applications. (The view below is the default expanded view)
If you have multiple applications, the pane view may be automatically reduced by collapsing the panes as shown below:
You can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.
2. RUM Mobile Overview Splunk RUM supports Native Mobile RUM, for Apple iPhone and Android Phones. You can use this to see the End-user experience of your native Smartphone app.
The above screen is to show you the various metrics and data Splunk Mobile RUM can track. For example:
Custom events, similar to the Browser version. App Errors , with App Errors \u0026 Crashes per minute. App Lifecycle Performance, with Cold Startup Time, Hot Startup Time per OS. Request/Response, similar to the Browser version. At this point we will not go deeper into Mobile RUM, due to the need to run either a native app on a phone, or run an emulation. We can provide more information in a deep dive demo if needed.
`,description:"",tags:null,title:"10. Introdcution to RUM for Mobile Applications",uri:"/en/other/o11y4rookies/rum/11-mobile-app-summary/index.html"},{content:` Newbie to Ninja - OpenTelemetry CollectorThis workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector
`,description:".conf 2023 - Workshops",tags:null,title:".conf Workshops",uri:"/en/conf/index.html"},{content:` Short introduction to Mobile RUM See an overview of the performance of your Mobile Application(s) in the Application Summary Dashboard 1. Visit your RUM Application Summary Dashboard Visit and login into your Splunk IM/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your RUM Application Summary Page.
The goal of this page is to give you in a single pane/dashboard, a clear indication of the health, performance and potential errors found in your application(s) and allow you dive deeper into the information about your User Session ran against your web site.
You will have a pane for each of your active RUM applications. (The view below is the default expanded view)
If you have multiple applications, the pane view may be automatically reduced by collapsing the panes as shown below:
You can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.
2. RUM Mobile Overview Splunk RUM supports Native Mobile RUM, for Apple iPhone and Android Phones. You can use this to see the End-user experience of your native Smartphone app.
The above screen is to show you the various metrics and data Splunk Mobile RUM can track. For example:
Custom events, similar to the Browser version. App Errors , with App Errors \u0026 Crashes per minute. App Lifecycle Performance, with Cold Startup Time, Hot Startup Time per OS. Request/Response, similar to the Browser version. At this point we will not go deeper into Mobile RUM, due to the need to run either a native app on a phone, or run an emulation. We can provide more information in a deep dive demo if needed.
`,description:"",tags:null,title:"11. Introdcution to RUM for Mobile Applications",uri:"/en/rum/11-mobile-app-summary/index.html"},{content:` Observability 4 RookiesThis workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector
PetClinic Java WorkshopA workshop using Zero Configuration Auto-Instrumentation for Java
Getting Data In (GDI) with OTel and UF45 minutes During this technical workshop you will learn how to: Efficiently deploy complex environments Capture metrics from these environments to Splunk Observability Cloud Auto-instrument a python application Enable OS logging to Splunk Enterprise via Universal Forwarder In order to simplify the workshop modules, a pre-configured AWS EC2 instance is provided. By the end of this technical workshop you will have an approach to demonstrating metrics collection for complex environments and services.
Monitoring Horizontal Pod Autoscaling in KubernetesThis workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector
Build a Distributed Trace in Lambda and KinesisThis workshop will equip you with how a distributed trace is constructed for a small serverless application that runs on AWS Lambda, producing and consuming a message via AWS Kinesis
Improving MTTR with Custom TagsThis workshop will equip you with...
`,description:"",tags:null,title:"Other Workshops",uri:"/en/other/index.html"},{content:`Mac Setup Tested on Macos Ventura 13.2.1 Mac M1/M2 Intel Macs should be work; however if they are slower you may need to run ./BuildAndDeploy multiple times.
IMPORTANT: Docker must have access to 6-GB RAM.
Prerequisites XCode Command line tools Homebrew Install Homebrew full install details mkdir homebrew \u0026\u0026 curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew eval "$(homebrew/bin/brew shellenv)" brew update --force --quiet chmod -R go-w "$(brew --prefix)/share/zsh" Install Colima Colima - Colima is a docker daemon that does not require Docker Desktop. This is used to avoid any docker license issues with Docker Desktop.
Colima full install details brew uninstall docker docker-compose colima brew install docker docker-compose colima colima stop colima start --cpu 4 --memory 6 Java Tools Install brew install git brew install maven `,description:"",tags:null,title:"Appendix - Setting up on Mac",uri:"/en/other/dev-mttr-custom-tags/appendix-a-setup-mac/index.html"},{content:"",description:"",tags:null,title:"Categories",uri:"/en/categories/index.html"},{content:"",description:"",tags:null,title:"Tags",uri:"/en/tags/index.html"}]