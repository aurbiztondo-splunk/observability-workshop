<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.110.0"><meta name=generator content="Relearn 5.12.2+tip"><meta name=description content="Splunk Observability Workshops"><title>Other Workshops :: Splunk Observability Cloud Workshops</title><link href=https://splunk.github.io/observability-workshop/v4.82/en/other/index.html rel=alternate hreflang=x-default><link href=https://splunk.github.io/observability-workshop/v4.82/en/other/index.html rel=alternate hreflang=en><link href=https://splunk.github.io/observability-workshop/v4.82/ja/other/index.html rel=alternate hreflang=ja><link href=https://splunk.github.io/observability-workshop/v4.82/en/other/index.html rel=canonical type=text/html title="Other Workshops :: Splunk Observability Cloud Workshops"><link href=../../en/other/index.xml rel=alternate type=application/rss+xml title="Other Workshops :: Splunk Observability Cloud Workshops"><link href=../../images/favicon.ico?1682626356 rel=icon type=image/x-icon><link href=../../css/fontawesome-all.min.css?1682626357 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/fontawesome-all.min.css?1682626357 rel=stylesheet></noscript><link href=../../css/nucleus.css?1682626357 rel=stylesheet><link href=../../css/auto-complete.css?1682626357 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/auto-complete.css?1682626357 rel=stylesheet></noscript><link href=../../css/perfect-scrollbar.min.css?1682626357 rel=stylesheet><link href=../../css/fonts.css?1682626357 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../css/fonts.css?1682626357 rel=stylesheet></noscript><link href=../../css/theme.css?1682626357 rel=stylesheet><link href=../../css/theme-splunk-light.css?1682626357 rel=stylesheet id=variant-style><link href=../../css/variant.css?1682626357 rel=stylesheet><link href=../../css/print.css?1682626357 rel=stylesheet media=print><link href=../../css/format-print.css?1682626357 rel=stylesheet><link href=../../css/ie.css?1682626357 rel=stylesheet><script src=../../js/url.js?1682626357></script>
<script src=../../js/variant.js?1682626357></script>
<script>window.index_js_url="../../en/index.search.js";var root_url="../../",baseUriFull,baseUri=root_url.replace(/\/$/,"");window.T_Copy_to_clipboard="Copy to clipboard",window.T_Copied_to_clipboard="Copied to clipboard!",window.T_Copy_link_to_clipboard="Copy link to clipboard",window.T_Link_copied_to_clipboard="Copied link to clipboard!",window.T_No_results_found="No results found for \u0022{0}\u0022",window.T_N_results_found="{1} results found for \u0022{0}\u0022",baseUriFull="https://splunk.github.io/observability-workshop/v4.82/",window.variants&&variants.init(["splunk-light","splunk-dark","aws"])</script><style>@media screen and (min-width:1300px){#body .flex-block-wrapper{margin-left:auto;margin-right:auto;max-width:1300px;width:100%}}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=../../en/other/index.html><div id=body class=default-animation><div id=sidebar-overlay></div><div id=toc-overlay></div><nav id=topbar class=highlightable><div><div id=breadcrumbs><span id=sidebar-toggle-span><a href=# id=sidebar-toggle class=topbar-link title='Menu (CTRL+ALT+n)'><i class="fas fa-bars fa-fw"></i></a></span><ol class=links itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Other Workshops</span><meta itemprop=position content="2"></li></ol></div></div></nav><main id=body-inner class="highlightable home" tabindex=-1><div class=flex-block-wrapper><div id=head-tags></div><article class=home><h1 id=other-workshops>Other Workshops</h1><div class="children children-h3 children-sort-"><h3><a href=../../en/other/pet-clinic/index.html>PetClinic Java Workshop</a></h3><p>A workshop using Zero Configuration Auto-Instrumentation for Java</p><h3><a href=../../en/other/hpa/index.html>Monitoring Horizontal Pod Autoscaling in Kubernetes</a></h3><p>This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector</p></div><footer class=footline></footer></article><section><h1 class=a11y-only>Subsections of Other Workshops</h1><article class=default><h1 id=petclinic-java-workshop>PetClinic Java Workshop</h1><p>The goal is to walk through the basic steps to configure the following components of the Splunk Observability platform:</p><ul><li>Splunk Infrastructure Monitoring (IM)</li><li>Splunk Zero Configuration Auto Instrumentation for Java (APM)<ul><li>Database Query Performance</li><li>AlwaysOn Profiling</li></ul></li><li>Splunk Real User Monitoring (RUM)</li><li>RUM spans to APM spans</li><li>Splunk LogsObserver (LO)</li></ul><p>We will also show the steps about how to clone (download) a sample Java application (Spring PetClinic), as well as how to compile, package and run the application.</p><p>Once the application is up and running, we will instantly start seeing metrics and traces via the Zero Configuration Auto Instrumentation for Java that will be used by the Splunk APM product.</p><p>After that, we will instrument the PetClinic&rsquo;s end user interface (HTML pages rendered by the application) with the Splunk OpenTelemetry Javascript Libraries (RUM) that will generate RUM traces around all the individual clicks and page loads executed by an end user.</p><p>Lastly, we will configure the Spring PetClinic application to write application logs to the filesystem and also configure the Splunk OpenTelemetry Collector to read (tail) the logs and report to Splunk Observability Cloud.</p><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> Prerequisites</div><div class=box-content><p>A Splunk run workshop where an host/instance is provided <strong>OR</strong> a self led workshop on own host / <a href=https://github.com/splunk/observability-workshop/tree/main/multipass target=_blank>multipass instance</a></p><p>For your own system you will need the following installed and enabled:</p><ol><li>JDK 17 installed</li><li>Maven</li><li>Port <code>8080</code> open inbound/outbound</li></ol></div></div><p><a href=#image-2a29c6ba607f02e0b6fac82d942d7066 class=lightbox-link><img src=../../en/other/pet-clinic/images/petclinic-exercise.png alt="PetClinic Exercise" style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-2a29c6ba607f02e0b6fac82d942d7066><img src=../../en/other/pet-clinic/images/petclinic-exercise.png alt="PetClinic Exercise" class=lightbox-image loading=lazy></a></p><footer class=footline></footer></article><section><h1 class=a11y-only>Subsections of PetClinic Java Workshop</h1><article class=default><h1 id=installing-the-opentelemetry-collector>Installing the OpenTelemetry Collector</h1><h2 id=1-introduction>1. Introduction</h2><p>The OpenTelemetry Collector is the core component of instrumenting infrastructure and applications. Its role is to collect and send:</p><ul><li>Infrastructure metrics (disk, cpu, memory, etc)</li><li>Application Performance Monitoring (APM) traces</li><li>Profiling data</li><li>Host and application logs</li></ul><p>Splunk Observability Cloud offers wizards to walk you through the setup of the Collector on both your infrastructure and applications. By default, the wizard will only provide the commands to only install the collector.</p><h2 id=2-configure-environment-variables>2. Configure environment variables</h2><p>If you have already completed the <strong>Splunk IM</strong> workshop you can take advantage of the existing environment variables. Otherwise, create the <code>ACCESS_TOKEN</code> and <code>REALM</code> environment variables to use in the proceeding OpenTelemetry Collector install command.</p><p>For instance, if your realm is <code>us1</code>, you would type <code>export REALM=us1</code> and for <code>eu0</code> type <code>export REALM=eu0</code> etc.</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="Export ACCESS TOKEN" class="tab-nav-button active" onclick='switchTab("default","Export ACCESS TOKEN")'>
<span>Export ACCESS TOKEN</span></button></div><div class=tab-content><div data-tab-item="Export ACCESS TOKEN" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>ACCESS_TOKEN</span><span class=o>=</span><span class=s2>&#34;&lt;replace_with_O11y-Workshop-ACCESS_TOKEN&gt;&#34;</span>
</span></span></code></pre></div></div></div></div><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="Export REALM" class="tab-nav-button active" onclick='switchTab("default","Export REALM")'>
<span>Export REALM</span></button></div><div class=tab-content><div data-tab-item="Export REALM" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>REALM</span><span class=o>=</span><span class=s2>&#34;&lt;replace_with_REALM&gt;&#34;</span>
</span></span></code></pre></div></div></div></div><div class="box notices cstyle warning"><div class=box-label><i class="fa-fw fas fa-exclamation-triangle"></i> Delete any existing OpenTelemetry Collectors</div><div class=box-content><p>If you have completed the Splunk IM workshop, please ensure you have deleted the collector running in Kubernetes before continuing. This can be done by running the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm delete splunk-otel-collector
</span></span></code></pre></div></div></div><h2 id=3-install-the-opentelemetry-collector>3. Install the OpenTelemetry Collector</h2><p>We can then go ahead and install the Collector. There are two additional parameters passed to the install script, they are <code>--with-instrumentation</code> and <code>--deployment-environment</code>. The <code>--with-instrumentation</code> option the installer will install the agent from the Splunk distribution of OpenTelemetry Java, which is then loaded automatically when the PetClinic Java application starts up. No configuration required!</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh &gt; /tmp/splunk-otel-collector.sh <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>sudo sh /tmp/splunk-otel-collector.sh --with-instrumentation --deployment-environment <span class=k>$(</span>hostname<span class=k>)</span>-petclinic --realm <span class=nv>$REALM</span> -- <span class=nv>$ACCESS_TOKEN</span>
</span></span></code></pre></div><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> AWS/EC2 instances</div><div class=box-content><p>If you are attempting this workshop on an AWS/EC2 instance you will have to patch the collector to expose the hostname of the instance:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo sed -i <span class=s1>&#39;s/gcp, ecs, ec2, azure, system/system, gcp, ecs, ec2, azure/g&#39;</span> /etc/otel/collector/agent_config.yaml
</span></span></code></pre></div><p>Once the <code>agent_config.yaml</code> has been patched, you will need to restart the collector:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl restart splunk-otel-collector
</span></span></code></pre></div></div></div><p>Once the install is completed, you can navigate to the <strong>Hosts with agent installed</strong> dashboard to see the data from your host, <strong>Dashboards → Hosts with agent installed</strong>.</p><p>Use the dashboard filter and select <code>host.name</code> and type or select the hostname of your virtual machine. Once you see data flowing for your host, we are then ready to get started with the APM component.</p><footer class=footline></footer></article><article class=default><h1 id=zero-configuration-auto-instrumentation-for-java>Zero Configuration Auto Instrumentation for Java</h1><h2 id=1-spring-petclinic-application>1. Spring PetClinic Application</h2><p>First thing we need to setup APM is&mldr; well, an application. For this exercise, we will use the Spring PetClinic application. This is a very popular sample java application built with Spring framework (Springboot).</p><p>Next we will clone the PetClinic repository, then we will compile, build, package and test the application.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/spring-projects/spring-petclinic
</span></span></code></pre></div><p>Change into the <code>spring-petclinic</code> directory:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> spring-petclinic <span class=o>&amp;&amp;</span> git checkout 276880e
</span></span></code></pre></div><p>Start a MySQL database for PetClinic to use:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d -e <span class=nv>MYSQL_USER</span><span class=o>=</span>petclinic -e <span class=nv>MYSQL_PASSWORD</span><span class=o>=</span>petclinic -e <span class=nv>MYSQL_ROOT_PASSWORD</span><span class=o>=</span>root -e <span class=nv>MYSQL_DATABASE</span><span class=o>=</span>petclinic -p 3306:3306 docker.io/mysql:5.7.8
</span></span></code></pre></div><p>Next, run the <code>maven</code> command to compile/build/package PetClinic:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./mvnw package -Dmaven.test.skip<span class=o>=</span><span class=nb>true</span>
</span></span></code></pre></div><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> Note</div><div class=box-content><p>This will take a few minutes the first time you run, <code>maven</code> will download a lot of dependencies before it actually compiles the application. Future executions will be a lot shorter.</p></div></div><p>Once the compilation is complete, you can run the application with the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>java <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.service.name<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic-service <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-jar target/spring-petclinic-*.jar --spring.profiles.active<span class=o>=</span>mysql
</span></span></code></pre></div><p>If you check the logs of the Splunk OpenTelemetry collector you will see that the collector automatically detected the application running and auto-instrumented it. You can view the logs using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo tail -f /var/log/syslog
</span></span></code></pre></div><p>You can validate if the application is running by visiting <code>http://&lt;VM_IP_ADDRESS>:8080</code>.</p><p>Once your validation is complete you can stop the application by pressing <code>Ctrl-c</code>.</p><h2 id=2-generating-traffic>2. Generating Traffic</h2><p>Next we will start a Docker container running Locust that will generate some simple traffic to the PetClinic application. Locust is a simple load testing tool that can be used to generate traffic to a web application.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run --network<span class=o>=</span><span class=s2>&#34;host&#34;</span> -d -p 8089:8089 -v /home/ubuntu/workshop/petclinic:/mnt/locust docker.io/locustio/locust -f /mnt/locust/locustfile.py --headless -u <span class=m>10</span> -r <span class=m>3</span> -H http://127.0.0.1:8080
</span></span></code></pre></div><h2 id=3-enabling-alwayson-profiling-and-metrics>3. Enabling AlwaysOn Profiling and Metrics</h2><p>To enable CPU and Memory Profiling on the application we can start the application by passing <code>splunk.profiler.enabled=true</code> and for metrics pass <code>splunk.metrics.enabled=true</code>. Make sure the application is stopped and run the following command to enable metrics and profiling.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>java <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.service.name<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic-service <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.profiler.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.metrics.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-jar target/spring-petclinic-*.jar --spring.profiles.active<span class=o>=</span>mysql
</span></span></code></pre></div><p>You can now visit the Splunk APM UI and examine the application components, traces, profiling, DB Query performance and metrics <strong>Hamburger Menu → APM → Explore</strong>.</p><p>Once your validation is complete you can stop the application by pressing <code>Ctrl-c</code>.</p><h2 id=4-adding-resource-attributes-to-spans>4. Adding Resource Attributes to Spans</h2><p>Resource attributes can be added to every reported span. For example <code>version=0.314</code>. A comma separated list of resource attributes can also be defined e.g. <code>key1=val1,key2=val2</code>.</p><p>Let&rsquo;s launch the PetClinic again using a new resource attribute. Note, that adding resource attributes to the run command will override what was defined when we installed the collector. So, we also need to specify our <code>deployment.environment</code> resource attribute along with our new resource attribute. Below you will see we are setting <code>deployment.environment=$(hostname)-petclinic</code> and <code>version=0.314</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>java <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.service.name<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic-service <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.profiler.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.metrics.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.resource.attributes<span class=o>=</span>deployment.environment<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic,version<span class=o>=</span>0.314 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-jar target/spring-petclinic-*.jar --spring.profiles.active<span class=o>=</span>mysql
</span></span></code></pre></div><p>Back in the Splunk APM UI we can drill down on a recent trace and see the new <code>version</code> attribute in a span.</p><footer class=footline></footer></article><article class=default><h1 id=3-real-user-monitoring>3. Real User Monitoring</h1><h2 id=1-enable-rum>1. Enable RUM</h2><p>For the Real User Monitoring (RUM) instrumentation, we will add the Open Telemetry Javascript <a href=https://github.com/signalfx/splunk-otel-js-web target=_blank>https://github.com/signalfx/splunk-otel-js-web</a> snippet in the pages, we will use the wizard again <strong>Data Management → Add Integration → RUM Instrumentation → Browser Instrumentation</strong>.</p><p>Select the preconfigured <strong>RUM ACCESS TOKEN</strong> from the dropdown, click <strong>Next</strong>. Enter <strong>App name</strong> and <strong>Environment</strong> using the following syntax:</p><ul><li><code>[hostname]-petclinic-service</code> - replacing <code>[hostname]</code> with your actual hostname.</li><li><code>[hostname]-petclinic-env</code> - replacing <code>[hostname]</code> with your actual hostname.</li></ul><p>Then you&rsquo;ll need to select the workshop RUM token and define the application and environment names. The wizard will then show a snipped of HTML code that needs to be place at the top at the pages in the <code>&lt;head></code> section. In this example we are using:</p><ul><li>Application Name: <code>&lt;hostname>-petclinic-service</code></li><li>Environment: <code>&lt;hostname>-petclinic-env</code></li></ul><p>Copy the generated code snippet in the wizard or copy and edit the snippet below accordingly. You need to replace <code>&lt;REALM></code>, <code>&lt;RUM_ACCESS_TOKEN></code> and <code>&lt;hostname></code> with the actual values.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-html data-lang=html><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>script</span> <span class=na>src</span><span class=o>=</span><span class=s>&#34;https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js&#34;</span> <span class=na>crossorigin</span><span class=o>=</span><span class=s>&#34;anonymous&#34;</span><span class=p>&gt;&lt;/</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nx>SplunkRum</span><span class=p>.</span><span class=nx>init</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=nx>beaconUrl</span><span class=o>:</span> <span class=s2>&#34;https://rum-ingest.&lt;REALM&gt;.signalfx.com/v1/rum&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nx>rumAuth</span><span class=o>:</span> <span class=s2>&#34;&lt;RUM_ACCESS_TOKEN&gt;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nx>app</span><span class=o>:</span> <span class=s2>&#34;&lt;hostname&gt;-petclinic-service&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nx>environment</span><span class=o>:</span> <span class=s2>&#34;&lt;hostname&gt;-petclinic-env&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>});</span>
</span></span><span class=line><span class=cl><span class=p>&lt;/</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>The Spring PetClinic application uses a single HTML page as the &ldquo;layout&rdquo; page, that is reused across all pages of the application. This is the perfect location to insert the Splunk RUM Instrumentation Library as it will be loaded in all pages automatically.</p><p>Let&rsquo;s then edit the layout page:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vi src/main/resources/templates/fragments/layout.html
</span></span></code></pre></div><p>Next, insert the snippet we generated above in the <code>&lt;head></code> section of the page. Now we need to rebuild the application and run it again:</p><h2 id=2-rebuild-petclinic>2. Rebuild PetClinic</h2><p>Run the <code>maven</code> command to compile/build/package PetClinic:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./mvnw package -Dmaven.test.skip<span class=o>=</span><span class=nb>true</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>java <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.service.name<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic-service <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.profiler.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.metrics.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.resource.attributes<span class=o>=</span>deployment.environment<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic,version<span class=o>=</span>0.314 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-jar target/spring-petclinic-*.jar --spring.profiles.active<span class=o>=</span>mysql
</span></span></code></pre></div><p>Then let&rsquo;s visit the application using a browser to generate real-user traffic <code>http://&lt;VM_IP_ADDRESS>:8080</code>, now we should see RUM traces being reported.</p><p>Let&rsquo;s visit RUM and see some of the traces and metrics <strong>Hamburger Menu → RUM</strong> and you will see some of the Spring PetClinic URLs showing up in the UI.</p><p>When you drill down into a RUM trace you will see a link to APM in the spans. Clicking on the trace ID will take you to the corresponding APM trace for the current RUM trace.</p><footer class=footline></footer></article><article class=default><h1 id=4-log-observer>4. Log Observer</h1><h2 id=1-introduction>1. Introduction</h2><p>For the Splunk Log Observer component, we will configure the Spring PetClinic application to write logs to a file in the filesystem and configure the Splunk OpenTelemetry Collect to read (tail) that log file and report the information to the Splunk Observability Platform.</p><h2 id=2-fluentd-configuration>2. FluentD Configuration</h2><p>We need to configure the Splunk OpenTelemetry Collector to tail the Spring PetClinic log file and report the data to the Splunk Observability Cloud endpoint.</p><p>The Splunk OpenTelemetry Collector uses FluentD to consume/report logs and to configure the proper setting to report Spring PetClinic logs, we just need to add a FluentD configuration file in the default directory (<code>/etc/otel/collector/fluentd/conf.d/</code>).</p><p>So we need to create the a new FluentD configuration file:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo vi /etc/otel/collector/fluentd/conf.d/petclinic.conf
</span></span></code></pre></div><p>Copy and paste in the following configuration, this will read the file <code>/tmp/spring-petclinic.log</code> that will be configured in the next section.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=na>&lt;source&gt;</span>
</span></span><span class=line><span class=cl>  <span class=na>@type tail</span>
</span></span><span class=line><span class=cl>  <span class=na>@label @SPLUNK</span>
</span></span><span class=line><span class=cl>  <span class=na>tag petclinic.app</span>
</span></span><span class=line><span class=cl>  <span class=na>path /tmp/spring-petclinic.log</span>
</span></span><span class=line><span class=cl>  <span class=na>pos_file /tmp/spring-petclinic.pos_file</span>
</span></span><span class=line><span class=cl>  <span class=na>read_from_head false</span>
</span></span><span class=line><span class=cl>  <span class=na>&lt;parse&gt;</span>
</span></span><span class=line><span class=cl>    <span class=na>@type none</span>
</span></span><span class=line><span class=cl>  <span class=na>&lt;/parse&gt;</span>
</span></span><span class=line><span class=cl><span class=na>&lt;/source&gt;</span>
</span></span></code></pre></div><p>We now need to change permission and ownership of the petclinic.conf file so the agent can read it:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf
</span></span><span class=line><span class=cl>sudo chmod <span class=m>755</span> /etc/otel/collector/fluentd/conf.d/petclinic.conf
</span></span></code></pre></div><p>Now that we have created the new configuration and changed the permissions we need to restart the FluentD process:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl restart td-agent
</span></span></code></pre></div><h2 id=3-logback-settings>3. Logback Settings</h2><p>The Spring PetClinic application can be configured to use a number of different java logging libraries. In this scenario, we are using logback. We just need to create a file named <code>logback.xml</code> in the configuration folder:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vi src/main/resources/logback.xml
</span></span></code></pre></div><p>Copy and paste the following XML content:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;!DOCTYPE xml&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration</span> <span class=na>scan=</span><span class=s>&#34;true&#34;</span> <span class=na>scanPeriod=</span><span class=s>&#34;30 seconds&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;contextListener</span> <span class=na>class=</span><span class=s>&#34;ch.qos.logback.classic.jul.LevelChangePropagator&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;resetJUL&gt;</span>true<span class=nt>&lt;/resetJUL&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/contextListener&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;logger</span> <span class=na>name=</span><span class=s>&#34;org.springframework.samples.petclinic&#34;</span> <span class=na>level=</span><span class=s>&#34;debug&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;appender</span> <span class=na>name=</span><span class=s>&#34;file&#34;</span> <span class=na>class=</span><span class=s>&#34;ch.qos.logback.core.rolling.RollingFileAppender&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;file&gt;</span>/tmp/spring-petclinic.log<span class=nt>&lt;/file&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;rollingPolicy</span> <span class=na>class=</span><span class=s>&#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;fileNamePattern&gt;</span>springLogFile.%d{yyyy-MM-dd}.log<span class=nt>&lt;/fileNamePattern&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;maxHistory&gt;</span>5<span class=nt>&lt;/maxHistory&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;totalSizeCap&gt;</span>1GB<span class=nt>&lt;/totalSizeCap&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/rollingPolicy&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;encoder&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;pattern&gt;</span>
</span></span><span class=line><span class=cl>        %d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg trace_id=%X{trace_id} span_id=%X{span_id} trace_flags=%X{trace_flags} %n service.name=%property{otel.resource.service.name}, deployment.environment=%property{otel.resource.deployment.environment}: %m%n
</span></span><span class=line><span class=cl>      <span class=nt>&lt;/pattern&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/encoder&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/appender&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;root</span> <span class=na>level=</span><span class=s>&#34;debug&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;appender-ref</span> <span class=na>ref=</span><span class=s>&#34;file&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/root&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>Now we need to rebuild the application and run it again:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./mvnw package -Dmaven.test.skip<span class=o>=</span><span class=nb>true</span>
</span></span></code></pre></div><p>And then run the application again:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>java <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.service.name<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic-service <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.profiler.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dsplunk.metrics.enabled<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-Dotel.resource.attributes<span class=o>=</span>deployment.environment<span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>-petclinic,version<span class=o>=</span>0.314 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-jar target/spring-petclinic-*.jar --spring.profiles.active<span class=o>=</span>mysql
</span></span></code></pre></div><p>Then let&rsquo;s visit the application again to generate more traffic, now we should see log messages being reported <code>http://&lt;VM_IP_ADDRESS>:8080</code> (feel free to navigate and click around).</p><p>Then visit:
Hamburger Menu > Log Observer</p><p>And you can add a filter to select only log messages from your host and the Spring PetClinic Application:</p><ul><li>Add Filter → Fields → <code>host.name</code> → <code>&lt;your host name></code></li><li>Add Filter → Fields → <code>service.name</code> → <code>&lt;your host name>-petclinic.service</code></li></ul><h2 id=4-summary>4. Summary</h2><p>This the end of the exercise and we have certainly covered a lot of ground. At this point you should have metrics, traces (APM & RUM), logs, database query performance and code profiling being reported into Splunk Observability Cloud. <strong>Congratulations</strong>!</p><footer class=footline></footer></article></section><article class=default><h1 id=monitoring-horizontal-pod-autoscaling-in-kubernetes>Monitoring Horizontal Pod Autoscaling in Kubernetes</h1><span class="btn cstyle transparent"><button type=button>
<i class="fa-fw fas fa-clock"></i>
45 minutes</button></span><p>This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector. During the workshop you will deploy PHP/Apache and a load generator.</p><p>You will learn about OpenTelemetry Receivers, Kubernetes Namespaces, ReplicaSets, Kubernetes Horizontal Pod AutoScaling and how to monitor all this using the Splunk Observability Cloud. The main learnings from the workshop will be a better understanding of the Kubernetes Navigator (and Dashboards) in Splunk Observability Cloud as well as seeing Kubernetes metrics, events and Detectors.</p><p>For this workshop Splunk has prepared an Ubuntu Linux instance in AWS/EC2 all pre-configured for you.</p><p>To get access to the instance that you will be using in the workshop, please visit the URL provided by the workshop leader.</p><footer class=footline></footer></article><section><h1 class=a11y-only>Subsections of Monitoring Horizontal Pod Autoscaling in Kubernetes</h1><article class=default><h1 id=deploying-the-opentelemetry-collector-in-kubernetes-using-a-namespace>Deploying the OpenTelemetry Collector in Kubernetes using a NameSpace</h1><h2 id=1-kubernetes-navigator-20-ui>1. Kubernetes Navigator 2.0 UI</h2><p>We will be starting this workshop using the new Kubernetes Navigator so please check that you are already using the new Navigator.</p><p>When you select <strong>Infrastructure</strong> from the main menu on the left, followed by selecting <strong>Kubernetes</strong>, you should see two services panes (<strong>K8s nodes</strong> and <strong>K8s workloads</strong>) for Kubernetes, similar like the ones below:</p><p><a href=#image-d84b3210f09f0e534d407d7b754ca2dd class=lightbox-link><img src=../../en/other/hpa/1-deploy-otel/../images/k8s-nav2-two.png alt=k8s-navi-v-2 style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-d84b3210f09f0e534d407d7b754ca2dd><img src=../../en/other/hpa/1-deploy-otel/../images/k8s-nav2-two.png alt=k8s-navi-v-2 class=lightbox-image loading=lazy></a></p><h2 id=2-connect-to-ec2-instance>2. Connect to EC2 instance</h2><p>You will be able to connect to the workshop instance by using SSH from your Mac, Linux or Windows device. Open the link to the sheet provided by your instructor. This sheet contains the IP addresses and the password for the workshop instances.</p><p>To use SSH, open a terminal on your system and type <code>ssh ubuntu@x.x.x.x</code> (replacing x.x.x.x with the IP address assigned to you). The password for this workshop is also provided in the sheet.</p><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> Note</div><div class=box-content><p>Your workshop instance has been pre-configured with the correct <strong>Access Token</strong> and <strong>Realm</strong> for this workshop. There is no need for you to configure these.</p></div></div><h2 id=3-namespaces-in-kubernetes>3. Namespaces in Kubernetes</h2><p>Most of our customers will make use of some kind of private or public cloud service to run Kubernetes. They often choose to have only a few large Kubernetes clusters as it is easier to manage centrally.</p><p>Namespaces are a way to organize these large Kubernetes clusters into virtual sub-clusters. This can be helpful when different teams or projects share a Kubernetes cluster as this will give them the easy ability to just see and work with their own resources.</p><p>Any number of namespaces are supported within a cluster, each logically separated from others but with the ability to communicate with each other. Components are only <strong>visible</strong> when selecting a namespace or when adding the <code>--all-namespaces</code> flag to <code>kubectl</code> instead of allowing you to view just the components relevant to your project by selecting your namespace.</p><p>Most customers will want to install the Splunk OpenTelemetry Collector into a separate namespace. This workshop will follow that best practice.</p><h2 id=4-install-splunk-otel-using-helm>4. Install Splunk OTel using Helm</h2><p>Install the OpenTelemetry Collector using the Splunk Helm chart. First, add the Splunk Helm chart repository and update.</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="helm repo add" class="tab-nav-button active" onclick='switchTab("default","helm repo add")'>
<span>helm repo add</span></button>
<button data-tab-item="helm repo add output" class=tab-nav-button onclick='switchTab("default","helm repo add output")'>
<span>helm repo add output</span></button></div><div class=tab-content><div data-tab-item="helm repo add" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart <span class=o>&amp;&amp;</span> helm repo update
</span></span></code></pre></div></div><div data-tab-item="helm repo add output" class=tab-content-text><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Using ACCESS_TOKEN={REDACTED}
</span></span><span class=line><span class=cl>Using REALM=eu0
</span></span><span class=line><span class=cl>&#34;splunk-otel-collector-chart&#34; has been added to your repositories
</span></span><span class=line><span class=cl>Using ACCESS_TOKEN={REDACTED}
</span></span><span class=line><span class=cl>Using REALM=eu0
</span></span><span class=line><span class=cl>Hang tight while we grab the latest from your chart repositories...
</span></span><span class=line><span class=cl>...Successfully got an update from the &#34;splunk-otel-collector-chart&#34; chart repository
</span></span><span class=line><span class=cl>Update Complete. ⎈Happy Helming!⎈
</span></span></code></pre></div></div></div></div><p>Install the OpenTelemetry Collector Helm chart into a new <strong>splunk</strong> namespace with the following commands, do <strong>NOT</strong> edit this:</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="helm install" class="tab-nav-button active" onclick='switchTab("default","helm install")'>
<span>helm install</span></button></div><div class=tab-content><div data-tab-item="helm install" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm install splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.realm=</span><span class=nv>$REALM</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.accessToken=</span><span class=nv>$ACCESS_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;clusterName=</span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>-k3s-cluster&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.logsEnabled=true&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.infrastructureMonitoringEventsEnabled=true&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>splunk-otel-collector-chart/splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--namespace splunk <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--create-namespace <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-f ~/workshop/k3s/splunk-defaults.yaml
</span></span></code></pre></div></div></div></div><h2 id=5-verify-deployment>5. Verify Deployment</h2><p>You can monitor the progress of the deployment by running <code>kubectl get pods</code> and adding <code>-n splunk</code> to the command to see the pods in the <code>splunk</code> namespace which should typically report that the new pods are up and running after about 30 seconds.</p><p>Ensure the status is reported as <strong>Running</strong> before continuing.</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="kubectl get pods" class="tab-nav-button active" onclick='switchTab("default","kubectl get pods")'>
<span>kubectl get pods</span></button>
<button data-tab-item="kubectl get pods Output" class=tab-nav-button onclick='switchTab("default","kubectl get pods Output")'>
<span>kubectl get pods Output</span></button></div><div class=tab-content><div data-tab-item="kubectl get pods" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get pods -n splunk
</span></span></code></pre></div></div><div data-tab-item="kubectl get pods Output" class=tab-content-text><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>NAME                                                          READY   STATUS    RESTARTS   AGE
</span></span><span class=line><span class=cl>splunk-otel-collector-agent-pvstb                             2/2     Running   0          19s
</span></span><span class=line><span class=cl>splunk-otel-collector-k8s-cluster-receiver-6c454894f8-mqs8n   1/1     Running   0          19s
</span></span></code></pre></div></div></div></div><p>Use the label set by the <code>helm</code> install to tail logs (You will need to press <code>ctrl + c</code> to exit).</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="kubectl logs" class="tab-nav-button active" onclick='switchTab("default","kubectl logs")'>
<span>kubectl logs</span></button></div><div class=tab-content><div data-tab-item="kubectl logs" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl logs -l <span class=nv>app</span><span class=o>=</span>splunk-otel-collector -f --container otel-collector -n splunk
</span></span></code></pre></div></div></div></div><p>Or use the installed <code>k9s</code> terminal UI.</p><p><a href=#image-ea45001c27b71a859e0b482b5b3d395c class=lightbox-link><img src=../../en/other/hpa/1-deploy-otel/../images/k9s.png alt=k9s style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-ea45001c27b71a859e0b482b5b3d395c><img src=../../en/other/hpa/1-deploy-otel/../images/k9s.png alt=k9s class=lightbox-image loading=lazy></a></p><div class="box notices cstyle warning"><div class=box-label><i class="fa-fw fas fa-exclamation-triangle"></i> Deleting a failed installation</div><div class=box-content><p>If you make an error installing the Splunk OpenTelemetry Collector you can start over by deleting the installation using:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>helm delete splunk-otel-collector -n splunk
</span></span></code></pre></div></div></div><footer class=footline></footer></article><article class=default><h1 id=tour-of-the-kubernetes-navigator-v2>Tour of the Kubernetes Navigator v2</h1><h2 id=1-cluster-vs-workload-view>1. Cluster vs Workload View</h2><p>The Kubernetes Navigator offers you two separate use cases to view your Kubernetes data.</p><ul><li>The <strong>K8s workloads</strong> is focusing on providing information in regards to workloads a.k.a. <em>your deployments</em>.</li><li>The <strong>K8s nodes</strong> is focusing on providing insight into the performance of clusters, nodes, pods and containers.</li></ul><p>You will initially select either view depending on your need (you can switch between the view on the fly if required). The most common one we will use in this workshop is the workload view and we will focus on that specifically.</p><h3 id=11-finding-your-k8s-cluster-name>1.1 Finding your K8s Cluster name</h3><p>Your first task is to identify and find your own cluster. The cluster will be named after your EC2 instance name.</p><p>To confirm your EC2 instance name, look at the prompt of your EC2 instance. For example, if you are assigned the 7th EC2 instance, the prompt will show:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ubuntu@emea-ws-7 ~ $
</span></span></code></pre></div><p>This means your cluster will be named: <code>emea-ws-7-k3s-cluster</code>. Please make a note of your cluster name as you will need this later in the workshop for filtering.</p><h2 id=2-workloads--workload-details-pane>2. Workloads & Workload Details Pane</h2><p>Go to the <strong>Infrastructure</strong> page in the Observability UI and select <strong>Kubernetes</strong>, this will offer you a set of Kubernetes services, one of them being the <strong>K8s workloads</strong> pane.</p><p>The pane will show a tiny graph giving you a bird&rsquo;s eye view of the load being handled across those Workloads. Also, if there are any alerts for one of the workloads, you will see a small alert indicator as shown in the image below.</p><p><a href=#image-9a1173b29c7fd91060f9cd10c003d604 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/K8s-Workloads.png alt=k8sWorkloads style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-9a1173b29c7fd91060f9cd10c003d604><img src=../../en/other/hpa/2-check-new-navigator-short/../images/K8s-Workloads.png alt=k8sWorkloads class=lightbox-image loading=lazy></a></p><p>Click on the <strong>K8s workloads</strong> pane and you will be taken to the workload view.</p><p>Initially, you will see all the workloads for all clusters that are reported into your Observability Cloud Org. If an alert has fired for any of the workloads, it will be highlighted on the top right (as marked with a red stripe) in the image below. You can go directly to the alert by clicking it to expand it.</p><p><a href=#image-747fbeecd20c8826b96b60151b4801ad class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-screen.png alt=Workloads style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-747fbeecd20c8826b96b60151b4801ad><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-screen.png alt=Workloads class=lightbox-image loading=lazy></a></p><p>Now, let&rsquo;s find your own cluster by filtering on the field <code>k8s.cluster.name</code> in the filter toolbar (as marked with a blue stripe).</p><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> Note</div><div class=box-content><p>You can enter a partial name into the search box, such as &rsquo;emea-ws-7*&rsquo;, to quickly find your Cluster.</p><p>Also, it&rsquo;s a very good idea to switch the default time from the default <strong>-3h</strong> back to last 15 minutes (<strong>-15m</strong>).</p></div></div><p><a href=#image-6e3d8d0698b53de03076749f53b285a6 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-filter.png alt=Workloads style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-6e3d8d0698b53de03076749f53b285a6><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-filter.png alt=Workloads class=lightbox-image loading=lazy></a></p><p>You should now just see information for your own cluster.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>How many workloads are running & how many namespaces are in your Cluster?</p></div></div><h3 id=21-using-the-navigator-selection-chart>2.1 Using the Navigator Selection chart</h3><p>The <strong>K8s workloads</strong> table is a common feature used across most of the Navigator&rsquo;s and will offer you a list view of the data you are viewing. In our case, it shows a list of <code>Pods Failed</code> grouped by <code>k8s.namespace.name</code>.</p><p><a href=#image-b6ed1711b27f5beba35db2c490e7e907 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/workload-selection.png alt=k8s-workload-list style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-b6ed1711b27f5beba35db2c490e7e907><img src=../../en/other/hpa/2-check-new-navigator-short/../images/workload-selection.png alt=k8s-workload-list class=lightbox-image loading=lazy></a></p><p>Now let&rsquo;s change the list view to a heat map view by selecting either the Heat map icon or List icon in the upper-right corner of the screen (as marked with the purple line).</p><p>Changing this option will result in the following visualisation:</p><p><a href=#image-bbe2d92abe5f31de70eb00616ee69ed9 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/heatmap.png alt=k8s-Heat-map style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-bbe2d92abe5f31de70eb00616ee69ed9><img src=../../en/other/hpa/2-check-new-navigator-short/../images/heatmap.png alt=k8s-Heat-map class=lightbox-image loading=lazy></a></p><p>In this view, you will note that each workload is now a colored square. These squares will change color according to the <strong>Color by</strong> option you selected, <em>as marked by the first green line</em> in the image above. The colors give a visual indication of health and/or usage. You can check the meaning by hovering over the <strong>legend</strong> exclamation icon
<i class="fa-fw fas fa-exclamation-circle"></i>
bottom right of the heatmaps.</p><p>Another valuable option in this screen is <strong>Find Outliers</strong> which provides historical analytics of your clusters based on what is selected in the <strong>Color by</strong> dropdown.</p><p>Now, let&rsquo;s select the <strong>File system usage (bytes)</strong> from the <strong>Color by</strong> drop down box, then click on the <strong>Find outliers</strong> drop down <em>as marked by a yellow line</em> in the above image and make sure you change the <strong>Scope</strong> in the dialog to <strong>Per k8s.namespace.name</strong> and <strong>Deviation from Median</strong> as below:</p><p><a href=#image-dd4d11204be2979d0b77c289a25cd4c3 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/set-find-outliers.png alt=k8s-Heat-map style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-dd4d11204be2979d0b77c289a25cd4c3><img src=../../en/other/hpa/2-check-new-navigator-short/../images/set-find-outliers.png alt=k8s-Heat-map class=lightbox-image loading=lazy></a></p><p>The <strong>Find outliers</strong> view is very useful when you need to view a selection of your workloads (or any service depending on the Navigator used) and quickly need to figure out if something has changed.</p><p>It will give you fast insight into items (workloads in our case) that are performing differently (both increased or decreased) which helps to make it easier to spot problems.</p><h3 id=22-the-deployment-overview-pane>2.2 The Deployment overview pane</h3><p>The Deployment overview pane gives you a quick insight of the status of your deployments. You can see at once if the pods of your deployments are Pending, Running, Succeeded, Failed or in an Unknown state.</p><p><a href=#image-f4e8c8a2295259ee02d1b451343636d2 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-deployment-overview.png alt=k8s-workload-overview style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-f4e8c8a2295259ee02d1b451343636d2><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-deployment-overview.png alt=k8s-workload-overview class=lightbox-image loading=lazy></a></p><ul><li><em>Running:</em> Pod is deployed and in a running state</li><li><em>Pending:</em> Waiting to be deployed</li><li><em>Succeeded:</em> Pod has been deployed and completed its job and is finished</li><li><em>Failed:</em> Containers in the pod have run and returned some kind of error</li><li><em>Unknown:</em> Kubernetes isn&rsquo;t reporting any of the known states. (This may be during the starting or stopping of pods, for example).</li></ul><p>You can expand the Workload name by hovering your mouse on it, in case the name is longer than the chart allows.</p><p><a href=#image-2f3db9fccf22c1eb0082c3de061a8a52 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-hover.png alt=k8s-workload-hoover style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-2f3db9fccf22c1eb0082c3de061a8a52><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-hover.png alt=k8s-workload-hoover class=lightbox-image loading=lazy></a></p><p>To filter to a specific workload, you can click on three dots <strong>&mldr;</strong> next to the workload name in the <strong>k8s.workload.name</strong> column and choose <strong>Filter</strong> from the dropdown box.</p><p><a href=#image-564fd9da4dffc263fd6173d330f87e41 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/workload-add-filter.png alt=workload-add-filter style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-564fd9da4dffc263fd6173d330f87e41><img src=../../en/other/hpa/2-check-new-navigator-short/../images/workload-add-filter.png alt=workload-add-filter class=lightbox-image loading=lazy></a></p><p>This will add the selected workload to your filters. Try this for the <strong>splunk-otel-collector-k8s-cluster-receiver</strong> workload. It will then list a single workload in the <strong>splunk</strong> namespace.</p><p>The Heat map above will also filter down to a single coloured square. Click on the square to see more information about the workload.</p><p><a href=#image-6fee1849044c05e33e77b1685ba06df3 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-detail.png alt=workload-add-filter style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-6fee1849044c05e33e77b1685ba06df3><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-detail.png alt=workload-add-filter class=lightbox-image loading=lazy></a></p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What are the CPU request & CPU limit units for the otel-collector?</p></div></div><p>At this point you can drill into the information of the pods, but that is outside the scope of this workshop, for now reset your view by removing the filter for the <strong>splunk-otel-collector-k8s-cluster-receiver</strong> workload and setting the <strong>Color by</strong> option to <strong>Pods Running</strong>.</p><p><a href=#image-7fc911486077c7f7d1efa9d481460353 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-remove-filter.png alt=workload-add-filter style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-7fc911486077c7f7d1efa9d481460353><img src=../../en/other/hpa/2-check-new-navigator-short/../images/k8s-workload-remove-filter.png alt=workload-add-filter class=lightbox-image loading=lazy></a></p><h2 id=3-navigator-sidebar>3. Navigator Sidebar</h2><p>Later in the workshop, you will deploy an Apache server into your cluster which will display an icon in the <strong>Navigator Sidebar</strong>.</p><p>In navigators for Kubernetes, you can track dependent services and containers in the navigator sidebar. To get the most out of the navigator sidebar you configure the services you want to track by configuring an extra dimension called <code>service.name</code>. For this workshop, we have already configured the <code>extraDimensions</code> in the collector configuration for monitoring Apache e.g.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>extraDimensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>service.name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span></code></pre></div><p>The Navigator Sidebar will expand and a link to the discovered service will be added as seen in the image below:</p><p><a href=#image-94a08f53ee8134000987d9d47c8ca863 class=lightbox-link><img src=../../en/other/hpa/2-check-new-navigator-short/../images/pivotbar.png alt=pivotbar style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-94a08f53ee8134000987d9d47c8ca863><img src=../../en/other/hpa/2-check-new-navigator-short/../images/pivotbar.png alt=pivotbar class=lightbox-image loading=lazy></a></p><p>This will allow for easy switching between Navigators. The same applies for your Apache server instance, it will have a Navigator Sidebar allowing you to quickly jump back to the Kubernetes Navigator.</p><footer class=footline></footer></article><article class=default><h1 id=deploying-phpapache>Deploying PHP/Apache</h1><h2 id=1--dns-and-services-in-kubernetes>1. DNS and Services in Kubernetes</h2><p>The Domain Name System (DNS) is a mechanism for linking various sorts of information with easy-to-remember names, such as IP addresses. Using a DNS system to translate request names into IP addresses makes it easy for end-users to reach their target domain name effortlessly.</p><p>Most Kubernetes clusters include an internal DNS service configured by default to offer a lightweight approach for service discovery. Even when Pods and Services are created, deleted, or shifted between nodes, built-in service discovery simplifies applications to identify and communicate with services on the Kubernetes clusters.</p><p>In short, the DNS system for Kubernetes will create a DNS entry for each Pod and Service. In general, a Pod has the following DNS resolution:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>pod-name.my-namespace.pod.cluster-domain.example
</span></span></code></pre></div><p>For example, if a Pod in the <code>default</code> namespace has the Pod name <code>my_pod</code>, and the domain name for your cluster is <code>cluster.local</code>, then the Pod has a DNS name:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>my_pod.default.pod.cluster.local
</span></span></code></pre></div><p>Any Pods exposed by a Service have the following DNS resolution available:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>my_pod.service-name.my-namespace.svc.cluster-domain.example
</span></span></code></pre></div><p>More information can be found here : <a href=https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/ target=_blank>DNS for Service and Pods</a></p><h2 id=2-review-otel-receiver-for-phpapache>2. Review OTel receiver for PHP/Apache</h2><p>Inspect the YAML file <code>~/workshop/k3s/otel-apache.yaml</code> and validate the contents using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/workshop/k3s/otel-apache.yaml
</span></span></code></pre></div><p>This file contains the configuration for the OpenTelemetry agent to monitor the PHP/Apache deployment.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>agent</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>receiver_creator</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>smartagent/apache</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>rule</span><span class=p>:</span><span class=w> </span><span class=l>type == &#34;port&#34; &amp;&amp; pod.name matches &#34;apache&#34; &amp;&amp; port == 80</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>collectd/apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>http://php-apache-svc.apache.svc.cluster.local/server-status?auto</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>extraDimensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>service.name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span></code></pre></div><h2 id=3--observation-rules-in-the-opentelemetry-config>3. Observation Rules in the OpenTelemetry config</h2><p>The above file contains an observation rule for Apache using the OTel <code>receiver_creator</code>. This receiver can instantiate other receivers at runtime based on whether observed endpoints match a configured rule.</p><p>The configured rules will be evaluated for each endpoint discovered. If the rule evaluates to true, then the receiver for that rule will be started as configured against the matched endpoint.</p><p>In the file above we tell the OpenTelemetry agent to look for Pods that match the name <code>apache</code> and have port <code>80</code> open. Once found, the agent will configure an Apache receiver to read Apache metrics from the configured URL. Note, the K8s DNS based URL in the above YAML for the service.</p><p>To use the Apache configuration, you can upgrade the existing Splunk OpenTelemetry Collector Helm chart to use the <code>otel-apache.yaml</code> file with the following command:</p><div class=tab-panel data-tab-group=default><div class=tab-nav><button data-tab-item="Helm Upgrade" class="tab-nav-button active" onclick='switchTab("default","Helm Upgrade")'>
<span>Helm Upgrade</span></button></div><div class=tab-content><div data-tab-item="Helm Upgrade" class="tab-content-text active"><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm upgrade splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.realm=</span><span class=nv>$REALM</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.accessToken=</span><span class=nv>$ACCESS_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;clusterName=</span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>-k3s-cluster&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.logsEnabled=true&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--set<span class=o>=</span><span class=s2>&#34;splunkObservability.infrastructureMonitoringEventsEnabled=true&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>splunk-otel-collector-chart/splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--namespace splunk <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-f ~/workshop/k3s/splunk-defaults.yaml <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>-f ~/workshop/k3s/otel-apache.yaml
</span></span></code></pre></div></div></div></div><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> NOTE</div><div class=box-content><p>The <strong>REVISION</strong> number of the deployment has changed, which is a helpful way to keep track of your changes.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Release &#34;splunk-otel-collector&#34; has been upgraded. Happy Helming!
</span></span><span class=line><span class=cl>NAME: splunk-otel-collector
</span></span><span class=line><span class=cl>LAST DEPLOYED: Tue Jan 31 16:57:22 2023
</span></span><span class=line><span class=cl>NAMESPACE: splunk
</span></span><span class=line><span class=cl>STATUS: deployed
</span></span><span class=line><span class=cl>REVISION: 2
</span></span><span class=line><span class=cl>TEST SUITE: None
</span></span></code></pre></div></div></div><h2 id=4-kubernetes-configmaps>4. Kubernetes ConfigMaps</h2><p>A ConfigMap is an object in Kubernetes consisting of key-value pairs which can be injected into your application. With a ConfigMap, you can separate configuration from your Pods.</p><p>Using ConfigMap, you can prevent hardcoding configuration data. ConfigMaps are useful for storing and sharing non-sensitive, unencrypted configuration information.</p><p>The OpenTelemetry collector/agent uses ConfigMaps to store the configuration of the agent and the K8s Cluster receiver. You can/will always verify the current configuration of an agent after a change by running the following commands:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get cm -n splunk
</span></span></code></pre></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>How many ConfigMaps are used by the collector?</p></div></div><p>When you have list of ConfigMaps from the namespace, select the one for the <code>otel-agent</code> and view it with the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get cm splunk-otel-collector-otel-agent -n splunk -o yaml
</span></span></code></pre></div><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-info-circle"></i> NOTE</div><div class=box-content><p>The option <code>-o yaml</code> will output the content of the ConfigMap in a readable YAML format.</p></div></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Is the configuration from <code>otel-apache.yaml</code> visible in the ConfigMap for the collector agent?</p></div></div><h2 id=5-review-phpapache-deployment-yaml>5. Review PHP/Apache deployment YAML</h2><p>Inspect the YAML file <code>~/workshop/k3s/php-apache.yaml</code> and validate the contents using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/workshop/k3s/php-apache.yaml
</span></span></code></pre></div><p>This file contains the configuration for the PHP/Apache deployment and will create a new StatefulSet with a single replica of the PHP/Apache image.</p><p>A stateless application is one that does not care which network it is using, and it does not need permanent storage. Examples of stateless apps may include web servers such as Apache, Nginx, or Tomcat.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>StatefulSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>updateStrategy</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>RollingUpdate</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>serviceName</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;php-apache-svc&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/splunk/php-apache:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;8&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9Mi&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;6&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;4Mi&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache-svc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span></code></pre></div><h2 id=6-deploy-phpapache>6. Deploy PHP/Apache</h2><p>Create an apache namespace then deploy the PHP/Apache application to the cluster.</p><p>Create the <code>apache</code> namespace:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl create namespace apache
</span></span></code></pre></div><p>Deploy the PHP/Apache application:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f ~/workshop/k3s/php-apache.yaml -n apache
</span></span></code></pre></div><p>Ensure the deployment has been created:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get statefulset -n apache
</span></span></code></pre></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What metrics for your Apache instance are being reported in the Apache Navigator?</p><p><strong>Tip:</strong> Use the Navigator Sidebar and click on the service name.</p></div></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Using Log Observer what is the issue with the PHP/Apache deployment?</p><p><strong>Tip:</strong> Adjust your <strong>Table settings</strong> by clicking on the cog to use only <code>object.involvedObject.name</code>, <code>object.message</code> and <code>k8s.cluster.name</code>. Make sure you unselect <code>_raw</code>!</p></div></div><footer class=footline></footer></article><article class=default><h1 id=fix-phpapache-issue>Fix PHP/Apache Issue</h1><h2 id=1-kubernetes-resources>1. Kubernetes Resources</h2><p>Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.</p><p>You do this by placing a Resource section in the deployment of you application/Pod</p><p><strong>Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>         </span><span class=c># Maximum amount of CPU &amp; memory for peek use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;8&#34;</span><span class=w>      </span><span class=c># Maximum of 8 cores of CPU allowed at for peek use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9Mi&#34;</span><span class=w> </span><span class=c># Maximum allowed 9Mb of memory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>       </span><span class=c># Request are the expected amount of CPU &amp; memory for normal use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;6&#34;</span><span class=w>      </span><span class=c># Requesting 4 cores of a CPU</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;4Mi&#34;</span><span class=w> </span><span class=c># Requesting 4Mb of memory</span><span class=w>
</span></span></span></code></pre></div><p>More information can be found here : <a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ target=_blank>Resource Management for Pods and Containers</a></p><p>If your application or Pod will go over the limits set in your deployment, Kubernetes will kill and restart your Pod to protect the other applications on the Cluster.</p><p>Another scenario that you will run into is when there is not enough Memory or CPU on a Node. In that case, the Cluster will try to reschedule your Pod(s) on a different Node with more space.</p><p>If that fails, or if there is not enough space when you deploy your application, the Cluster will put your workload/deployment in schedule mode until there is enough room on any of the available Nodes to deploy the Pods according their limits.</p><h2 id=2-fix-phpapache-deployment>2. Fix PHP/Apache Deployment</h2><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Before we start, let&rsquo;s check the current status of the PHP/Apache deployment. Under <strong>Alerts & Detectors</strong> which detector has fired? Where else can you find this information?</p></div></div><p>To fix the PHP/Apache StatefulSet, edit <code>~/workshop/k3s/php-apache.yaml</code> using the following commands to reduce the CPU resources:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/workshop/k3s/php-apache.yaml
</span></span></code></pre></div><p>Find the resources section and reduce the CPU limits to <strong>1</strong> and the CPU requests to <strong>0.5</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9Mi&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;4Mi&#34;</span><span class=w>
</span></span></span></code></pre></div><p>Save the changes youhave made. (Hint: Use <code>Esc</code> followed by <code>:wq!</code> to save your changes).</p><p>Now, we must delete the existing StatefulSet and re-create it. StatefulSets are immutable, so we must delete the existing one and re-create it with the new changes.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl delete statefulset php-apache -n apache
</span></span></code></pre></div><p>Now, deploy your changes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f ~/workshop/k3s/php-apache.yaml -n apache
</span></span></code></pre></div><h2 id=3-validate-the-changes>3. Validate the changes</h2><p>You can validate the changes have been applied by running the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl describe statefulset php-apache -n apache
</span></span></code></pre></div><p>Validate the Pod is now running in Splunk Observability Cloud.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Is the <strong>Apache Web Servers</strong> dashboard showing any data now?</p><p><strong>Tip:</strong> Don&rsquo;t forget to use filters and time frames to narrow down your data.</p></div></div><p>Monitor the Apache web servers Navigator dashboard for a few minutes.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What is happening with the # Hosts reporting chart?</p></div></div><h2 id=4-fix-memory-issue>4. Fix memory issue</h2><p>If you navigate back to the Apache dashboard, you will notice that metrics are no longer coming in. We have another resource issue and this time we are Out of Memory. Let&rsquo;s edit the stateful set and increase the memory to what is shown in the image below:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl edit statefulset php-apache -n apache
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>16Mi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>500m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>12Mi</span><span class=w>
</span></span></span></code></pre></div><p>Save the changes you have made.</p><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-exclamation"></i> Hint</div><div class=box-content><p><code>kubectl edit</code> will open the contents in the <code>vi</code> editor, use <code>Esc</code> followed by <code>:wq!</code> to save your changes.</p></div></div><p>Because StatefulSets are immutable, we must delete the existing Pod and let the StatefulSet re-create it with the new changes.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl delete pod php-apache-0 -n apache
</span></span></code></pre></div><p>Validate the changes have been applied by running the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl describe statefulset php-apache -n apache
</span></span></code></pre></div><footer class=footline></footer></article><article class=default><h1 id=deploy-load-generator>Deploy Load Generator</h1><p>Now let&rsquo;s apply some load against the <code>php-apache</code> pod. To do this, you will need start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending HTTP GETs to the <code>php-apache</code> service.</p><h2 id=1-review-loadgen-yaml>1. Review loadgen YAML</h2><p>Inspect the YAML file <code>~/workshop/k3s/loadgen.yaml</code> and validate the contents using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/workshop/k3s/loadgen.yaml
</span></span></code></pre></div><p>This file contains the configuration for the load generator and will create a new ReplicaSet with a two replicas of the load generator image.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ReplicaSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>loadgen</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>loadgen</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>loadgen</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>loadgen</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>loadgen</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>infinite-calls</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>busybox</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>command</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>/bin/sh</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- -<span class=l>c</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=s2>&#34;while true; do wget -q -O- http://php-apache-svc.apache.svc.cluster.local; done&#34;</span><span class=w>
</span></span></span></code></pre></div><h2 id=2-create-a-new-namespace>2. Create a new namespace</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl create namespace loadgen
</span></span></code></pre></div><h2 id=3-deploy-the-loadgen-yaml>3. Deploy the loadgen YAML</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl apply -f ~/workshop/k3s/loadgen.yaml --namespace loadgen
</span></span></code></pre></div><p>Once you have deployed the load generator, you can see the Pods running in the <code>loadgen</code> namespace. Use previous similar commands to check the status of the Pods from the command line.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Which metrics in the Apache Navigator have now significantly increased?</p></div></div><h2 id=4-scale-the-load-generator>4. Scale the load generator</h2><p>A ReplicaSet is a process that runs multiple instances of a Pod and keeps the specified number of Pods constant. Its purpose is to maintain the specified number of Pod instances running in a cluster at any given time to prevent users from losing access to their application when a Pod fails or is inaccessible.</p><p>ReplicaSet helps bring up a new instance of a Pod when the existing one fails, scale it up when the running instances are not up to the specified number, and scale down or delete Pods if another instance with the same label is created. A ReplicaSet ensures that a specified number of Pod replicas are running continuously and helps with load-balancing in case of an increase in resource usage.</p><p>Let&rsquo;s scale our ReplicaSet to 4 replicas using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl scale replicaset/loadgen --replicas 4 -n loadgen
</span></span></code></pre></div><p>Validate the replicas are running from both the command line and Splunk Observability Cloud:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl get replicaset loadgen -n loadgen
</span></span></code></pre></div><p><a href=#image-679859ac1875da5502a64bd38b817512 class=lightbox-link><img src=../../en/other/hpa/5-deploy-loadgen/../images/k8s-workload-replicaset.png alt=Replicaset style=height:auto;width:auto loading=lazy></a>
<a href=javascript:history.back(); class=lightbox id=image-679859ac1875da5502a64bd38b817512><img src=../../en/other/hpa/5-deploy-loadgen/../images/k8s-workload-replicaset.png alt=Replicaset class=lightbox-image loading=lazy></a></p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What impact can you see in the Apache Navigator?</p></div></div><p>Let the load generator run for around 2-3 minutes and keep observing the metrics in the Kubernetes Navigator and the Apache Navigator.</p><footer class=footline></footer></article><article class=default><h1 id=setup-horizontal-pod-autoscaling-hpa>Setup Horizontal Pod Autoscaling (HPA)</h1><p>In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.</p><p>Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.</p><p>If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.</p><h2 id=1-setup-hpa>1. Setup HPA</h2><p>Inspect the <code>~/workshop/k3s/hpa.yaml</code> file and validate the contents using the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat ~/workshop/k3s/hpa.yaml
</span></span></code></pre></div><p>This file contains the configuration for the Horizontal Pod Autoscaler and will create a new HPA for the <code>php-apache</code> deployment.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>autoscaling/v2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>HorizontalPodAutoscaler</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>apache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>maxReplicas</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>Resource</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>resource</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>cpu</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>target</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>averageUtilization</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>Utilization</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>Resource</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>resource</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>memory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>target</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>averageUtilization</span><span class=p>:</span><span class=w> </span><span class=m>75</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>Utilization</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>minReplicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>scaleTargetRef</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>StatefulSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>php-apache</span><span class=w>
</span></span></span></code></pre></div><p>Once deployed, <code>php-apache</code> will autoscale when either the average CPU usage goes above 50% and average memory usage for the deployment goes above 75%, with a minimum of 1 pod and a maximum of 4 pods.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl apply -f ~/workshop/k3s/hpa.yaml
</span></span></code></pre></div><h2 id=2-validate-hpa>2. Validate HPA</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>kubectl get hpa -n apache
</span></span></code></pre></div><p>Go to the <strong>Workloads</strong> or <strong>Node Detail</strong> tab in Kubernetes and check the HPA deployment.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>How many additional <code>php-apache-x</code> pods have been created?</p></div></div><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Which metrics in the Apache Navigator have significantly increased again?</p></div></div><h2 id=3-increase-the-hpa-replica-count>3. Increase the HPA replica count</h2><p>Increase the <code>maxReplicas</code> to 8</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl edit hpa php-apache -n apache
</span></span></code></pre></div><p>Save the changes you have made. (Hint: Use <code>Esc</code> followed by <code>:wq!</code> to save your changes).</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Questions</div><div class=box-content><ol><li><p>How many pods are now in a running state?</p></li><li><p>How many are pending?</p></li><li><p>Why are they pending?</p></li></ol></div></div><p><strong>Congratulations!</strong> You have successfully completed the workshop.</p><footer class=footline></footer></article></section></section></div></main></div><script src=../../js/clipboard.min.js?1682626358 defer></script>
<script src=../../js/perfect-scrollbar.min.js?1682626358 defer></script>
<script src=../../js/theme.js?1682626358 defer></script></body></html>