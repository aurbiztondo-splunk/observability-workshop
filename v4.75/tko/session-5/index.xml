<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>5. How Platform Engineers Observe Kubernetes on Splunk Observability Cloud Workshops</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/index.html</link><description>Recent content in 5. How Platform Engineers Observe Kubernetes on Splunk Observability Cloud Workshops</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://splunk.github.io/observability-workshop/v4.75/tko/session-5/index.xml" rel="self" type="application/rss+xml"/><item><title>Deploying the OpenTelemetry Collector in Kubernetes using a NameSpace</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-otel/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-otel/index.html</guid><description>1. New Kubernetes Navigator 2.0 UI Note As the new Kubernetes Navigator is still in Preview, some steps of this workshop might not work as expected. If you encounter any issues, please do the following:
Switch back to the old Kubernetes Navigator by clicking on the big blue Switch to old navigator button in the top right corner of the Kubernetes Navigator.
Let us know in the #tko-2023-o11y-session-5 channel in Slack.</description></item><item><title>Tour of the Kubernetes Navigator v2</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/check-new-navigator-short/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/check-new-navigator-short/index.html</guid><description>1. Cluster vs Workload View The Kubernetes Navigator offers you two separate use cases to view your Kubernetes data.
The K8s workloads is focusing on providing information in regards to workloads a.k.a. your deployments. The K8s nodes is focusing on providing insight into the performance of clusters, Nodes, Pods &amp;amp; Containers. You initially select either view depending on your need (you can switch between the view on the fly if required).</description></item><item><title>Deploying PHP/Apache</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-apache/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-apache/index.html</guid><description>1. DNS and Services in Kubernetes The Domain Name System (DNS) is a mechanism for linking various sorts of information with easy-to-remember names, such as IP addresses. Using a DNS system to translate request names into IP addresses makes it easy for end-users to reach their target domain name effortlessly.
Most Kubernetes clusters include an internal DNS service configured by default to offer a lightweight approach for service discovery. Even when Pods and Services are created, deleted, or shifted between nodes, built-in service discovery simplifies applications to identify and communicate with services on the Kubernetes clusters.</description></item><item><title>Fix PHP/Apache Issue</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/fix-apache/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/fix-apache/index.html</guid><description>1. Kubernetes Resources Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.
You do this by placing a Resource section in the deployment of you application/Pod
Example:
resources: limits: # Maximum amount of CPU &amp;amp; memory for peek use cpu: &amp;#34;8&amp;#34; # Maximum of 8 cores of CPU allowed at for peek use memory: &amp;#34;9Mi&amp;#34; # Maximum allowed 9Mb of memory requests: # Request are the expected amount of CPU &amp;amp; memory for normal use cpu: &amp;#34;6&amp;#34; # Requesting 4 cores of a CPU memory: &amp;#34;4Mi&amp;#34; # Requesting 4Mb of memory More information can be found here : Resource Management for Pods and Containers</description></item><item><title>Deploy Load Generator</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-loadgen/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/deploy-loadgen/index.html</guid><description>Now let&amp;rsquo;s see how the autoscaler reacts to increased load. To do this, you&amp;rsquo;ll start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending queries to the php-apache service.
1. Review loadgen YAML Inspect the YAML file ~/workshop/k3s/loadgen.yaml and validate the contents using the following command:
cat ~/workshop/k3s/loadgen.yaml This file contains the configuration for the load generator and will create a new StatefulSet with a single replica of the load generator image.</description></item><item><title>Setup Horizontal Pod Autoscaling (HPA)</title><link>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/setup-hpa/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://splunk.github.io/observability-workshop/v4.75/tko/session-5/setup-hpa/index.html</guid><description>In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.
Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.
If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.</description></item></channel></rss>